Title: Filter Bubbles and the Unfeeling: How AI for Social Media Can Foster Extremism and Polarization | Philosophy & Technology
URL: https://link.springer.com/article/10.1007/s13347-024-00758-4
Content:

1 Introduction
--------------

The potential of artificial intelligence is multiplying at an exponential rate, to the extent that it is difficult to predict its long-term effects in the social sphere. A platform like ChatGPT is changing the way we engage with intellectual and creative work and, at a more substantive level, the way we search, structure, and learn information (CU Committee, 2023). As stated by an increasing number of studies, generative AI has proven to be effective in the healthcare sector and may be used in areas such as data analysis, medical imaging and clinical diagnosis (ELKarazle et al., 2024). The algorithms that direct the web and social media are redefining the world of marketing and business, implementing new methods that effectively intercept consumer desires (Poornima et al., 2023). Deep learning features of AI can significantly improve transport systems and are currently being included in several National AI strategies – Dominican Republic, US, Rwanda, Italy, and India to name a few of them (MEPD, 2023). For these reasons, information selection is now crucial for users to employ the Web: without any effective sorting process, we would not be able to navigate a boundless ocean of data. That is why our experience of the digital world is customized and different from anyone else’s.

This brings numerous benefits. Users can efficiently access the information and products they are interested in, companies can easily interact with consumers, and the circulation of knowledge has exponentially improved in recent years. At the same time, the selective management of Big Data through specific algorithms gives rise to a paradox: we are both extremely connected with and disconnected from the Web. We constantly interact with the kind of information that is consistent with our habitual behavior on the Web, with little (if any) chance of experiencing unexpected information and data. In other words, we are not guaranteed to be exposed to perspectives other than our own, to explore the diversity of opinions and narratives around us.

It is important to note that exposure to opinions similar to our own and a general narrowness of our experiences also occurs outside the virtual world. Even in the concrete world, we tend to move within a personal bubble: we hang out with a limited group of people, do a certain type of work, and have access to a specific kind of experience, and therefore tend to receive information and narratives consistent with our daily habits. We have always been dealing with issues related to confirmation bias, selective exposure, and group polarization. In this work, I intend to point out that – considering how selective algorithms work – our social media experience may exacerbate the aforementioned issues.

### 2.1 A Brief on Recommender Systems (RSs) and Machine Learning Algorithms (MLAs)

To understand how filter bubbles are formed and work – and to better grasp the effects of a preselected informational environment – it is essential to introduce Recommender Systems (RSs) and explain the functioning of Machine Learning Algorithms (MLAs). Recommender systems can be defined as software tools and algorithmic mechanisms that attempt to recommend the most suitable items (e.g., products and services) to a user. They collect and analyze information on the preferences, behavior, and historical data of users to predict their interests in certain items. These recommendations are thus tailored to meet users’ interests, needs, and preferences, aiming to facilitate decision-making and increase engagement with items and content (Bobadilla et al., 2013).

These systems are undoubtedly useful and can have many applications. First, they allow us to filter the massive amount of information available to users: as I previously said, in today’s digital age we tend to be overwhelmed by a massive amount of data, hence recommender systems are crucial for helping users navigate the Web and select the kind of information they need in specific contexts. Second, being exposed to personalized content that adheres to our desires, needs, habits, and dispositions creates a strong bond between users and items. That’s why filtering engines are employed in different areas like marketing, education, social life, and entertainment, and thus influence many aspects of our daily lives (Suhaim & Berri, 2021). Given their ability to simplify the users’ lives and direct them to content to which they attribute value and significance, these tools have proven to be exceptional resources for fully exploiting the potential of the Web and rapidly became widely used in social media. Moreover, they are becoming much more sophisticated over time. While in first and second-generation social media these engines were more rudimentary, third-generation platforms have seen remarkable advancements in content personalization and have thus created new opportunities and innovations, especially in marketing (Abed et al., 2023).

The point at which recommender systems become crucial in this work lies in the fact that such personalized content is capable of creating engagement with the user (Reviglio & Agosti, 2020). The principle by which machine learning algorithms employed in social media are becoming increasingly sophisticated is that they make the user more involved with the platform. Since users experience a virtual scenario perfectly adherent to their interests, needs, and habits, they will be inclined to spend more and more time on social media to seek gratification. Social media are made to be appealing and addictive, to intercept the user’s attention for as long as possible (Doheny & Lighthall, 2023), and they can achieve that aim through the sense of satisfaction we feel during a social media experience that is consistent with what we consider enjoyable and rewarding (Gal, 2017). What I intend to do in this paper is to emphasize how the specific functioning of selective algorithms may foster polarization of opinions and biased decisions and how, as a result, it can impair our deliberative capacity in general. In the next section, I will highlight how the Deweyan theory of experience is useful in understanding the possible consequences of algorithmic selection for our epistemic world.

### 2.2 Material Experience vs Algorithm-Driven Experience

As mentioned in the previous paragraphs, we are all subject to limited experience. Not only in our digital experience but also in the outside world. As Cass Sunstein argues, “Filtering is inevitable, a fact of life. It is as old as humanity itself. No one can see, hear, or read everything” (Sunstein, 2007). It is important to say that experience itself is made possible by the phenomenon of _continuity_: the accumulation of certain past experiences will influence future experiences (Dewey, 1938). I believe that these statements can be further enriched by analyzing more specifically the operation of machine learning algorithms, which shows how our ability to learn from our experiences and develop adequate decision-making power can be hindered by a type of experience that is perfectly tailored for users and, therefore, eliminates the possibility of testing our experiences, and thus our views, opinions, and habits. Based on the above, machine learning algorithms are currently designed in such a way as to: (a) avoid unexpected and serendipitous experiences; (b) hinder the exploration of views and perspectives other than one’s own, making our decision-making more biased and prone to polarization; and (c) prevent human individuals from having an experimental approach to experience. These inherent characteristics of selective algorithms, according to Deweyan experience theory, constitute a detriment to individuals' growth and the development of their critical sense.

In algorithm-driven experience our thoughts and actions remain confined to our comfort zone and tend to perpetuate themselves consistently. Filter bubbles can thus be considered self-confirming comfort zones that tend to reinforce pre-existing beliefs, behaviors and preferences, while limiting exposure to diverse perspectives (Courtois et al., 2018). An even more problematic aspect of this phenomenon is that we tend to believe we are all equally connected (or hyperconnected) with the infosphere, when in fact our Web experiences are highly limited and self-referential. In other words, we believe that our way of accessing information is the same as everyone else’s and that the entire knowledge and the entire spectrum of virtual interactions are simply there for all to grasp, while we live in a narrow intellectual ecosystem that is mostly impermeable and isolated from other ecosystems.

This isolation can also lead to the generation of echo chambers, namely “the epistemic structure from which other relevant voices have been actively excluded and discredited” (Nguyen, 2020). The process that leads us to favor information that reinforces our pre-existing beliefs (confirmation bias) is a consolidated attitude through which we approach knowledge (Nickerson, 1998). The human mind accumulates and selects information, develops schemata, and tends to reinforce those schemata that appear most credible and functional, to fit more effectively into its ecosystem (Pariser, 2011) made up of discussion, exchange of views, verification, and critical analysis of information. More importantly, it should include a varied set of experiences, sometimes conflicting with each other, so that members of the democratic community can _deliberate_, which means discussing the information at hand and developing plans and alternatives (Dewey, 1927), so I believe that this line of inquiry should be further analyzed through the lens of political philosophy. Here, I propose to recall Dewey’s theory of experience as an interpretive model of political radicalization. For instance, if we consider a set of similar experiences repeated over time, according to the Deweyan model of experience we can say that they can stratify and give rise to established practices, habits, and beliefs that the individual can use according to environments, contexts, and needs. Similarly, we can argue that experiential hyperstimulation and constant exposure to repetitive political content can lead to the disproportionate reinforcement of opinions and views – to the point of crystallizing into rigid attitudes and beliefs that refuse to admit other interpretations of the public and its problems. Thus, to break this dangerous cycle of reinforcement, we need to ask ourselves how we can have material and virtual experiences that challenge our perspectives.

4 Political Compassion vs Emotional Anesthetization
---------------------------------------------------

The Deweyan concept of political apathy finds resonance in a work by Martha Nussbaum dedicated to the so-called _political emotions_ (Ure and Frost, 2014). Before delving into a brief reconnaissance of this analysis, we should take a step back and return to the notion of selective algorithms and filter bubbles. Here, I want to point out the distinctive features of data usually selected by algorithms – which explain why social media platforms employ content personalization. This kind of data can be _appealing_, in the sense that it is perceived as pleasant by the person interacting with them (Pariser, 2011). This option is based on the general principles of the Open Source Software movement, which calls for the free circulation of information for the common good and progressive human development (Stewart & Gosain, 2006). One promising proposal is to implement _“serendipity”_ within algorithms to enable processing “unexpected and valuable information” and thus stimulate “cognitive diversity, creativity, and innovation” (Reviglio, 2017). I believe that Reviglio’s proposal may provide greater diversity exposure even to those who do not have prior knowledge of algorithms and thus may be a fruitful direction for the development of algorithms designed to avert the risk of producing filter bubbles.

Making source codes open and implementing more serendipity or randomness within machine learning algorithms are undoubtedly two possibilities to mitigate our epistemic bubbles and allow us to go out and explore the world outside our comfort zones. If “the measure of the worth of any social institution, economic, domestic, political, legal, religious, is its effect in enlarging and improving experience” (Dewey, 1916). I believe one effective path could be training the algorithms through the virtue ethics model, which has as a foundation the enhancement and flourishing of the human being (Farina et al., 2022). The process of cultivating virtues is based, according to the Neo-Aristotelian view (e.g. McIntyre, 1984), on experience and learning: through the exercise of the virtues in different moral situations (whether real or hypothetical), algorithms can be refined by leading the subject (whether human or artificial) toward excellence. In order to design virtuous algorithms, these must confront different data and experiences, take a cross-cultural approach, and train the creative and narrative ability to imagine different moral scenarios. In doing so, algorithms should be trained to present not only serendipity but also discomfort. Getting out of their comfort zone and learning about even uncomfortable narratives is what enables human individuals to learn about different realities, identify injustices, and promote collective well-being and flourishing.

Exploring diverse narratives and moral situations through constant virtue training by algorithmic systems could significantly decrease the negative repercussions that recommender systems have for users, and thus avoid the formation of Filter Bubbles. Virtuous algorithms could even have an ameliorative effect on the evaluative and moral abilities of individuals, who would be exposed to a much wider and different range of realities than their own limited experience, and hence train their _phronesis_ or “practical wisdom” (see Aristotle, 2012). The ethical training of algorithms could also have a positive effect on the circulation of information in general, since they could select quality information, excluding fake news and fake data. On the other hand, it should be noted that algorithms could do little to counteract echo chambers: since – unlike filter bubbles – they involve _voluntary_ exclusion and discrediting of information by the subject, we could infer that varied exposure to the Web might not be sufficient to counteract this phenomenon. The topic is vast and would require dedicated studies. I suggest, therefore, further investigations into the link between machine learning algorithms and the political and collective dimensions, and into ethical models that could effectively be applied to the development of _ethical algorithms_.

Philosophical and ethical analysis of artificial intelligence should be encouraged since, as I said at the beginning of this paper, we do not yet have enough speculative tools to keep up with technological acceleration. The digital revolution holds enormous benefits but also introduces unpredictable consequences. That is why we should conceive philosophy not as Minerva's noctule appearing only at the end of history but as a watchful sentinel conscious of history and ready to intercept the changes and needs of our time, prepared to ask questions and provide answers.

5 Conclusion
------------

In this work, I first tried to reconnect the concept of filter bubbles to the Deweyan theory of experience. At a basic level, Dewey’s theoretical framework shows us that we better function as human beings if we accumulate plenty of experiences through which we learn different ways to interact with our environment, which may stratify into habits and beliefs. These processes also show how experience is fundamental to the maintenance of democratic equilibrium, as “everything which bars freedom and fullness of communication sets up barriers that divide human beings into sets and cliques, into antagonistic sects and factions, and thereby undermines the democratic way of life” (Dewey, [1988](https://link.springer.com/article/10.1007/s13347-024-00758-4#ref-CR22 "Dewey, J. (1988). The collected works of John Dewey. the later works, 1925–1953 (Vol. 14, pp. 1939–1941). Southern Illinois University Press."): 227–8; this same quote is given in Pariser’s work).

However, if filter bubbles aprioristically select our experiences and propose to us the same content, our intellectual ecosystem will be limited, and – at the same time – it will limit our development and the stability of the social community in which we interact. These processes could jeopardize our deliberative and participatory capacity as they would (a) limit users’ access to information, whereby the ability to engage in informed political discussion and unbiased decision-making would be compromised; (b) discourage social aggregation, preventing the development of forms of collaboration that enable citizens to realize their political potential and positively influence their social environment. More alarmingly, the phenomena of isolation and self-reinforcement can lead to radicalization and polarization of the political views of users exposed to filtering algorithms. As we know, radicalization and polarization are not only a threat to democracy but to all forms of civil coexistence.

Nonetheless, I believe it is possible to mitigate phenomena related to cognitive and moral isolation caused by artificial intelligence and, perhaps, direct these instruments toward greater human empowerment and cooperation. If we develop new modes of experience and expand our sympathetic faculties, we can dismantle our bubble or make it more permeable to external stimuli. Among the ways to deal with this purpose, emotional cultivation can predispose us to openness and cooperation with others. Especially if supported by narrative exercise, the cultivation of emotion can show us that human nature is marked by shared forms of vulnerability. By recognizing ourselves in others, by admitting our mutual need for compassion and care, we broaden our epistemic and moral experience, break the vicious circle of solipsism, and achieve our flourishing and harmonious cohesion with our environment.

References
----------

*   Abed, L. Y., Hamad, M., & Aljaaf, A .J. (2023). A review of marketing recommendation systems. _Al-Kadhum 2nd International Conference on Modern Applications of Information and Communication Technology_, _2591_(1). [https://doi.org/10.1063/5.0119651](https://doi.org/10.1063/5.0119651)
    
*   Alexander, T. M. (1987). _John Dewey’s theory of art_. State University of New York Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=John%20Dewey%27s%20theory%20of%20art&publication_year=1987&author=Alexander%2CTM) 
    
*   Anayat, S., & Rasool, G. (2022). Artificial Intelligence Marketing (AIM): Connecting-the-dots using bibliometrics. _Journal of Marketing Theory and Practice,_ _32_(1), 114–135. [https://doi.org/10.1080/10696679.2022.2103435](https://doi.org/10.1080/10696679.2022.2103435)
    
    [Article](https://doi.org/10.1080%2F10696679.2022.2103435)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Artificial%20Intelligence%20Marketing%20%28AIM%29%3A%20Connecting-the-dots%20using%20bibliometrics&journal=Journal%20of%20Marketing%20Theory%20and%20Practice&doi=10.1080%2F10696679.2022.2103435&volume=32&issue=1&pages=114-135&publication_year=2022&author=Anayat%2CS&author=Rasool%2CG) 
    
*   Anderson, E. (2021). Epistemic bubbles and authoritarian politics. In E. Edenberg & M. Hannon (Eds.), _Political epistemology_. Oxford University Press.
    
*   Aristotle. (2012). _Nicomachean ethics_ (trans: Bartlett, R.C., & Collins, S.D.). University of Chicago Press.
    
*   Bai, J., et al. (2019). Exploring cognitive dissonance on social media. _IEEE International Conference on Intelligence and Security Informatics (ISI),_ _2019_, 143–145. [https://doi.org/10.1109/ISI.2019.8823262](https://doi.org/10.1109/ISI.2019.8823262)
    
    [Article](https://doi.org/10.1109%2FISI.2019.8823262)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Exploring%20cognitive%20dissonance%20on%20social%20media&journal=IEEE%20International%20Conference%20on%20Intelligence%20and%20Security%20Informatics%20%28ISI%29&doi=10.1109%2FISI.2019.8823262&volume=2019&pages=143-145&publication_year=2019&author=Bai%2CJ) 
    
*   Baldauf, J., Ebner, J., & Guhl, J. (Eds.). (2019). _Hate speech and radicalisation online: The OCCI research report_. Institute for Strategic Dialogue (ISD).
    
*   Bernstein, R. J. (1961). John Dewey’s metaphysics of experience. _The Journal of Philosophy,_ _58_(1), 5–14. [https://doi.org/10.2307/2023564](https://doi.org/10.2307/2023564)
    
    [Article](https://doi.org/10.2307%2F2023564)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=John%20Dewey%27s%20metaphysics%20of%20experience&journal=The%20Journal%20of%20Philosophy&doi=10.2307%2F2023564&volume=58&issue=1&pages=5-14&publication_year=1961&author=Bernstein%2CRJ) 
    
*   Bernstein, R. J. (2010). _The pragmatic turn_. Polity Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20pragmatic%20turn&publication_year=2010&author=Bernstein%2CRJ) 
    
*   Bobadilla, J., Ortega, F., Hernando, A., & Gutiérrez, A. (2013). Recommender systems survey. _Knowledge-Based Systems,_ _46_, 109–132. [https://doi.org/10.1016/j.knosys.2013.03.012](https://doi.org/10.1016/j.knosys.2013.03.012)
    
    [Article](https://doi.org/10.1016%2Fj.knosys.2013.03.012)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Recommender%20systems%20survey&journal=Knowledge-Based%20Systems&doi=10.1016%2Fj.knosys.2013.03.012&volume=46&pages=109-132&publication_year=2013&author=Bobadilla%2CJ&author=Ortega%2CF&author=Hernando%2CA&author=Guti%C3%A9rrez%2CA) 
    
*   Borgman, C. L. (2015). _Big data, little data, no data: Scholarship in the networked world_. The MIT Press.
    
    [Book](https://doi.org/10.7551%2Fmitpress%2F9963.001.0001)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Big%20data%2C%20little%20data%2C%20no%20data%3A%20Scholarship%20in%20the%20networked%20world&doi=10.7551%2Fmitpress%2F9963.001.0001&publication_year=2015&author=Borgman%2CCL) 
    
*   Brady, M. (2013). _Emotional insight: The epistemic role of emotional experience_. Oxford University Press.
    
    [Book](https://doi.org/10.1093%2Facprof%3Aoso%2F9780199685523.001.0001)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Emotional%20insight%3A%20The%20epistemic%20role%20of%20emotional%20experience&doi=10.1093%2Facprof%3Aoso%2F9780199685523.001.0001&publication_year=2013&author=Brady%2CM) 
    
*   Brodsky, G. M. (1964). Dewey on experience and nature. _The Monist,_ _48_(3), 366–381. [https://doi.org/10.5840/monist196448322](https://doi.org/10.5840/monist196448322)
    
    [Article](https://doi.org/10.5840%2Fmonist196448322)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Dewey%20on%20experience%20and%20nature&journal=The%20Monist&doi=10.5840%2Fmonist196448322&volume=48&issue=3&pages=366-381&publication_year=1964&author=Brodsky%2CGM) 
    
*   Caspary, W. R. (2000). _Dewey on democracy_. Cornell University Press.
    
    [Book](https://doi.org/10.7591%2F9781501722509)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Dewey%20on%20democracy&doi=10.7591%2F9781501722509&publication_year=2000&author=Caspary%2CWR) 
    
*   Chen, M., & Racz, M. (2021). An adversarial model of network disruption: Maximizing disagreement and polarization in social networks. _IEEE Transactions on Network Science and Engineering,_ _9_, 728–739. [https://doi.org/10.1109/TNSE.2021.3131416](https://doi.org/10.1109/TNSE.2021.3131416)
    
    [Article](https://doi.org/10.1109%2FTNSE.2021.3131416)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=An%20adversarial%20model%20of%20network%20disruption%3A%20Maximizing%20disagreement%20and%20polarization%20in%20social%20networks&journal=IEEE%20Transactions%20on%20Network%20Science%20and%20Engineering&doi=10.1109%2FTNSE.2021.3131416&volume=9&pages=728-739&publication_year=2021&author=Chen%2CM&author=Racz%2CM) 
    
*   Coeckelbergh, M. (2023). Democracy, epistemic agency, and AI: Political epistemology in times of artificial intelligence. _AI and Ethics,_ _3_, 1341–1350. [https://doi.org/10.1007/s43681-022-00239-4](https://doi.org/10.1007/s43681-022-00239-4)
    
    [Article](https://link.springer.com/doi/10.1007/s43681-022-00239-4)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Democracy%2C%20epistemic%20agency%2C%20and%20AI%3A%20Political%20epistemology%20in%20times%20of%20artificial%20intelligence&journal=AI%20and%20Ethics&doi=10.1007%2Fs43681-022-00239-4&volume=3&pages=1341-1350&publication_year=2023&author=Coeckelbergh%2CM) 
    
*   Courtois, C., Slechten, L., & Coenen, L. (2018). Challenging Google Search filter bubbles in social and political information: Disconforming evidence from a digital methods case study. _Telematics and Informatics,_ _35_(7), 2006–2015. [https://doi.org/10.1016/j.tele.2018.07.004](https://doi.org/10.1016/j.tele.2018.07.004)
    
    [Article](https://doi.org/10.1016%2Fj.tele.2018.07.004)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Challenging%20Google%20Search%20filter%20bubbles%20in%20social%20and%20political%20information%3A%20Disconforming%20evidence%20from%20a%20digital%20methods%20case%20study&journal=Telematics%20and%20Informatics&doi=10.1016%2Fj.tele.2018.07.004&volume=35&issue=7&pages=2006-2015&publication_year=2018&author=Courtois%2CC&author=Slechten%2CL&author=Coenen%2CL) 
    
*   CU Committee. (2023). _Generative artificial intelligence for education and pedagogy_. Cornell University. [https://research-and-innovation.cornell.edu/generative-ai-in-academic-research/](https://research-and-innovation.cornell.edu/generative-ai-in-academic-research/). Accessed 3 Apr 2024
    
*   de Arruda, et al. (2021). Modelling how social network algorithms can influence opinion polarization. _Information Sciences,_ _588_, 265–78. [https://doi.org/10.1016/j.ins.2021.12.069](https://doi.org/10.1016/j.ins.2021.12.069)
    
    [Article](https://doi.org/10.1016%2Fj.ins.2021.12.069)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Modelling%20how%20social%20network%20algorithms%20can%20influence%20opinion%20polarization&journal=Information%20Sciences&doi=10.1016%2Fj.ins.2021.12.069&volume=588&pages=265-78&publication_year=2021&author=Arruda%2C) 
    
*   Dewey, J. (1925). _Experience and nature_. Open Court.
    
*   Dewey, J. (1976). _The collected works of John Dewey. The middle works, 1899–1924_ (Vol. 7, pp. 1912–1914). Southern Illinois University Press.
    
*   Dewey, J. (1988). _The collected works of John Dewey. the later works, 1925–1953_ (Vol. 14, pp. 1939–1941). Southern Illinois University Press.
    
*   Dewey, J. (1989). _The collected works of John Dewey. The later works, 1925–1953_ (Vol. 15, pp. 1942–1948). Southern Illinois University Press.
    
*   Dewey, J. (1916). _Democracy and education: An introduction to the philosophy of education_. Macmillan Publishing.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Democracy%20and%20education%3A%20An%20introduction%20to%20the%20philosophy%20of%20education&publication_year=1916&author=Dewey%2CJ) 
    
*   Dewey, J. (1927). _The public and its problems_. Ohio University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20public%20and%20its%20problems&publication_year=1927&author=Dewey%2CJ) 
    
*   Dewey, J. (1938). _Experience and Education_. Touchstone.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Experience%20and%20Education&publication_year=1938&author=Dewey%2CJ) 
    
*   Doheny, M. M., & Lighthall, N. R. (2023). Social cognitive neuroscience in the digital age. _Frontiers in Human Neuroscience_, _17_. [https://doi.org/10.3389/fnhum.2023.1168788](https://doi.org/10.3389/fnhum.2023.1168788)
    
*   ELKarazle, K., Raman, V., Then, P., & Chua, C. (2024). How generative AI is transforming medical imaging: A practical guide. Applications of generative AI. In Z. Lyu (Ed.), _Applications of generative AI._ Springer.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=How%20generative%20AI%20is%20transforming%20medical%20imaging%3A%20A%20practical%20guide.%20Applications%20of%20generative%20AI&publication_year=2024&author=ELKarazle%2CK&author=Raman%2CV&author=Then%2CP&author=Chua%2CC) 
    
*   Farina, M., Zhdanov, P., Karimov, A., et al. (2022). AI and society: A virtue ethics approach. _AI & Society_. [https://doi.org/10.1007/s00146-022-01545-5](https://doi.org/10.1007/s00146-022-01545-5)
    
    [Article](https://link.springer.com/doi/10.1007/s00146-022-01545-5)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=AI%20and%20society%3A%20A%20virtue%20ethics%20approach&journal=AI%20%26%20Society&doi=10.1007%2Fs00146-022-01545-5&publication_year=2022&author=Farina%2CM&author=Zhdanov%2CP&author=Karimov%2CA) 
    
*   Farshidi, et al. (2023). Understanding user intent modeling for conversational recommender systems: A systematic literature review. _ArXiv_. [https://doi.org/10.21203/rs.3.rs-3238230/v1](https://doi.org/10.21203/rs.3.rs-3238230/v1)
    
*   Floridi, L. (2023). _The ethics of artificial intelligence: Principles, challenges, and opportunities_. Oxford University Press.
    
    [Book](https://doi.org/10.1093%2Foso%2F9780198883098.001.0001)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20ethics%20of%20artificial%20intelligence%3A%20Principles%2C%20challenges%2C%20and%20opportunities&doi=10.1093%2Foso%2F9780198883098.001.0001&publication_year=2023&author=Floridi%2CL) 
    
*   Floridi, L., Cowls, J., Beltrametti, M., et al. (2018). AI4People – an ethical framework for a good AI society: Opportunities, risks, principles, and recommendations. _Minds & Machines,_ _28_, 689–707. [https://doi.org/10.1007/s11023-018-9482-5](https://doi.org/10.1007/s11023-018-9482-5)
    
    [Article](https://link.springer.com/doi/10.1007/s11023-018-9482-5)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=AI4People%20%E2%80%93%20an%20ethical%20framework%20for%20a%20good%20AI%20society%3A%20Opportunities%2C%20risks%2C%20principles%2C%20and%20recommendations&journal=Minds%20%26%20Machines&doi=10.1007%2Fs11023-018-9482-5&volume=28&pages=689-707&publication_year=2018&author=Floridi%2CL&author=Cowls%2CJ&author=Beltrametti%2CM) 
    
*   Gal, M. S. (2017). Algorithmic challenges to autonomous choice. _Michigan Telecommunications and Technology Law Review,_ _25_(1), 59–104. [https://doi.org/10.2139/ssrn.2971456](https://doi.org/10.2139/ssrn.2971456)
    
    [Article](https://doi.org/10.2139%2Fssrn.2971456)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Algorithmic%20challenges%20to%20autonomous%20choice&journal=Michigan%20Telecommunications%20and%20Technology%20Law%20Review&doi=10.2139%2Fssrn.2971456&volume=25&issue=1&pages=59-104&publication_year=2017&author=Gal%2CMS) 
    
*   Gangadharan, K., Malathi, K., Purandaran, A., et al. (2024). From data to decisions: The Transformational power of machine learning in business recommendations. _ArXiv_. [https://doi.org/10.48550/arXiv.2402.0810](https://doi.org/10.48550/arXiv.2402.0810)
    
*   Gehl, R. W. (2015). The case for alternative social media. _Social Media + Society,_ _1_(2), 1–13. [https://doi.org/10.1177/2056305115604338](https://doi.org/10.1177/2056305115604338)
    
    [Article](https://doi.org/10.1177%2F2056305115604338)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20case%20for%20alternative%20social%20media&journal=Social%20Media%20%2B%20Society&doi=10.1177%2F2056305115604338&volume=1&issue=2&pages=1-13&publication_year=2015&author=Gehl%2CRW) 
    
*   Geschke, D., Lorenz, J., & Holtz, P. (2019). The triple-filter bubble: Using agent-based modelling to test a meta-theoretical framework for the emergence of filter bubbles and echo chambers. _British Journal of Social Psychology,_ _58_(1), 129–149. [https://doi.org/10.1111/bjso.12286](https://doi.org/10.1111/bjso.12286)
    
    [Article](https://doi.org/10.1111%2Fbjso.12286)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20triple-filter%20bubble%3A%20Using%20agent-based%20modelling%20to%20test%20a%20meta-theoretical%20framework%20for%20the%20emergence%20of%20filter%20bubbles%20and%20echo%20chambers&journal=British%20Journal%20of%20Social%20Psychology&doi=10.1111%2Fbjso.12286&volume=58&issue=1&pages=129-149&publication_year=2019&author=Geschke%2CD&author=Lorenz%2CJ&author=Holtz%2CP) 
    
*   Hildreth, R. (2012). Word and deed: A Deweyan integration of deliberative and participatory democracy. _New Political Science,_ _34_(3), 295–320. [https://doi.org/10.1080/07393148.2012.703852](https://doi.org/10.1080/07393148.2012.703852)
    
    [Article](https://doi.org/10.1080%2F07393148.2012.703852)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Word%20and%20deed%3A%20A%20Deweyan%20integration%20of%20deliberative%20and%20participatory%20democracy&journal=New%20Political%20Science&doi=10.1080%2F07393148.2012.703852&volume=34&issue=3&pages=295-320&publication_year=2012&author=Hildreth%2CR) 
    
*   Huang, Z., Silva, A., & Singh, A. (2022). _Pole: Polarized embedding for signed networks_. In K. S. Candan, et al. (Eds.), _Proceedings, of the Fifteenth ACM International Conference on Web Search and Data Mining_. Association for Computing Machinery, 390–400. [https://catalog.libraries.psu.edu/catalog/41952652](https://catalog.libraries.psu.edu/catalog/41952652). Accessed 13 Apr 2024
    
*   Hutchinson, D. (2015). Coming to understand experience: Dewey’s theory of experience and narrative inquiry. _Journal of Thought,_ _49_, 3–17.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Coming%20to%20understand%20experience%3A%20Dewey%E2%80%99s%20theory%20of%20experience%20and%20narrative%20inquiry&journal=Journal%20of%20Thought&volume=49&pages=3-17&publication_year=2015&author=Hutchinson%2CD) 
    
*   Interian, R., Moreno, J., & Ribeiro, C. (2021). Polarization reduction by minimum-cardinality edge additions: Complexity and integer programming approaches. _International Transactions in Operational Research,_ _28_, 1242–1264. [https://doi.org/10.1111/itor.12854](https://doi.org/10.1111/itor.12854)
    
    [Article](https://doi.org/10.1111%2Fitor.12854)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Polarization%20reduction%20by%20minimum-cardinality%20edge%20additions%3A%20Complexity%20and%20integer%20programming%20approaches&journal=International%20Transactions%20in%20Operational%20Research&doi=10.1111%2Fitor.12854&volume=28&pages=1242-1264&publication_year=2021&author=Interian%2CR&author=Moreno%2CJ&author=Ribeiro%2CC) 
    
*   Kitchin, R., & McArdle, G. (2016). What makes big data, big data? Exploring the ontological characteristics of 26 datasets. _Big Data & Society_, _3_(1). [https://doi.org/10.1177/2053951716631130](https://doi.org/10.1177/2053951716631130)
    
*   Lang, O., et al. (2024). Using generative AI to investigate medical imagery models and datasets. _EBiomedicine_, _102_. [https://doi.org/10.1016/j.ebiom.2024.105075](https://doi.org/10.1016/j.ebiom.2024.105075)
    
*   Levy, R. (2021). Social media, news consumption, and polarization: Evidence from a field experiment. _American Economic Review,_ _111_(3), 831–870. [https://doi.org/10.1257/aer.20191777](https://doi.org/10.1257/aer.20191777)
    
    [Article](https://doi.org/10.1257%2Faer.20191777)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Social%20media%2C%20news%20consumption%2C%20and%20polarization%3A%20Evidence%20from%20a%20field%20experiment&journal=American%20Economic%20Review&doi=10.1257%2Faer.20191777&volume=111&issue=3&pages=831-870&publication_year=2021&author=Levy%2CR) 
    
*   Leysen, J., Michiels, L., Smets, A., & Goethals, B. (2022). What are filter bubbles really? A review of the conceptual and empirical work. In A. Bellogin, et al. (Eds.), _Adjunct proceedings of the 30th ACM conference on user modeling, adaptation and personalization_. Association for Computing Machinery.
    
*   Liao, T., & Tyson, O. (2021). “Crystal is creepy, but cool”: Mapping folk theories and responses to automated personality recognition algorithms. _Social Media + Society_, _7_(2). [https://doi.org/10.1177/20563051211010170](https://doi.org/10.1177/20563051211010170)
    
*   Lippmann, W. (1925). _The phantom public_. Mcmillan & Co.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20phantom%20public&publication_year=1925&author=Lippmann%2CW) 
    
*   Mannell, K., & Smith, E. T. (2022). Alternative social media and the complexities of a more participatory culture: A view from Scuttlebutt. _Social Media + Society_, _8_(3). [https://doi.org/10.1177/20563051221122448](https://doi.org/10.1177/20563051221122448)
    
*   McBride, N., & Amrollahi A. (2019). How to burst the bubble in social networks? _UK Academy for Information Systems Conference Proceedings 2019_, 44. [https://aisel.aisnet.org/ukais2019/44](https://aisel.aisnet.org/ukais2019/44)
    
*   McIntyre, A. (1984). _After virtue: A study in moral theory_. University of Notre Dame Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=After%20virtue%3A%20A%20study%20in%20moral%20theory&publication_year=1984&author=McIntyre%2CA) 
    
*   Ministerio de Economía, Planificación y Desarrollo (MEPD), República Dominicana. (2023). _ENIA – Estrategia Nacional de Inteligencia Artificial de la República Dominicana_. [https://agendadigital.gob.do/wp-content/uploads/2023/10/Final\_ENIA-Estrategia-Nacional-de-Inteligencia-Artificial-de-la-Republica-Dominicana-.pdf](https://agendadigital.gob.do/wp-content/uploads/2023/10/Final_ENIA-Estrategia-Nacional-de-Inteligencia-Artificial-de-la-Republica-Dominicana-.pdf). Accessed 3 Apr 2024
    
*   Ministero dell’Innovazione e della Digitalizzazione. (MID), Repubblica Italiana. (2020). _Strategia Nazionale per l'Intelligenza Artificiale_. [https://www.mimit.gov.it/images/stories/documenti/Strategia\_Nazionale\_AI\_2020.pdf](https://www.mimit.gov.it/images/stories/documenti/Strategia_Nazionale_AI_2020.pdf). Accessed 3 Apr 2024
    
*   Ministry of ICT and Innovation (MINICT), Republic of Rwanda. (2022). _Rwanda’s National Artificial Intelligence Policy Framework_. [https://www.minict.gov.rw/index.php?eID=dumpFile&t=f&f=67550&token=6195a53203e197efa47592f40ff4aaf24579640e](https://www.minict.gov.rw/index.php?eID=dumpFile&t=f&f=67550&token=6195a53203e197efa47592f40ff4aaf24579640e). Accessed 3 Apr 2024
    
*   Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., & Floridi, L., (2016). The ethics of algorithms: Mapping the debate. _Big Data & Society_, _3_(2). [https://doi.org/10.1177/2053951716679679](https://doi.org/10.1177/2053951716679679)
    
*   Mogdil, S., Singh, R., Gupta, S., & Dennehy, D. (2021). A confirmation bias view on social media induced polarisation during Covid-19. _Information Systems Frontiers_, 1–25. [https://doi.org/10.1007/s10796-021-10222-9](https://doi.org/10.1007/s10796-021-10222-9)
    
*   National Institution for Transforming India (NITI Aayog), India. (2018). _National strategy for artificial intelligence_. [https://www.niti.gov.in/sites/default/files/2023-03/National-Strategy-for-Artificial-Intelligence.pdf](https://www.niti.gov.in/sites/default/files/2023-03/National-Strategy-for-Artificial-Intelligence.pdf). Accessed 3 Apr 2024
    
*   National Science and Technology Council (NSTC), United States of America. (2023). _National Artificial Intelligence Research and Development Strategic Plan 2023 Update_. [https://www.whitehouse.gov/wp-content/uploads/2023/05/National-Artificial-Intelligence-Research-and-Development-Strategic-Plan-2023-Update.pdf](https://www.whitehouse.gov/wp-content/uploads/2023/05/National-Artificial-Intelligence-Research-and-Development-Strategic-Plan-2023-Update.pdf). Accessed 3 Apr 2024
    
*   Necula, S. (2023). Exploring the impact of time spent reading product information on e-commerce websites: A machine learning approach to analyze consumer behavior. _Behavioral Sciences,_ _13_(6), 439–460. [https://doi.org/10.3390/bs13060439](https://doi.org/10.3390/bs13060439)
    
    [Article](https://doi.org/10.3390%2Fbs13060439)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Exploring%20the%20impact%20of%20time%20spent%20reading%20product%20information%20on%20e-commerce%20websites%3A%20A%20machine%20learning%20approach%20to%20analyze%20consumer%20behavior&journal=Behavioral%20Sciences&doi=10.3390%2Fbs13060439&volume=13&issue=6&pages=439-460&publication_year=2023&author=Necula%2CS) 
    
*   Nguyen, C. (2020). Echo chambers and epistemic bubbles. _Episteme,_ _17_(2), 141–161. [https://doi.org/10.1017/epi.2018.32](https://doi.org/10.1017/epi.2018.32)
    
    [Article](https://doi.org/10.1017%2Fepi.2018.32)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Echo%20chambers%20and%20epistemic%20bubbles&journal=Episteme&doi=10.1017%2Fepi.2018.32&volume=17&issue=2&pages=141-161&publication_year=2020&author=Nguyen%2CC) 
    
*   Nickerson, R. (1998). Confirmation bias: A ubiquitous phenomenon in many guises. _Review of General Psychology,_ _175_(2), 175–220. [https://doi.org/10.1037/1089-2680.2.2.175](https://doi.org/10.1037/1089-2680.2.2.175)
    
    [Article](https://doi.org/10.1037%2F1089-2680.2.2.175)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Confirmation%20bias%3A%20A%20ubiquitous%20phenomenon%20in%20many%20guises&journal=Review%20of%20General%20Psychology&doi=10.1037%2F1089-2680.2.2.175&volume=175&issue=2&pages=175-220&publication_year=1998&author=Nickerson%2CR) 
    
*   Nussbaum, M. (2013). _Political emotions_. Harvard University Press.
    
    [Book](https://doi.org/10.2307%2Fj.ctt6wpqm7)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Political%20emotions&doi=10.2307%2Fj.ctt6wpqm7&publication_year=2013&author=Nussbaum%2CM) 
    
*   Pappas, G. (2014). What difference can “Experience” make to pragmatism? _Symposia. Language or Experience_. [https://doi.org/10.4000/ejpap.322](https://doi.org/10.4000/ejpap.322)
    
*   Pariser, E. (2011). _The filter bubble: What the internet is hiding from you_. Penguin.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20filter%20bubble%3A%20What%20the%20internet%20is%20hiding%20from%20you&publication_year=2011&author=Pariser%2CE) 
    
*   Petrosyan, A. (2023a). Internet usage worldwide – statistics & facts. _Statista_. [https://www.statista.com/topics/1145/internet-usage-worldwide/#topicOverview](https://www.statista.com/topics/1145/internet-usage-worldwide/#topicOverview). Accessed 17 Apr 2024
    
*   Petrosyan, A. (2023b). Number of internet and social media users worldwide as of April 2023. _Statista_. [https://www.statista.com/statistics/617136/digital-population-worldwide/](https://www.statista.com/statistics/617136/digital-population-worldwide/). Accessed 17 Apr 2024
    
*   Poornima, N., et al. (2023). Recommender systems for personalized business marketing: Employing artificial intelligence and business intelligence in machine learning techniques. _Power Engineering and Intelligent Systems_, 325–35. [https://doi.org/10.1007/978-981-99-7216-6](https://doi.org/10.1007/978-981-99-7216-6)
    
*   Reviglio, U. (2017). Serendipity by design? How to turn from diversity exposure to diversity experience to face filter bubbles in social media. _INSCI 2017: Internet Science_, 281–300. [https://doi.org/10.1007/978-3-319-70284-1\_22](https://doi.org/10.1007/978-3-319-70284-1_22)
    
*   Reviglio, U., & Agosti, C. (2020). Thinking outside the black-box: The case for “Algorithmic Sovereignty” in social media. _Social Media + Society_, _6_(2). [https://doi.org/10.1177/2056305120915613](https://doi.org/10.1177/2056305120915613)
    
*   Ricci, F., Rokach, L., Shapira, B., & Kantor, P. B. (2011). _Recommender systems handbook_. Springer.
    
    [Book](https://link.springer.com/doi/10.1007/978-0-387-85820-3)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Recommender%20systems%20handbook&doi=10.1007%2F978-0-387-85820-3&publication_year=2011&author=Ricci%2CF&author=Rokach%2CL&author=Shapira%2CB&author=Kantor%2CPB) 
    
*   Santos, F. P., Lelkes Y., & Levin S. A. (2021). Link recommendation algorithms and dynamics of polarization in online social networks. _Computer Sciences_, _118_(50). [https://doi.org/10.1073/pnas.2102141118](https://doi.org/10.1073/pnas.2102141118)
    
*   Stewart, K. J., & Gosain, S. (2006). The impact of ideology on effectiveness in open source software development teams. _MIS Quarterly,_ _30_, 291–314. [https://doi.org/10.2307/25148732](https://doi.org/10.2307/25148732)
    
    [Article](https://doi.org/10.2307%2F25148732)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20impact%20of%20ideology%20on%20effectiveness%20in%20open%20source%20software%20development%20teams&journal=MIS%20Quarterly&doi=10.2307%2F25148732&volume=30&pages=291-314&publication_year=2006&author=Stewart%2CKJ&author=Gosain%2CS) 
    
*   Suhaim, A. B., & Berri, J. (2021). Context-aware recommender systems for social networks: Review, challenges and opportunities. _IEEE Access,_ _9_, 57440–57463. [https://doi.org/10.1109/ACCESS.2021.3072165](https://doi.org/10.1109/ACCESS.2021.3072165)
    
    [Article](https://doi.org/10.1109%2FACCESS.2021.3072165)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Context-aware%20recommender%20systems%20for%20social%20networks%3A%20Review%2C%20challenges%20and%20opportunities&journal=IEEE%20Access&doi=10.1109%2FACCESS.2021.3072165&volume=9&pages=57440-57463&publication_year=2021&author=Suhaim%2CAB&author=Berri%2CJ) 
    
*   Sunstein, C. R. (2007). _Rebublic.com 2.0_. Princeton University Press.
    
*   Sunstein, C. R. (2009). _Going to extremes: How like minds unite and divide_. Oxford University Press.
    
    [Book](https://doi.org/10.1093%2Foso%2F9780195378016.001.0001)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Going%20to%20extremes%3A%20How%20like%20minds%20unite%20and%20divide&doi=10.1093%2Foso%2F9780195378016.001.0001&publication_year=2009&author=Sunstein%2CCR) 
    
*   Teknologirådet. (2022). _Artificial Intelligence in the clinic – six trends for the health service of the future_. Teknologirådet. [https://media.wpd.digital/teknologiradet/uploads/2023/01/Artificial-Intelligence-in-the-Clinic.pdf](https://media.wpd.digital/teknologiradet/uploads/2023/01/Artificial-Intelligence-in-the-Clinic.pdf). Accessed 3 Apr 2024
    
*   Treanor, B. (2014). _Emplotting virtue: A narrative approach to environmental virtue ethics_. SUNY Press.
    
    [Book](https://doi.org/10.1515%2F9781438451190)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Emplotting%20virtue%3A%20A%20narrative%20approach%20to%20environmental%20virtue%20ethics&doi=10.1515%2F9781438451190&publication_year=2014&author=Treanor%2CB) 
    
*   Turkle, S. (2011). _Alone together: Why we expect more from technology and less from each other_. Basic Books.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Alone%20together%3A%20Why%20we%20expect%20more%20from%20technology%20and%20less%20from%20each%20other&publication_year=2011&author=Turkle%2CS) 
    
*   Ure, M., & Frost, M. (2014). _The politics of compassion_. Routledge.
    
    [Book](https://doi.org/10.4324%2F9781315851389)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20politics%20of%20compassion&doi=10.4324%2F9781315851389&publication_year=2014&author=Ure%2CM&author=Frost%2CM) 
    
*   Westbrook, R. B. (1991). _John Dewey and American Democracy_. Cornell University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=John%20Dewey%20and%20American%20Democracy&publication_year=1991&author=Westbrook%2CRB) 
    
*   Westerwick, A., Johnson, B., & Knobloch-Westerwick, S. (2017). Confirmation biases in selective exposure to political online information: Source bias vs. content bias. _Communication Monographs,_ _84_(3), 343–364. [https://doi.org/10.1080/03637751.2016.1272761](https://doi.org/10.1080/03637751.2016.1272761)
    
    [Article](https://doi.org/10.1080%2F03637751.2016.1272761)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Confirmation%20biases%20in%20selective%20exposure%20to%20political%20online%20information%3A%20Source%20bias%20vs.%20content%20bias&journal=Communication%20Monographs&doi=10.1080%2F03637751.2016.1272761&volume=84&issue=3&pages=343-364&publication_year=2017&author=Westerwick%2CA&author=Johnson%2CB&author=Knobloch-Westerwick%2CS) 
    
*   Yahya, A. H., & Sukmayadi, V. (2020). A review of cognitive dissonance theory and its relevance to current social issues. _Mimbar_, _36_(2). [https://doi.org/10.29313/mimbar.v36i2.6652](https://doi.org/10.29313/mimbar.v36i2.6652)
    
*   Zhang, P., & Kamel Boulos, M. N. (2023). Generative AI in medicine and healthcare: Promises. _Opportunities and Challenges, Future Internet,_ _15_(9), 286–301. [https://doi.org/10.3390/fi15090286](https://doi.org/10.3390/fi15090286)
    