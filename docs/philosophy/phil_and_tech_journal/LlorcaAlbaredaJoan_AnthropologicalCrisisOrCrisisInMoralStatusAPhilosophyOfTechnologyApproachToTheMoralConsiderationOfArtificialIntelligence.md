# Anthropological Crisis or Crisis in Moral Status: a Philosophy of Technology Approach to the Moral Consideration of Artificial Intelligence

**Author:** Llorca Albareda, Joan

**Source:** https://link.springer.com/article/10.1007/s13347-023-00682-z

---

1 Introduction
--------------

The inquiry into the moral status of artificial intelligence (AI) is leading to prolific theoretical discussions (Calverley, 2008; Coeckelbergh, 2012, 2014; Gunkel, 2012, 2018; Llorca-Albareda & Díaz-Cobacho, 2023; Mosakas, 2021; Müller, 2021). A new entity that does not share the material substrate of human beings begins to show signs of a number of properties that are nuclear to the understanding of moral agency in modern philosophy (Floridi & Sanders, 2004; Bostrom & Yudkowsky, 2018; Llorca Albareda, 2023). In the face of this scenario, questions arise such as what properties are necessary to have moral status (Gordon, 2021; Mosakas, 2020; Sullins, 2011); how can we access to these properties (Neely, 2014; Søraker, 2014; Sparrow, 2004); in what sense they are deployed in new artificial entities (Illies & Meijers, 2014); or how real are the forecasts announcing the future appearance of artificial entities as or more intelligent than human beings (Bostrom, 2014; Totschnig, 2019).

The novelty of the question about the moral status of AI, however, does not reside in a resignification of the debates that took place in animal ethics (Gerdes, 2016; Powers, 2013). Animal ethics was the first to propose that the moral consideration of an entity is determined by the possession of certain properties and not by its belonging to a particular species (Hursthouse, 2013; Singer, 1975/2009). However, this approach is based on the idea that to have moral status it is sufficient to be a moral patient, i.e., to have sentience and to be able to be harmed (Singer, 1979/2011). The possession of intellectual qualities associated with adult human beings becomes a secondary criterion that can confer a higher degree of moral status (DeGrazia, 2008; Warren, 1997), but that cannot determine the limits of the circle of moral consideration (Singer, 1983). AI, by contrast, poses a challenge to traditional conceptions of moral agency rather than moral patiency (Floridi & Sanders, 2004), since current technology is a long way from being able to construct sentient artificial beings (Véliz, 2021). The recent development of AI is leading to the view that humans are no longer the only entity capable of such intelligence and rationality as to deliberate morally (Nadeau, 2006).

However, both the discussions on the moral status of animals and those on the moral status of AI start from the following reasoning (Coeckelbergh, 2012):

*   P1. An individual X has moral status if and only if she possesses property Y.
    
*   P2. X can possess property Y.
    
*   C1: X can have moral status.[Footnote 1]
    


AI can have moral status if and only if it possesses the defining property of moral agency, whether this is consciousness (Himma, 2009), internal life (Nyholm, 2020), or intentionality (Powers, 2013). These properties are those that have traditionally characterized human beings. John Danaher (2019a) expresses this idea by pointing to the _civilizational crisis_ that can result from the massive implementation and development of AI: what defines human beings, their capacity for agency, is undermined by new artificial entities, due to the fact that they will occupy the domains in which humans were previously able to exercise this capacity. However, the undermining of moral agency is presented in the literature on the moral status of AI in another sense, namely, the fact that artificial entities can acquire these kinds of properties calls into question the very definition of being human. The properties that humans exclusively possessed in the past are now shared by other types of entities (Tegmark, 2018). This is why it can be understood that the advent of AI has provoked the foreboding that we are at the gates of an _anthropological crisis_ (Brey, 2014; Bryson & Kime, 2011). The great oppositions on which the idea of the human was sustained have been collapsing throughout history (Mazlish, 1993) and we are now witnessing the fall of the last of the exclusions, that which separates the objectual and artifactual world from the human world (Haraway, 1985/2006; Latour, 1993).

This article will argue that this is an alleged anthropological crisis. The debate on the moral status of AI starts from this crisis when it comes to articulating the theoretical positions that enter into the discussion: either new properties are proposed that account for a new definition of the human being or it is admitted that there are no significant differences between human beings and AI—in the case that the latter would have such properties. However, this debate departs from a questionable anthropological premise: human beings are defined by having property X. Discussions about new AI systems and their resemblances with human beings have set aside an array of anthropological models that had developed in parallel with the advance of technologies and that challenge the declared state of emergency of contemporary reality. It abruptly separates again the human being from technologies and abandons the questioning of the relation between the two and their capacity for hybridization (Latour, 1993; Verbeek, 2005). The task of the article will be to show, from history and philosophy of technology, that it is possible to conceive other ways of understanding the human being and its relation with technology. To this end, six anthropological models will be proposed based on three criteria of analysis: traditional anthropology, industrial anthropology, phenomenological anthropology, postphenomenological anthropology, symmetrical anthropology, and cyborg anthropology. Then, it will be argued that the history and philosophy of technology leads us to take into consideration the relational dimensions of anthropology and that this idea has very important effects on the debate about the moral status of AI.

2 Technological Anthropology
----------------------------

Arnold Gehlen argued that once human beings had displaced nature, their opposite, they would turn their gaze back on themselves (1988). The blurring of the barriers between nature and the human calls into question the construction mechanisms of the concept of humanity: its properties, constructed by virtue of the exclusion of something that is not itself, cease to differentiate it from its opposite (Haraway, 1985/2006). Therefore, when these demarcation criteria cease to function, she begins to wonder about herself, about the reasons by virtue of which she can be classified as a human being. And this is precisely what happens with AI: the artifactual world ceases to be that to which the human being is opposed and begins to question that which was understood as human.

This anthropological crisis reveals the underlying assumptions of the relation between human beings and technologies that encapsulate the debate on the moral status of AI. It is assumed that the human being is such because of a series of properties that she possesses. If these do not work, others must be proposed. If they remain inadequate, a more exhaustive catalog of properties must be provided. If they still remain inadequate, it must be admitted that there are no properties that allow us to meaningfully differentiate human beings from AI. At no point is it questioned that the human being should be characterized as an entity defined through certain properties (Coeckelbergh, 2012; Gunkel, 2012).

Nevertheless, philosophy of technology throughout the twentieth century, although it has lacked an exhaustive anthropological investigation, has provided an insight into the relations that can be maintained with technologies and how these relations generate fracture lines that reject the radical separation between the artifactual and the human world. Our aim in this section is to develop the various anthropological models that can be derived from philosophy of technology. Their rationale lies not only in the theoretical originality of the cited authors, but also in the type of concrete relations that occurred with the introduction of new technologies.[Footnote 2]

Where do these models come from? Many philosophers of technology have simply chosen to distinguish instrumentalist conceptions from substantivist ones (Feenberg, 1991; Mitcham, 1994/2022; Rapp, 2012). I consider, however, that this distinction is insufficient and that we need more analytical criteria. I will introduce the anthropological gradient and the concrete relations with technologies, in addition to the already noted conceptions regarding technology. Each of them can be considered as a philosophical dimension of technologies: ontological, epistemic, and practical. Once crossed with each other, we obtain six anthropological models (Table 1).

**Table 1 The anthropological models derived from philosophy of technology. They have been obtained through three anthropological criteria: anthropological gradient (ontological dimension), conceptions regarding technology (epistemic dimension), and concrete relations with technology (practical dimension)**

### 2.1 Three Anthropological Criteria

#### 2.1.1 Anthropological Gradient

We will call the _continuum_ of equivalence/difference between human beings and technologies the anthropological gradient. It refers to the ontological dimension of the relation between human beings and technologies, since it categorizes the type of reality of both entities, to what extent they are the same or different, and what type of (cor)relations can occur between them.

It is precisely this dimension that Peter-Paul Verbeek (2008a, 2011), pp. 139–152) claims against Don Ihde (1990). Verbeek surreptitiously introduces an anthropological question of the greatest relevance. One of the innovative intuitions of Ihde (1979, 1990) consists in transferring the phenomenological notion of intentionality to the use of technologies. "It is only through the transformation which the instrument effects, that features which may be noted to be genuinely emerge. Phenomenologically speaking, the instrument allows new noematic features to arise within the horizon of perceptual experience" (1979, p. 22). Human intentionality is profoundly affected by the mediations effected by technologies, introducing fundamental changes in the forms of perception. A blind man's cane (Merleau-Ponty, 1945/2013) or a dentist's dental exploratory probe (Ihde, 1979) are not mere prostheses, but determine the way the world is perceived. Verbeek argues that the figure of the cyborg challenges this notion of intentionality, since an instrument of partial use and clearly differentiable from the subject that makes use of it is not the same as an instrument that becomes part of a biological body. In the former, the relation is one of quasi-transparency (Ihde, 1990), while in the latter transparency is total (Verbeek, 2005).[Footnote 3] Therefore, before determining the relation that the human being has with the world, it is necessary to determine the ontological continuity or discontinuity between the human being and technologies.[Footnote 4]

Assuming the importance of the new question introduced by Verbeek, I propose four types of ontology of the relation between the human being and technologies:

*   Human being ≠ technologies. These are two ontologically distinct entities with no strong connections between them.
    
*   Human being → technologies. The human being is the focus of intentionality, but she perceives reality mainly through technologies, namely, technologies condition the way he perceives reality.
    
*   Human being ⇆ technologies. The human being is no longer the focus of intentionality nor the ontologically prioritized entity in the relation with technologies. The relation is one of co-determination (Verbeek, 2005), that is, both are transformed in their reciprocal interaction.
    
*   Human being = technologies. The human being and technologies are ontologically indistinguishable, that is, there are no defining properties that distinguish one entity from the other.


#### 2.1.2 Conceptions Regarding Technology

The most common classifications of philosophy of technology have tended to distinguish instrumentalist conceptions from substantivist ones. Both positions answer the following epistemological question: how should we understand technologies? According to Andrew Feenberg (1991), pp. 5–7), instrumentalism is based on four basic premises: _(i)_ technologies are indifferent to the various purposes for which they can be used; _(ii)_ technologies are indifferent to politics and in no case can the artifact be understood as a particular political construct; _(iii)_ technologies can only take place in the light of knowledge of the universal laws of nature, so their character is neither particular nor contingent, but has a degree of generality that surpasses concrete contexts and individual intentions (Rapp, 2012); _(iv)_ technologies, being products of the universality of science, can be applied to different fields without undergoing substantial modifications (Ellul, 2021). Martin Heidegger (1954/2013) was one of the first to stress that the instrumentalist view of technologies derives from conceiving technologies as applied science: human beings elaborate hypotheses and theories that are materially applied in the form of technologies.

However, both Heidegger and many other authors have argued that technologies have much more profound effects on human beings. Before we theorize about the world, we already have a practical relation with technologies.[Footnote 5] This makes technologies have a much more substantive influence. Technologies incline, both perceptually and existentially (Verbeek, 2005, 2011), human beings in different ways, which makes it impossible to understand them as neutral objects and procedures (Coeckelbergh, 2022). They embody ways of life and values that affect us distinctively (Ihde, 1990).

The problem with the division between instrumentalism and substantivism lies in the fact that the specificities of the latter are not usually attended to. The classical philosophy of technology (Ellul, 2021; Heidegger, 1954/2013, 1927/2010; Mumford, 1934/2010) has understood the question of substantivity in transcendental terms, hence many later authors have subsumed their approaches under the transcendental philosophy of technology (Schuurman, 1980; Verbeek, 2005). The meaning of technologies in the classical positions resides in their conditions of possibility, that is, there is a Technology that possesses a sort of essential or primary structure that determines human behavior in a total way. Fatalistic views of technology that understand modern technology as a uniform and monolithic rationality can also be introduced in this position (Marcuse, 1964/2013; Weber, 1920/1993).

But not all authors who have defended the non-neutral character of technologies have opted for this type of approach. Many of them understand that technologies have profound effects on human beings, but that their influence is ambiguous and depends on certain characteristics of their inner workings (Ihde, 1979; Verbeek, 2005) and/or the social relations in which they are imbued (Feenberg, 1999; Winner, 1986/2010).[Footnote 6] Albert Borgmann (1987) has fully grasped these differences and proposed a new category of analysis: _pluralism_.[Footnote 7] This position highlights the ambiguity inherent to technologies and how they can embody different values. I will introduce, however, a further distinction, which distinguishes weak pluralism from strong pluralism. _Weak pluralism_ argues that technologies are human constructs that, by virtue of the design that is intentionally developed, may embody some values or others (Friedman et al., 2013) while _strong pluralism_ highlights the impossibility of completely controlling those inclinations of action and perception of technologies because of the diversity of contexts of use and the subtleties of their internal structure (Verbeek, 2008a, 2011).


#### 2.1.3 Concrete Relations with Technologies

In the last quarter of the twentieth century we witnessed, within the philosophy of technology, an empirical turn (Achterhuis, 2001). Philosophers of technology stop asking themselves about the spirit of modern technology (Ellul, 2021) or about the mode of revelation of technologies (Heidegger, 1954/2013) and start analyzing the inner workings and use of concrete technologies.[Footnote 8] This interest in particular technologies allows a much more exhaustive analysis of technological possibilities: it discloses aspects of technologies that remained hidden in generalist discourses on technical rationality. The main exponents of the empirical turn claim the need to capture the concrete and pragmatic aspects of the use of technologies in order to escape from the previous transcendentalism (Ihde, 2009).

One of the philosophers who has most emphasized the need to study in depth the concrete relations between human beings and technologies is Don Ihde. He uses the phenomenological method to account for the fact that the correlation between the object experienced (_noema_) and the act of experiencing (_noesis_) is produced through the use of technologies. Human beings, since primitive times, intentionally direct themselves towards the world by means of artifacts. Ihde therefore sets himself the task of showing to what extent experience is mediated by technologies and to what degree they convey our perceptions and interpretations. In _Technology and the Lifeworld_ (1990),[Footnote 9] he proposes four types of relations with technologies: embodiment relations, hermeneutic relations, alterity relations, and background relations. All of these must be understood within a _continuum_ rather than discretely.[Footnote 10]

First, _embodiment relations_ are those in which technology acts as an extension of bodily perception. The artifact is withdrawn from the user's attention and felt by the user as a part of her perceptual organs.[Footnote 11] Thus, this type of relation is based on quasi-transparency, i.e., the object is withdrawn from direct perception, but, at the same time, it can never be completely equal to bare perception.[Footnote 12] Ihde formulates them in these terms_: (human—technology) → world_.

Secondly, _hermeneutic relations_ are those we maintain with artifacts that, despite not being extensions of our perception, refer to an aspect of the world that lies beyond them. Ihde (1990) gives the example of a thermometer, an object with which we confront directly, which we must interpret according to a certain language and which refers to an aspect of the world (temperature) that is outside itself. He uses the following formula: _human → (technology—world)_.

Thirdly, _alterity relations_ are those that we maintain with artifacts as Others: entities alien to each of us that do not refer to a reality external to themselves but constitute in themselves a mystery. These types of relations are never fully complete with technologies (Ihde, 1990) because there always remains a residue of their artifactuality, but, in spite of this, they can awaken in us emotions of love and friendship (Turkle, 2011). Ihde formulates it as follows: _human → technology (- world)_.

Fourth, _background relations_ are those that form the backdrop of direct relations between humans and technologies. We do not notice them in the course of our daily lives, but they form the stage on which the rest of the relations develop. The thermostat, with its associated functions and sounds, is a good example of technologies that can be placed in the background of human experience. Ihde the formula as follows: human _(- technology—world)_.


### 2.2 Anthropological Models

#### 2.2.1 Traditional Anthropology


AI can have moral status if and only if it possesses the defining property of moral agency, whether this is consciousness (Himma, 2009), internal life (Nyholm, 2020), or intentionality (Powers, 2013). These properties are those that have traditionally characterized human beings. John Danaher (2019a) expresses this idea by pointing to the _civilizational crisis_ that can result from the massive implementation and development of AI: what defines human beings, their capacity for agency, is undermined by new artificial entities, due to the fact that they will occupy the domains in which humans were previously able to exercise this capacity. However, the undermining of moral agency is presented in the literature on the moral status of AI in another sense, namely, the fact that artificial entities can acquire these kinds of properties calls into question the very definition of being human. The properties that humans exclusively possessed in the past are now shared by other types of entities (Tegmark, 2018). This is why it can be understood that the advent of AI has provoked the foreboding that we are at the gates of an _anthropological crisis_ (Brey, 2014; Bryson & Kime, 2011). The great oppositions on which the idea of the human was sustained have been collapsing throughout history (Mazlish, 1993) and we are now witnessing the fall of the last of the exclusions, that which separates the objectual and artifactual world from the human world (Haraway, 1985/2006; Latour, 1993).


### 2.2 Anthropological Models

#### 2.2.1 Traditional Anthropology

Traditional anthropology starts from the Cartesian premise that there is a radical separation between the _res cogitans_ and the _res extensa_. The human being is the mental substance endowed with reasoning, while everything that does not belong to this category is explained on purely mechanistic grounds. She can make use of tools and instruments as she pleases, even more so if she knows the laws of nature that mediate her actions. The ends and values of technologies depend entirely on human beings. This is why the ontological fracture between the two types of entities is total: human beings are capable of freedom and autonomy while instruments are nothing but an indeterminate mass to be shaped (Verbeek, 2011).

This makes technologies mere instruments that can be used for one purpose or another, since everything that acts as a mediator between the human being and her utility will be conceived as a technical instrument. Hence, for Aristotle (2004, 432a1) even the hand itself is conceived as the "instrument of instruments". This bodily analogy provides us with a very relevant key: technical instruments are understood under the paradigm of organ substitution and surpassing (Gehlen, 1988). Namely, the body is incapable of doing something under its own means and then it externalizes in the form of technique. This perspective derives from the concrete use of technical tools. Ihde (1979) already indicated that this is precisely the characteristic of embodiment relations, in which the relation of quasi-transparency makes the object mediate with hardly any difference to the bare perception of things. This particular type of relation to techniques constitutes a central feature of the pre-industrial era, since a unitary conception of technique was lacking (Dessauer, 1927). Techniques are understood as concrete tools used for certain activities and under certain conditions of use. Technique is neither a driving force of human development (Ellul, 2021, Mumford, 1934/2010) nor a mode of revelation (Heidegger, 1927/2010), but is understood as concrete and separate instruments that are used for the benefit of human beings.


#### 2.2.2 Industrial Anthropology

Industrial anthropology takes this name because of the historical transformations that have taken place in technology (Mumford, 1934/2010). And by this we are not referring to the relevance of the machine within the contemporary technical framework,[Footnote 13] but to the fact that technique has become a unitary force (Dessauer, 1927) and a form of rationality that is deployed in the different social spheres (Ellul, 2021). They are no longer a set of instruments that each man uses as tools to be used in certain activities directed towards an end. On the contrary, technology is an interweaving and inescapable context that shapes the curvature of contemporary societies (Ihde, 1990).


It is in this sense that background relations are claimed to be the fundamental aspect of this type of anthropology. The first philosophers of technology question the abstract and technified nature of life, its difference with respect to traditional techniques, and the degree to which technology determines humanity. Although they keep in mind embodiment relations, their main interest lies in accounting for the technification of life that occurred within the framework of the industrial societies of the twentieth century. However, the approaches to this phenomenon are not univocal and we can distinguish two typologies inspired by the difference proposed by Carl Mitcham (1994/2022) between philosophy of engineering and continental philosophy of technology.


On the one hand, philosophy of engineering pursues a philosophical explanation of the act of engineering creation (Mitcham, 1994/2022). They try to analyze how the pre-existing idea in the mind of the engineer is connected with the finished product after the process of technical transformation. The greatest exponent of this position is Friedrich Dessauer (1927). Dessauer understands technique in a unitary manner as a process that, although individualized in each creator, occurs universally. Each creator starts from an ideal form that, after going through the technical disquisitions, ends up materializing in the sensible world. He proposes a fourth Kantian critique, one that understands technology transcendentally: this act of creation unites us with the divine, since connects the ideal forms whose origin is unknow for us with the material forms experienced by our sensibility. Technologies, therefore, are understood as instruments that make it possible to establish a bridge between the divine and the human, although they lack autonomy.

On the other hand, continental philosophy of technology takes background relations in a problematic manner: technologies are forces that determine human activity and induce certain forms of behavior and understanding that escape truly human ends. Thus, it is a matter of analyzing what are the conditions of possibility of technologies and their implications with determining force in human doing (Verbeek, 2005). In this position we could find Jacques Ellul (2021), Lewis Mumford (1934/2010), and Martin Heidegger (1927/2010).

Both should be understood as transcendental approaches to technologies: what should be studied are not concrete technologies, but how these, unitarily, determine human behavior due to their essential features (Schuurman, 1980; Verbeek, 2005). However, the difference in their approaches lies in the fact that the former understands technologies as instruments and the latter substantively. This distinction makes it difficult to offer a univocal anthropological gradient. Philosophy of engineering maintains the ontological fracture of the previous typology, but the substantivist approach is more varied in its approaches. While the latter position argues that technologies are not neutral, this does not mean that humans and technologies are not different realities. Mumford and Ellul make efforts to establish major differences between one and the other. Heidegger, on the contrary, does outline a first phenomenological interpretation of technologies (Ihde, 1979; Verbeek, 2005).


#### 2.2.3 Phenomenological Anthropology

Although Heidegger can be considered the first phenomenological approach to the problem of technology, it is not until Don Ihde that a phenomenological anthropology of technology can be traced. And this is mainly due to Ihde's empirical turn (Achterhuis, 2001): the phenomenological invariant is not to be sought in Technology, understood as a driving and unifying force that (un)conceals a certain conception of the world, but in the study of the concrete relations with technologies, which hardly show univocal but multistable relations (Ihde, 1979, 1990). Only in this way can it be comprehended that Husserlian intentionality is traversed by technologies. Although the focus of intentionality is on human beings, this concept cannot be well understood if we do not analyze to what extent each concrete technology simultaneously broadens and narrows the direct perception of reality. In this sense, human beings are no longer simply influenced by the historical current of technology, nor do they barely use it as an instrument for their ends; on the contrary, the way in which they experience the world is technological (Ihde, 1990). Once the technological character of human experience is recognized, it is impossible to conceive of humans in the same manner. Technology is no longer something that we use for our ends or an encompassing rationality, but a particular entity that completely transforms how do we perceive the world. The human being and technologies are ontologically distinct entities, but they are phenomenologically correlated as the latter mediates all human experiences.

The empirical nature of the phenomenological relation makes its conception regarding technologies completely distinct. Technologies are also not neutral, but in a different manner. First, because not all technologies transform human intentionality in the same way (Ihde, 1979; Verbeek, 2005). A blind man's cane, for example, modifies perception in a different manner than a microscope does. The former broadens tactile capabilities while the latter enhances vision. Both limit reality to certain aspects of perception—to the tactile or visually perceptible. Secondly, because these perceptual changes are not univocal in each of the specific technologies. This is explained by the fact that two levels of analysis can be distinguished: the microperceptual level and the macroperceptual level (Ihde, 1990). On the one hand, the microperceptual dimension refers to the internal structure of each technology, i.e., to what extent human perception is transformed by the specific technical operations and how these are adapted to the structures of perception. On the other hand, the macroperceptual dimension refers to the large interpretative frameworks at the social level that invite to understand the phenomenological relation under certain parameters (Feenberg, 1991, 1999). This is precisely what multistability consists of, namely, it explains why a reality can be seen in different ways depending on the interpretative frameworks from which one starts. This accounts for the intimate connection between the two dimensions: the microperceptual dimension informs and conditions the macroperceptual dimension and vice versa.

Thus, this anthropology leads to a pluralistic view of technologies, i.e., technologies can embody different values according to their internal structure and external context. Both strong pluralism and weak pluralism have a place here depending on whether technologies are seen as embodying human values that are previously designed (Friedman et al., 2013) or whether technologies are understood to mediate in ways that are distinct and impossible to capture in their entirety (Ihde, 1979, 1990). And this diversity of values can be understood through different concrete relations with technologies, by reason of the empirical turn that separates them from transcendentalism. Hence, Table 1 includes embodiment relations, hermeneutic relations, and background relations.


#### 2.2.4 Postphenomenological Anthropology

The birth of the concept of postphenomenology must be framed in the intellectual trajectory of Don Ihde (Ihde, 2003; Selinger, 2006). The first time he explicitly used this term was in his _Postphenomenology: Essays in the Postmodern Context_ (1993) although he had previously surreptitiously introduced it in _Consequences of Phenomenology_ (1986). His aim was to overcome the shortcomings of classical phenomenology, mainly because of its aspiration to be the only true approach to reality, instead of using phenomenological tools to account for the diversity of ways of experiencing it technologically (Ihde, 1990).

Although Ihde was the initiator and the promoter of postphenomenology, he did not quite carry the innovations of this new position to their ultimate consequences. His anthropology still continued to have a unidirectional character, i.e., the human being is the focus of intentionality and technologies transform the way we perceive the experienced object (Verbeek, 2005). This shows in what sense Ihde places much emphasis on _noesis_ and little on _noema_. Technologies seem to play a passive role with respect to human beings, that is, they do not seem to transform them in meaningful ways, carrying specific intentionalities that profoundly impact human modes of intentionality.

Peter-Paul Verbeek (2005) has succeeded in radicalizing the presuppositions of Ihde's postphenomenology and presenting a postphenomenological anthropology. The relation between human beings and technologies must be one of co-determination, i.e., technologies are an active component and shape the reality of human beings. Not only are human beings focus of intentionality and are directed to the world through technologies, but also technologies are directed to the world in a certain way. Thus, we no longer find ourselves with distinct realities that are connected through the unidirectional effects of human intentionality, but rather both entities, although distinct, shape each other reciprocally.

This forces us to conceive technologies in a pluralistic manner. They all contain values and can channel the experiences of human beings in certain ways. But not simply in ways that are ancillary to the object of intentionality; rather, they profoundly transform what human beings are and the ways in which they experience the world. This pluralism, therefore, is always strong, because, due to their active role, human beings are hardly behind their conditioning. Moreover, like the previous anthropological model, because of the concreteness of the analysis and its strong roots in Ihde's methodology, it is able to account for a wide range of concrete relations: embodiment, hermeneutic, and background.


#### 2.2.5 Symmetrical Anthropology

One of the most important influences for Peter-Paul Verbeek is Bruno Latour. Although the former tries to fit phenomenology into the thought of the latter (Verbeek, 2005) Latour's rejection of this philosophical position is considerable:


> The phenomenologists have the impression that they have gone further than Kant and Hegel and Marx, since they no longer attribute any essence either to pure subjects or to pure objects. They really have the impression that they are speaking only of a mediation that does not require any pole to hold fast. Yet like so many anxious modernizers, they no longer trace anything but a line between poles that are thus given the greatest importance. (Latour, 1993, p. 58)


Phenomenology is still anchored in the subject-object schema, which prevents it from fully grasping the ways in which technologies act and modify human environments. Humans and technologies are one and the same entity (Latour, 1992, Latour & Weibel, 2005), they are actants that are part of networks (Latour, 1999). They lack any property that anchors them as a certain entity. On the contrary, these properties are the result of their position within the networks, in which they configure and are configured by the rest of the actants. Speed bumps that restrict the speed of cars, for example, have a type of agency that profoundly affects the actions performed by human beings (Latour, 1999). Symmetrical anthropology, therefore, is one that does not freeze the image of the poles of human relations—subject/object, human/non-human, natural/social—, but rather accounts for how they come to be formed as such poles in their interactions through networks (Latour, 1993). The reality of which they are part is the same, it is the reality of networks (Latour, 1999).

The conception regarding technology that derives from Latour's position is a strong pluralism: all technologies configure and shape the rest of the entities with which they interact, in the same way that human beings do. It is, in fact, even stronger than Verbeek's, because the barriers placed to their interaction go beyond the subject-object schema. The consequences of this approach force us to rethink the concrete relations with technologies, since embodiment and hermeneutic relations are no longer adequate. Their adequacy depended on human perception being at the center of technological experience, either as an extension of direct perception or as an objectual reference to be interpreted. However, for Latour all are background relations, as these networks occur beyond the position occupied by human consciousness with respect to the objectual world (Latour, 1993).


#### 2.2.6 Cyborg Anthropology

The possibilities offered by AI have completely altered our relations with technologies. Latour's insistence on hybrid entities, which could not be recognized as either human or non-human, has reached its maximum historical realization: whether they are technological extensions of human beings or whether they are entities with a silicon substrate that are capable of being as or more intelligent than human beings, hybrid individuals are beginning to become a reality. This forces us to rethink what the human being is, what intelligence is, or what the future of humanity will be. And these are precisely the questions I referred to at the beginning of the text, those that dispute what a human being is and who should fall into this category.


The debate on the moral status of AI has focused its efforts on asking this question. The fundamental intuition of these discussions is summarized in this sentence by Nick Bostrom and Eliezer Yudkowsky: "While it is generally agreed that present-day AI systems lack moral status, it is unclear exactly what attributes ground moral status" (2018, p. 61). This time we are no longer looking for attributes that separate humans from technologies, but, on the contrary, we are looking for technologies that are human enough not to be considered purely mechanical entities. Cyborg anthropology equates humans to AI technologies as long as they pass the established criteria. There is thus no longer an ontological separation between humans and technologies, but between different types of technologies.


The consequences of this are visible: technologies that lack moral consideration because they do not meet these properties become mere instruments, slaves to human ends (Bryson, 2010). However, those that do pass the threshold are fully human and thus should be treated in the same way as human beings: as alterities that deserve respect regardless of the plurality of actions they perform and beliefs they hold. Alterity relations were theorized by Don Ihde (1990) although he gave them little importance, conceiving it simply as one end of the _continuum_ of human relations with technologies.[Footnote 14] AI, however, poses a profound transformation: it can be possible for technologies to become fully an Other, not a machine designed and directed by another human being. This completely changes our relation with technologies and, at the same time, our conception of the human being.


3 Contesting Moral Status
-------------------------


### 3.1 The Relational Dimension of Technologies


The anthropological models presented above have not been randomly ordered.

 The order of appearance has an historical and a conceptual root.

 The first refers to the fact that any philosophy of technology is deeply dependent on the social context in which it arises (Rapp, 2012), so that the explicitness of the relations between human beings and technologies conditions the type of theories that are developed on these relations.

 The second refers to the fact that, as we advance in previously, anthropological models give progressively greater weight to the relations between human beings and technologies (Achterhuis, 2001).


 Except cyborg anthropology, these models are increasingly emphasizing the relation between humans and technologies, rather than radically separating them.

 In this section, I will show that both planes converge in their analyses and have parallel developments: the history of technology reports a socio-technical context in which the human and the technological are increasingly intertwined, while philosophy of technology pays greater attention to the actual and potential relations between humans and technologies.

 Awareness of this situation will force us to rethink the weight of the relational dimension of technologies in the debate on the moral status of AI.


 The first dimension leads us to what I will call the _historical argument_.

 This type of argument has been used on numerous occasions in debates about moral status (Gunkel, 2012, 2018; Stone, 1972/2010) in order to account for the progressive process of inclusion that has taken place within the circle of moral consideration.

 More and more entities are part of it and the last barriers of exclusion are exhausting their containment forces (Haraway, 1985/2006).

 The moral progress that takes place throughout history will result in all morally considerable entities entering the margins of moral status.

 However, this argument has been widely criticized (Gerdes, 2016; Mosakas, 2020, 2021; Müller, 2021; Nyholm, 2020) due to its factual nature: that the circle of moral consideration has progressively expanded over time tells us nothing about that this expansion should be normatively defended.

 The plane of being is confused with the plane of ought to be.

 This confusion leads to turning moral status into the result of an arbitrary judgment that depends on the affinities and connections that those making the judgment have with the entity in question.


 The use of the historical argument in our case has a different purpose.

 It will not be argued that because history has been running in a certain way, the course of events must follow the same trend.

 On the contrary, it will be argued that the history of technologies offers us two reasons why ignoring the relational dimension of technologies is a mistake.

 These reasons are based on Jacques Ellul's (2021) concept of enchainment of techniques and on Bruno Latour's (1993) concepts of purification and mixing.


 First, Jacques Ellul understands _the enchainment of techniques_ as the process in which modern technologies reveal their profound interconnection and interdependence.

 This is not to be confused with technical uniqueness and universalism, whose meaning, Ellul argues, derives from the uniformity of its principles and the equivalence of its manifestations; techniques are enchained because their functioning is only possible within the framework of the set of relations between particular techniques.

 Lewis Mumford (1934/2010) has defended a very similar idea with the passage from the paleotechnical era to the neotechnical era.

 While the former was characterized by an empire of disorder in which technical advances took place through individual and fragmentary efforts that fled from systematic knowledge, the latter is characterized by avoiding the automatic growth of technique by making use of a body of knowledge that emphasizes the interrelationship between different techniques.

 This means that contemporary technologies must be understood as a socio-technical system.

 A brief example will clarify this concept (Johnson & Noorman, 2014).

 If we think of a refrigerator, the first thing that will come to mind will be those properties or characteristics that differentiate it from other technologies: it cools and preserves food so that individuals can eat it in good conditions.

 However, a more thorough analysis will highlight that a refrigerator can only work if the set of technologies to which it is related work as they should.

 The refrigerator only works when it is connected to the power supply, which includes the proper functioning of the socket, the network of wires that carry it, and the power plant from which the energy comes.

 But the complexity of contemporary technologies highlights not only the interlinkage between them, but also the relations that must exist between them and human beings in order for them to function properly.

 For the refrigerator to fulfill its function, consumers must behave in certain ways, the technicians in charge of its installation must do so without errors, as must those in charge of the maintenance of the power plant.


 In this sense, the history of technology reveals not only the contemporary interlinking of technologies, but also their intimate connection with what human beings do.


 This brings us, in the second place, to the concepts of _purification and mixing_, expounded by Bruno Latour.

 If contemporary technologies, because of their enormous complexity, must always be understood within the framework of a technical system, the role that human beings play in these relations between technologies must not be overlooked.

 And this has not taken place due to the particular disposition in which contemporary technology finds itself.

 Both Ellul (2021) and Mumford (1934/2010) emphasized that technique has been developed to such a high degree thanks to its new autonomy: technical products no longer depend on the individual genius of the producer but are to a greater extent products of the inertia of a compact technical system.

 The technical sphere is purified of those elements that are not technical in order to allow its better development.

 That is to say, the enormous development of the socio-technical system can only occur when human affairs cease to intervene in strictly technical criteria.

 This process is what Latour calls purification.

 Latour points out, however, that the purification processes of modern technology have given rise to a profound paradox: while the exercise of separation between human activities and technical activities has led to technologies becoming enormously complex, their gigantic development has shown that the technical system is always imbued with human affairs.

 A simple glance at the newspaper shows, according to Latour, how the enormous development of technology has led to a proliferation of mixtures and hybrids: entities that one does not know whether they should be treated technically or humanly, since they can be considered on both planes.

 Cyborgs, synthetic biology or highly intelligent artificial systems are examples of this type of entities that are human and technical at the same time.


 Modern technology has highlighted, firstly, the necessary linkage between different techniques and, secondly, the progressively intimate relation between human beings and technologies followed by technological development. This leads us to raise a paradox that runs through all the debates on the moral status of AI.


> _The paradox of the relation between humans and technologies in the age of AI_: At the historical moment in which humans and technologies are most deeply intertwined and whose relations are increasingly visible, the relation begins to lose weight in philosophical analysis with the emergence of highly intelligent artificial entities.


 The new AI, by virtue of possessing a number of properties traditionally linked exclusively to human beings, begins to distort the image of human beings.

 The properties that have always characterized humanity can be possessed by another entity and, therefore, there are doubts as to whether these properties are really the ones that define them.

 However, the renewed interest in the defining properties of anthropology forgets the lessons of the history of technologies, which shows that technologies, on the one hand, are not mainly defined by themselves, but by the relations they maintain among themselves; and, on the other hand, that the relations that define them are not only technical but are also anchored in the relations maintained between human beings and technologies.

 And this is precisely the conceptual shift: contemporary philosophies of technology have taken these historical teachings and incorporated the relational dimension of technologies in their analyses, as shown in the previous section.

### 3.2 The Relational Dimension of Morality

The concept of moral status was born in the second half of the twentieth century within three debates in applied ethics: abortion, animal ethics and ecological ethics (Hursthouse, 2013). Its theoretical novelty consisted in raising the possibility that some non-human entities could be considered morally in their own right (Jaworska & Tannenbaum, 2023; Kamm, 2008). Animals, for example, should be morally considered because they possess certain properties that demand an impartial consideration of their interests (Singer, 1979/2011). Humans are no longer the only entity deserving of moral consideration because, in contrast to the ancient anthropocentric prejudices, moral consideration can only be founded on impartially determined properties that are not subject to membership of a certain species or collective (Singer, 1975/2009).

To understand that the moral consideration of an entity is always produced by the identification of a series of properties and characteristics that it possesses is problematic. David Gunkel (2012, 2018) and Mark Coeckelbergh (2012, 2014) argue that moral life usually works the other way around: we do not first identify properties of entities and then treat the latter according to whether or not they possess the former, but rather we first relate to entities and already then grant them certain properties. Many philosophers of technology have followed a similar reasoning to account for our relations to technologies. Martin Heidegger (1927/2010) argues that we do not use and treat tools according to the properties they possess, but that they simply are used pragmatically, and we relate to them according to certain horizons of understanding that we do not pay attention to. Don Ihde (1979) defends the same viewpoint and adduces that before we theorize scientifically about the world we already make use of instruments and tools in our practical life.


 The anthropological models presented in the preceding section show the need to take into consideration the relational dimensions of morality and technologies.


 The anthropological models presented in the preceding section show the need to take into consideration the relational dimensions of morality and technologies. If technologies are not simply isolated artifacts, endowed with a series of properties that define them, but are nodes in networks of relations in which they derive their meaning (Latour, 1999), and morality does not consist only in the identification of relevant moral properties, but these are constructed through the relations between entities (Coeckelbergh, 2012); then the moral relevance of technologies should pay special attention to the relations between humans and technologies and see in what ways these relations are moral. Let us show this through two examples.

The first was raised by Peter-Paul Verbeek (2008b, 2011): obstetric ultrasound. This technology gives prospective parents the possibility of being able to see the state of the fetus through a digitized image. It could be described through its technical properties: it is a technology that determines the presence or absence of pregnancy by means of ultrasound waves emitted by a transducer; all this is translated into a visual image seen by medical professionals and prospective parents. However, this is not all that can be said about obstetric ultrasound. The image of the fetus, at a size similar to that in the uterus, arouses affection and emotion in the parents-to-be. In addition, this technology is often used to identify pathologies, so that the fetus is beginning to be understood as an entity susceptible to be damaged. This technology, in this sense, introduces moral aspects in the perception of the fetus. The type of perception of this entity alters the way we understand it and has important moral consequences.

The second was exposed by Lucas D. Introna (2014), pp. 41–48): technologies linked to computerized writing. These technologies could be understood as a simple transposition of traditional modes of writing on computer devices. Their effects, however, produce profound changes in the way we write. First, the new forms of writing substantially change the ways in which the author relates to the text. Computerized writing tends toward rapid writing, susceptible to erasure and reworking, in contrast to the thoughtful and well-reflected traditional writing that requires its content and form to have been clearly defined. Secondly, the possibilities of plagiarism have multiplied in the face of the enormous number of writings and documents to which the author has access. This has led to the development of anti-plagiarism programs such as Turnitin that distinguish what is plagiarism from what is not. This is why these technologies, on the one hand, identify plagiarism—a phenomenon that was not previously well-defined and demarcated— and, on the other hand, present technological solutions that define how we should understand plagiarism. Other important effects are those that take place in authors writing in a non-native language, who use more sentences attached to basic structures and common vocabulary that are susceptible to being recognized as plagiarism; and the conversion of all writing into intellectual property once it is passed through anti-plagiarism programs. These are all relevant moral issues that arise from the relations we have with technologies.


### 3.3 Coordinates for Rethinking Moral Status


In the previous two subsections, I have dealt with two issues. On the one hand, I have shown the sense in which technologies and human beings are to be understood relationally. Their intimate intertwinement undermines the traditional belief that they are two distinctly separate entities, each possessing its own distinctive properties. On the other hand, the relational dimension of morality has been expounded. Moral status locates moral value in the objective properties of entities. However, the relation between humans and technologies introduces moral aspects that can only be grasped relationally. This argument posits that, given these reasons, moral status can hardly continue to be understood in the same way. We need to include the relational dimension of anthropology and morality. The argument has stated that we need to include it, but not how we should do so. This subsection will try to offer the coordinates from which the concept of moral status should be reformulated.


It would seem that, if we conclude that anthropology and morality have a relational dimension, this implies that moral status must be _entirely_ relational. However, this idea would be erroneous. We have not offered reasons to support that moral status must be comprehended solely and exclusively from a relational viewpoint. This type of reasoning is often common in some of the leading exponents of the relational turn in moral status (Coeckelbergh, 2014; Gunkel, 2012). In contrast, I will offer three arguments that undermine the idea that moral status can be entirely relational: the anthropological argument, the ontological argument, and the ethical argument.

Firstly, _the anthropological argument_ challenges anthropologies devoid of any kind of properties. This idea is equivalent to what is understood by negative anthropology, i.e., that which determines the human being precisely by its indeterminacy. Two authors who embrace this conception are Heidegger (1927/2010) and Gehlen (1988). Heidegger places at the center of his anthropology the openness of the human being and Gehlen understands her as a cultural animal that, unlike other animals, lacks biological determination. However, this is problematic for two reasons. On the one hand, the indeterminacy of the human being may be sustained on other properties. It can be argued that without consciousness or rationality human beings could not be open or culturally malleable. Without them, the indeterminate relations that are not defined by animal properties could not occur. On the other hand, a negative property need not imply the absence of properties. A negative property can be equivalent to the properties that make it possible for the human being to be understood in a primarily relational manner.

Secondly, _the ontological argument_ is a continuation of the previous one. For relations between entities to take place, entities have to be _capable_ of entering into certain relations. This capacity is usually a consequence of the intrinsic properties of the entity. Let us return to the example of the speed bump in Latour (1999). The speed bump may constitute an inscription of a certain kind of morality that prescribes to drivers traffic rules. However, if the speed bump did not have physical properties of internal consistency and hardness, it could not enter into such relations. Thus, it seems that, at the ontological level, the relations that an entity can maintain are only possible because of certain intrinsic properties that it possesses.[Footnote 15]


Third, _the ethical argument_ has been put forward by authors who have criticized the relational turn in moral status (Gerdes, 2016; Mosakas, 2020, 2021; Müller, 2021; Nyholm, 2020). Advocates of relationality call into question the existence of such properties and the possibility of accessing them. By denying the importance of properties, they conclude that any entity can have moral status depending on how we relate to it. And this is problematic for two reasons. On the one hand, it sets arbitrary boundaries. The innovation of moral status consists in giving objectivity to moral valuation. There are entities that have value beyond the relation we can maintain with them. Without important reasons, we can value pencils as if they were people and human beings as if they were pencils (Müller, 2021). On the other hand, it hides the preeminence of certain kinds of properties. In order to be able to determine which relations have value, we seem to presuppose certain phenomenological properties. So only whoever possesses these properties can claim the moral value of the entities to which she relates.


These three arguments suggest that we cannot abandon properties. While it has been argued that relations play a fundamental role, abandoning properties does not seem the best choice. Therefore, hybrid approaches to moral status appear to be the most appropriate. One of the reasons why these hybrid approaches have had little relevance in the literature derives from the little weight given to the analysis of the concept of property. An important distinction can be made. The properties associated with moral status correspond to what are understood as _intrinsic properties_, i.e., properties that depend only on the internal nature of the entity and are in no way the result of the relations that the entity may maintain. However, there is another typology: _dispositional properties_. These properties are usually associated with the capacity of an entity to respond in a certain way under certain conditions (Mumford, 2003). This implies two aspects. On the one hand, these properties are temporally variable, that is, they are modal because they only manifest themselves under certain conditions, as well as they can be gained depending on how the entity develops. On the other hand, they are structure—or environment—dependent properties. Latour's speed bump may be hard because of the physical conditions on Earth, but, if we were to put it on another planet, it may become a fragile entity (Smith, 1977). Both types of properties, considered together along with the emphasis we should give to relations, offer two possibilities for rethinking moral status.


First, we find _intrinsic properties that are a condition of possibility for valuable relations_. We can identify two typologies. On the one hand, properties that allow certain entities to maintain certain relations. An example of this could be friendship relationships. While some have argued that we can maintain friendly relationships with robots (Danaher, 2019b), these sorts of relations only seem possible if certain mental properties are possessed. Without them, the requirements of authenticity and reciprocity cannot be met (Nyholm, 2020). Thus, the possession of certain properties makes an entity able to be part of a relation.[Footnote 16] On the other hand, properties that make it possible to give inherent value to other entities. This reasoning was developed by Korsgaard (1983) in the following terms. There are entities that we can value in themselves without themselves possessing intrinsic moral properties. We need rational or phenomenological moral capacities that establish the conditions by which an entity has value. That does not mean that these entities are their own source of value, but that they are valuable in themselves.

Secondly, we find _relations that are a condition of possibility for valuable dispositional properties_. Moore (1903/1976) put forward this idea through the concept of organic unity: the sum of the value of the individual properties of a relation does not constitute the total value of the relation. The total value of the relation determines the particular value of the parts.[Footnote 17] Moore gives the example of aesthetic experience: the enjoyment of a work of art does not lie in the value of any of its parts. Both the mental state and the material object have hardly any value in isolation. Only through the combination of both is it possible to understand the value of aesthetic experience. Many properties therefore have different values depending on the relations in which they are embedded. This idea can also be raised at the ontological and anthropological level: many of the morally relevant properties, such as the attributes linked to character, are dispositional, depending on the particular history of the individual. As they become part of certain relationships, AI may acquire dispositional properties that gain value in the total framework of relations (Jecker et al., 2022).

4 Conclusion
------------

The anthropology of properties plays a fundamental role in the debate on the moral status of AI. The agential capabilities that artificial entities are progressively acquiring are calling into question traditional anthropological definitions. This has led to a renewed interest in the concept of moral status with the aim of rethinking the properties by which we define human beings. This article has argued that the presuppositions of the anthropology of properties, on which the debate about the moral status of AI is built, contradict the anthropological legacy of philosophy and history of technology. From the various philosophies of technology that developed throughout the twentieth century, a set of anthropological models can be derived that show the importance of relation versus property in understanding humans and technologies. If the debate about the moral consideration of new artificial entities is to be enriched, the consistency of the concept of moral status and how we can include the important role of relations in our moral lives must be rethought. This does not depend entirely on the identification of certain properties from which the moral treatment of an entity is derived but is open to modifications and transformations that relations produce in the entities involved. Thus, the anthropological crisis on which the debate on moral status is based is not such. On the contrary, the anthropological models presented above show that a reformulation of the dominant conceptions of moral status is required, since the latter, from the perspective of the history and philosophy of technology, loses its validity. Its dependence on the anthropology of properties calls for a theoretical reformulation.

While this article has argued for the need to take into consideration the role of the relation in debates about the moral status of AI, it should be made clear that this does not mean a complete denial of the anthropology of properties. The final subsection of the article offers three arguments for rejecting the idea of an entirely relational concept of moral status. Relational critiques will have force if they are able to articulate and complexify hybrid approaches in which both properties and relations are given weight. Two possibilities have been offered: intrinsic properties that are a condition of possibility for valuable relations and relations that are a condition of possibility for valuable dispositional properties.

References
----------

*   Achterhuis, H. (Ed.). (2001). _American philosophy of technology: The empirical turn_. Indiana University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=American%20philosophy%20of%20technology%3A%20The%20empirical%20turn&publication_year=2001) 
    
*   Aristotle. (2004). _De Anima (On the Soul)_. Penguin.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=De%20Anima%20%28On%20the%20Soul%29&publication_year=2004&author=Aristotle%2C) 
    
*   Borgmann, A. (1987). _Technology and the character of contemporary life: A philosophical inquiry_. University of Chicago Press.
    
    [Book](https://doi.org/10.7208%2Fchicago%2F9780226163581.001.0001)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Technology%20and%20the%20character%20of%20contemporary%20life%3A%20A%20philosophical%20inquiry&doi=10.7208%2Fchicago%2F9780226163581.001.0001&publication_year=1987&author=Borgmann%2CA) 
    
*   Bostrom, N. (2014). _Superintelligence: Paths, Dangers_. Oxford University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Superintelligence%3A%20Paths%2C%20Dangers&publication_year=2014&author=Bostrom%2CN) 
    
*   Bostrom, N., & Yudkowsky, E. (2018). The ethics of artificial intelligence. In R. Yampolskiy (Ed.), _Artificial intelligence safety and security_ (pp. 57–69). Chapman and Hall/CRC.
    
    [Chapter](https://doi.org/10.1201%2F9781351251389-4)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20ethics%20of%20artificial%20intelligence&doi=10.1201%2F9781351251389-4&pages=57-69&publication_year=2018&author=Bostrom%2CN&author=Yudkowsky%2CE) 
    
*   Brey, P. (2014). From moral agents to moral factors: The structural ethics approach. In P. Kroes & P. P. Verbeek (Eds.), _The moral status of technical artifacts_ (pp. 125–142). Springer.
    
    [Chapter](https://link.springer.com/doi/10.1007/978-94-007-7914-3_8)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=From%20moral%20agents%20to%20moral%20factors%3A%20The%20structural%20ethics%20approach&doi=10.1007%2F978-94-007-7914-3_8&pages=125-142&publication_year=2014&author=Brey%2CP) 
    
*   Bryson, J. J. (2010). Robots should be slaves. In Y. Wilkins (Ed.), _Close engagements with artificial companions: Key social, psychological, ethical and design issues_ (pp. 63–74). John Benjamins.
    
    [Chapter](https://doi.org/10.1075%2Fnlp.8.11bry)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Robots%20should%20be%20slaves&doi=10.1075%2Fnlp.8.11bry&pages=63-74&publication_year=2010&author=Bryson%2CJJ) 
    
*   Bryson, J. J., & Kime, P. P. (2011). Just an artifact: Why machines are perceived as moral agents. In T. Walsh (Ed.), _Twenty-second international joint conference on artificial intelligence_ (pp. 1641–1646). AAAI Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Just%20an%20artifact%3A%20Why%20machines%20are%20perceived%20as%20moral%20agents&pages=1641-1646&publication_year=2011&author=Bryson%2CJJ&author=Kime%2CPP) 
    
*   Calverley, D. J. (2008). Imagining a non-biological machine as a legal person. _AI & Soc,_ _22_(4), 523–537.
    
    [Article](https://link.springer.com/doi/10.1007/s00146-007-0092-7)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Imagining%20a%20non-biological%20machine%20as%20a%20legal%20person&journal=AI%20%26%20Soc&doi=10.1007%2Fs00146-007-0092-7&volume=22&issue=4&pages=523-537&publication_year=2008&author=Calverley%2CDJ) 
    
*   Coeckelbergh, M. (2012). _Growing moral relations: Critique of moral status ascription_. Springer.
    
    [Book](https://doi.org/10.1057%2F9781137025968)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Growing%20moral%20relations%3A%20Critique%20of%20moral%20status%20ascription&doi=10.1057%2F9781137025968&publication_year=2012&author=Coeckelbergh%2CM) 
    
*   Coeckelbergh, M. (2014). The moral standing of machines: Towards a relational and non-Cartesian moral hermeneutics. _Philos Technol,_ _27_(1), 61–77.
    
    [Article](https://link.springer.com/doi/10.1007/s13347-013-0133-8)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20moral%20standing%20of%20machines%3A%20Towards%20a%20relational%20and%20non-Cartesian%20moral%20hermeneutics&journal=Philos%20Technol&doi=10.1007%2Fs13347-013-0133-8&volume=27&issue=1&pages=61-77&publication_year=2014&author=Coeckelbergh%2CM) 
    
*   Coeckelbergh, M. (2022). _The Political Philosophy of AI_. Polity Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20Political%20Philosophy%20of%20AI&publication_year=2022&author=Coeckelbergh%2CM) 
    
*   Danaher, J. (2019a). The rise of the robots and the crisis of moral patiency. _AI Soc,_ _34_(1), 129–136.
    
    [Article](https://link.springer.com/doi/10.1007/s00146-017-0773-9)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20rise%20of%20the%20robots%20and%20the%20crisis%20of%20moral%20patiency&journal=AI%20Soc&doi=10.1007%2Fs00146-017-0773-9&volume=34&issue=1&pages=129-136&publication_year=2019&author=Danaher%2CJ) 
    
*   Danaher, J. (2019b). The philosophical case for robot friendship. _J Posthuman Stud,_ _3_(1), 5–24.
    
    [Article](https://doi.org/10.5325%2Fjpoststud.3.1.0005)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20philosophical%20case%20for%20robot%20friendship&journal=J%20Posthuman%20Stud&doi=10.5325%2Fjpoststud.3.1.0005&volume=3&issue=1&pages=5-24&publication_year=2019&author=Danaher%2CJ) 
    
*   DeGrazia, D. (2008). Moral status as a matter of degree? _South J Philos,_ _46_(2), 181–198.
    
    [Article](https://doi.org/10.1111%2Fj.2041-6962.2008.tb00075.x)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Moral%20status%20as%20a%20matter%20of%20degree%3F&journal=South%20J%20Philos&doi=10.1111%2Fj.2041-6962.2008.tb00075.x&volume=46&issue=2&pages=181-198&publication_year=2008&author=DeGrazia%2CD) 
    
*   Dessauer, F. (1927). _Philosophie der Technik: Das Problem der Realisierung_. Verlag von Friedrich Cohen.
    
*   Ellul, J. (2021). _The technological society_. Blackstone Publishing.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20technological%20society&publication_year=2021&author=Ellul%2CJ) 
    
*   Feenberg, A. (1991). _Critical theory of technology_. Oxford University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Critical%20theory%20of%20technology&publication_year=1991&author=Feenberg%2CA) 
    
*   Feenberg, A. (1999). _Questioning technology_. Routledge.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Questioning%20technology&publication_year=1999&author=Feenberg%2CA) 
    
*   Floridi, L., & Sanders, J. (2004). On the morality of artificial agents. _Mind Mach,_ _14_, 349–379.
    
    [Article](https://doi.org/10.1023%2FB%3AMIND.0000035461.63578.9d)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=On%20the%20morality%20of%20artificial%20agents&journal=Mind%20Mach&doi=10.1023%2FB%3AMIND.0000035461.63578.9d&volume=14&pages=349-379&publication_year=2004&author=Floridi%2CL&author=Sanders%2CJ) 
    
*   Friedman, B., Kahn, P. H., Borning, A., & Huldtgren, A. (2013). Value sensitive design and information systems. In D. Schuurbiers, N. Doorn, I. van de Poel, & M. E. Gorman (Eds.), _Early engagement and new technologies: Opening up the laboratory_ (pp. 55–95). Springer.
    
    [Chapter](https://link.springer.com/doi/10.1007/978-94-007-7844-3_4)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Value%20sensitive%20design%20and%20information%20systems&doi=10.1007%2F978-94-007-7844-3_4&pages=55-95&publication_year=2013&author=Friedman%2CB&author=Kahn%2CPH&author=Borning%2CA&author=Huldtgren%2CA) 
    
*   Gehlen, A. (1988). _Man: His Nature and Place in the World_. New York University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Man%3A%20His%20Nature%20and%20Place%20in%20the%20World&publication_year=1988&author=Gehlen%2CA) 
    
*   Gerdes, A. (2016). The issue of moral consideration in robot ethics. _ACM SIGCAS Comput Soc,_ _45_(3), 274–279.
    
    [Article](https://doi.org/10.1145%2F2874239.2874278)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20issue%20of%20moral%20consideration%20in%20robot%20ethics&journal=ACM%20SIGCAS%20Comput%20Soc&doi=10.1145%2F2874239.2874278&volume=45&issue=3&pages=274-279&publication_year=2016&author=Gerdes%2CA) 
    
*   Gordon, J. S. (2021). Artificial moral and legal personhood. _AI Soc,_ _36_(2), 457–471.
    
    [Article](https://link.springer.com/doi/10.1007/s00146-020-01063-2)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Artificial%20moral%20and%20legal%20personhood&journal=AI%20Soc&doi=10.1007%2Fs00146-020-01063-2&volume=36&issue=2&pages=457-471&publication_year=2021&author=Gordon%2CJS) 
    
*   Gunkel, D. (2012). _The machine question: Critical perspectives on AI, robots, and ethics_. MIT Press.
    
    [Book](https://doi.org/10.7551%2Fmitpress%2F8975.001.0001)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20machine%20question%3A%20Critical%20perspectives%20on%20AI%2C%20robots%2C%20and%20ethics&doi=10.7551%2Fmitpress%2F8975.001.0001&publication_year=2012&author=Gunkel%2CD) 
    
*   Gunkel, D. J. (2018). _Robot rights_. MIT Press.
    
    [Book](https://doi.org/10.7551%2Fmitpress%2F11444.001.0001)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Robot%20rights&doi=10.7551%2Fmitpress%2F11444.001.0001&publication_year=2018&author=Gunkel%2CDJ) 
    
*   Haraway, D. (1985/2006). A cyborg manifesto: Science, technology, and socialist-feminism in the late 20th century. In J. Weiss, J. Nolan, J, Hunsinger & P. Trifonas (eds), _The International Handbook of Virtual Learning Environments_ (pp. 117–158). Springer.
    
*   Heidegger, M. (1927/2010). _Being and time_. SUNY Press.
    
*   Heidegger, M. (1954/2013). _The Question Concerning Technology: And Other Essays_. Harper Perennial.
    
*   Himma, K. E. (2009). Artificial agency, consciousness, and the criteria for moral agency: What properties must an artificial agent have to be a moral agent? _Ethics Inf Technol,_ _11_(1), 19–29.
    
    [Article](https://link.springer.com/doi/10.1007/s10676-008-9167-5)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Artificial%20agency%2C%20consciousness%2C%20and%20the%20criteria%20for%20moral%20agency%3A%20What%20properties%20must%20an%20artificial%20agent%20have%20to%20be%20a%20moral%20agent%3F&journal=Ethics%20Inf%20Technol&doi=10.1007%2Fs10676-008-9167-5&volume=11&issue=1&pages=19-29&publication_year=2009&author=Himma%2CKE) 
    
*   Hursthouse, R. (2013). Moral status. In H. LaFollette (Ed.), International Encyclopedia of Ethics. Wiley.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Moral%20status&publication_year=2013&author=Hursthouse%2CR) 
    
*   Ihde, D. (1979). _Technics and Praxis_. Reidel.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Technics%20and%20Praxis&publication_year=1979&author=Ihde%2CD) 
    
*   Ihde, D. (1986). _Consequences of Phenomenology_. SUNY Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Consequences%20of%20Phenomenology&publication_year=1986&author=Ihde%2CD) 
    
*   Ihde, D. (1990). _Technology and the Lifeworld_. Indiana University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Technology%20and%20the%20Lifeworld&publication_year=1990&author=Ihde%2CD) 
    
*   Ihde, D. (1993). _Postphenomenology: Essays in the Posmodern Context_. Northwestern University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Postphenomenology%3A%20Essays%20in%20the%20Posmodern%20Context&publication_year=1993&author=Ihde%2CD) 
    
*   Ihde, D. (2003). _Postphenomenology-Again?_ University of Aarhus.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Postphenomenology-Again%3F&publication_year=2003&author=Ihde%2CD) 
    
*   Ihde, D. (2009). _Postphenomenology and technoscience: the Peking University lectures_. SUNY Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Postphenomenology%20and%20technoscience%3A%20the%20Peking%20University%20lectures&publication_year=2009&author=Ihde%2CD) 
    
*   Illies, C. F. R., & Meijers, A. (2014). Artefacts, agency, and actions schemes. In P. Kroes & P. P. Verbeek (Eds.), _The moral status of technical artifacts_ (pp. 159–184). Springer.
    
    [Chapter](https://link.springer.com/doi/10.1007/978-94-007-7914-3_10)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Artefacts%2C%20agency%2C%20and%20actions%20schemes&doi=10.1007%2F978-94-007-7914-3_10&pages=159-184&publication_year=2014&author=Illies%2CCFR&author=Meijers%2CA) 
    
*   Introna, L. D. (2014). Towards a post-human intra-actional account of sociomaterial agency (and morality). In P. Kroes & P. P. Verbeek (Eds.), _The moral status of technical artefacts_ (pp. 31–53). Springer.
    
    [Chapter](https://link.springer.com/doi/10.1007/978-94-007-7914-3_3)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Towards%20a%20post-human%20intra-actional%20account%20of%20sociomaterial%20agency%20%28and%20morality%29&doi=10.1007%2F978-94-007-7914-3_3&pages=31-53&publication_year=2014&author=Introna%2CLD) 
    
*   Jaworska, A., & Tannenbaum, J. (2023). The grounds of moral status. In E. N. Zalta & U. Nodelman (Eds.), _The Stanford Encyclopedia of Philosophy_.
    
*   Jecker, N. S., Atiure, C. A., & Ajei, M. O. (2022). The moral standing of social robots: Untapped insights from Africa. _Philos Technol,_ _35_(2), 34.
    
    [Article](https://link.springer.com/doi/10.1007/s13347-022-00531-5)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20moral%20standing%20of%20social%20robots%3A%20Untapped%20insights%20from%20Africa&journal=Philos%20Technol&doi=10.1007%2Fs13347-022-00531-5&volume=35&issue=2&publication_year=2022&author=Jecker%2CNS&author=Atiure%2CCA&author=Ajei%2CMO) 
    
*   Johnson, D. G., & Noorman, M. (2014). Artefactual agency and artefactual moral agency. In P. Kroes & P. P. Verbeek (Eds.), _The moral status of technical artefacts_ (pp. 143–158). Springer.
    
    [Chapter](https://link.springer.com/doi/10.1007/978-94-007-7914-3_9)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Artefactual%20agency%20and%20artefactual%20moral%20agency&doi=10.1007%2F978-94-007-7914-3_9&pages=143-158&publication_year=2014&author=Johnson%2CDG&author=Noorman%2CM) 
    
*   Kamm, F. M. (2008). _Intricate ethics: Rights, responsibilities, and permissible harm_. Oxford University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Intricate%20ethics%3A%20Rights%2C%20responsibilities%2C%20and%20permissible%20harm&publication_year=2008&author=Kamm%2CFM) 
    
*   Kapp, E. (1877/2018). _Elements of a philosophy of technology: On the evolutionary history of culture_. Minnesota University Press.
    
*   Korsgaard, C. M. (1983). Two distinctions in goodness. _Philos Rev,_ _92_(2), 169–195.
    
    [Article](https://doi.org/10.2307%2F2184924)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Two%20distinctions%20in%20goodness&journal=Philos%20Rev&doi=10.2307%2F2184924&volume=92&issue=2&pages=169-195&publication_year=1983&author=Korsgaard%2CCM) 
    
*   Latour, B. (1992). Where are the missing masses? The sociology of a few mundane artifacts. In W. Bijker & J. Law (Eds.), _Shaping technology/building society: Studies in sociotechnical change_ (pp. 225–258). MIT Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Where%20are%20the%20missing%20masses%3F%20The%20sociology%20of%20a%20few%20mundane%20artifacts&pages=225-258&publication_year=1992&author=Latour%2CB) 
    
*   Latour, B. (1993). _We have never been modern_. Harvard University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=We%20have%20never%20been%20modern&publication_year=1993&author=Latour%2CB) 
    
*   Latour, B. (1999). _Pandora’s hope: Essays on the reality of science studies_. Harvard University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Pandora%27s%20hope%3A%20Essays%20on%20the%20reality%20of%20science%20studies&publication_year=1999&author=Latour%2CB) 
    
*   Latour, B., & Weibel, P. (Eds.). (2005). _Making things public_. MIT Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Making%20things%20public&publication_year=2005) 
    
*   Llorca-Albareda, J. (2023). El estatus moral de las entidades de inteligencia artificial. _Disputatio. Philosophical Research Bulletin,_ _12_(24), 241–249.
    
*   Llorca-Albareda, J., & Díaz-Cobacho, G. (2023). Contesting the consciousness criterion: A more radical approach to the moral status of non-humans. _AJOB Neuroscience,_ _14_(2), 158–160.
    
*   Marcuse, H. (1964/2013). _One-dimensional man: Studies in the ideology of advanced industrial society_. Routledge.
    
*   Mazlish, B. (1993). _The fourth discontinuity: The co-evolution of humans and machines_. Yale University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20fourth%20discontinuity%3A%20The%20co-evolution%20of%20humans%20and%20machines&publication_year=1993&author=Mazlish%2CB) 
    
*   Merleau-Ponty, M. (1945/2013). _Phenomenology of perception_. Routledge.
    
*   Metz, T. (2012). An African theory of moral status: A relational alternative to individualism and holism. _Ethic Theory Moral Prac,_ _15_, 387–402.
    
    [Article](https://link.springer.com/doi/10.1007/s10677-011-9302-y)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=An%20African%20theory%20of%20moral%20status%3A%20A%20relational%20alternative%20to%20individualism%20and%20holism&journal=Ethic%20Theory%20Moral%20Prac&doi=10.1007%2Fs10677-011-9302-y&volume=15&pages=387-402&publication_year=2012&author=Metz%2CT) 
    
*   Mitcham, C. (1994/2022). _Thinking through technology: The path between engineering and philosophy_. University of Chicago Press.
    
*   Moore, G. E. (1903/1976). _Principia ethica_. Cambridge University Press.
    
*   Mosakas, K. (2020). Machine moral standing: in defence of the standard properties-based view. In J. S. Gordon (Ed.), _Smart technologies and fundamental rights_ (pp. 73–100). Brill.
    
    [Chapter](https://doi.org/10.1163%2F9789004437876_005)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Machine%20moral%20standing%3A%20in%20defence%20of%20the%20standard%20properties-based%20view&doi=10.1163%2F9789004437876_005&pages=73-100&publication_year=2020&author=Mosakas%2CK) 
    
*   Mosakas, K. (2021). On the moral status of social robots: Considering the consciousness criterion. _AI Soc,_ _36_(2), 429–443.
    
    [Article](https://link.springer.com/doi/10.1007/s00146-020-01002-1)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=On%20the%20moral%20status%20of%20social%20robots%3A%20Considering%20the%20consciousness%20criterion&journal=AI%20Soc&doi=10.1007%2Fs00146-020-01002-1&volume=36&issue=2&pages=429-443&publication_year=2021&author=Mosakas%2CK) 
    
*   Müller, V. C. (2021). Is it time for robot rights? Moral status in artificial entities. _Ethics Inf Technol,_ _23_(4), 579–587.
    
    [Article](https://link.springer.com/doi/10.1007/s10676-021-09596-w)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Is%20it%20time%20for%20robot%20rights%3F%20Moral%20status%20in%20artificial%20entities&journal=Ethics%20Inf%20Technol&doi=10.1007%2Fs10676-021-09596-w&volume=23&issue=4&pages=579-587&publication_year=2021&author=M%C3%BCller%2CVC) 
    
*   Mumford, L. (1934/2010). _Technics and civilization_. University of Chicago Press.
    
*   Mumford, S. (2003). _Dispositions_. Clarendon Press.
    
    [Book](https://doi.org/10.1093%2Facprof%3Aoso%2F9780199259823.001.0001)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Dispositions&doi=10.1093%2Facprof%3Aoso%2F9780199259823.001.0001&publication_year=2003&author=Mumford%2CS) 
    
*   Nadeau, J. E. (2006). Only androids can be ethical. In K. Ford, C. Glymour, & P. Hayes (Eds.), _Thinking about android epistemology_ (pp. 241–248). MIT Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Only%20androids%20can%20be%20ethical&pages=241-248&publication_year=2006&author=Nadeau%2CJE) 
    
*   Neely, E. L. (2014). Machines and the moral community. _Philos Technol,_ _27_(1), 97–111.
    
    [Article](https://link.springer.com/doi/10.1007/s13347-013-0114-y)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Machines%20and%20the%20moral%20community&journal=Philos%20Technol&doi=10.1007%2Fs13347-013-0114-y&volume=27&issue=1&pages=97-111&publication_year=2014&author=Neely%2CEL) 
    
*   Nyholm, S. (2020). _Humans and robots: Ethics, agency, and anthropomorphism_. Rowman & Littlefield Publishers.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Humans%20and%20robots%3A%20Ethics%2C%20agency%2C%20and%20anthropomorphism&publication_year=2020&author=Nyholm%2CS) 
    
*   Powers, T. M. (2013). On the moral agency of computers. _Topoi,_ _32_(2), 227–236.
    
    [Article](https://link.springer.com/doi/10.1007/s11245-012-9149-4)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=On%20the%20moral%20agency%20of%20computers&journal=Topoi&doi=10.1007%2Fs11245-012-9149-4&volume=32&issue=2&pages=227-236&publication_year=2013&author=Powers%2CTM) 
    
*   Rapp, F. (2012). _Analytical philosophy of technology_. Springer.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Analytical%20philosophy%20of%20technology&publication_year=2012&author=Rapp%2CF) 
    
*   Schuurman, E. (1980). _Technology and the future: A philosophical challenge_. Wedge Publishing.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Technology%20and%20the%20future%3A%20A%20philosophical%20challenge&publication_year=1980&author=Schuurman%2CE) 
    
*   Selinger, E. (Ed.). (2006). _Postphenomenology: A critical companion to Ihde_. SUNY Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Postphenomenology%3A%20A%20critical%20companion%20to%20Ihde&publication_year=2006) 
    
*   Singer, P. (1983). _The expanding circle: Ethics and sociobiology_. Oxford University Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20expanding%20circle%3A%20Ethics%20and%20sociobiology&publication_year=1983&author=Singer%2CP) 
    
*   Singer, P. (1975/2009). _Animal Liberation_. Harper Perennial.
    
*   Singer, P. (1979/2011). _Practical ethics_. Cambridge University Press.
    
*   Smith, A. D. (1977). Dispositional properties. _Mind,_ _86_(343), 439–445.
    
    [Article](https://doi.org/10.1093%2Fmind%2Flxxxvi.343.439)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Dispositional%20properties&journal=Mind&doi=10.1093%2Fmind%2Flxxxvi.343.439&volume=86&issue=343&pages=439-445&publication_year=1977&author=Smith%2CAD) 
    
*   Søraker, J. H. (2014). Continuities and discontinuities between humans, intelligent machines, and other entities. _Philos Technol,_ _27_(1), 31–46.
    
    [Article](https://link.springer.com/doi/10.1007/s13347-013-0132-9)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Continuities%20and%20discontinuities%20between%20humans%2C%20intelligent%20machines%2C%20and%20other%20entities&journal=Philos%20Technol&doi=10.1007%2Fs13347-013-0132-9&volume=27&issue=1&pages=31-46&publication_year=2014&author=S%C3%B8raker%2CJH) 
    
*   Sparrow, R. (2004). The turing triage test. _Ethics Inf Technol,_ _6_(4), 203–213.
    
    [Article](https://link.springer.com/doi/10.1007/s10676-004-6491-2)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20turing%20triage%20test&journal=Ethics%20Inf%20Technol&doi=10.1007%2Fs10676-004-6491-2&volume=6&issue=4&pages=203-213&publication_year=2004&author=Sparrow%2CR) 
    
*   Stone, C. D. (1972/2010). _Should trees have standing? Law, morality, and the environment_. Oxford University Press.
    
*   Sullins, J. (2011). When is a robot a moral agent? In M. Anderson & S. L. Anderson (Eds.), _Machine ethics_ (pp. 151–161). Cambridge University Press.
    
    [Chapter](https://doi.org/10.1017%2FCBO9780511978036.013)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=When%20is%20a%20robot%20a%20moral%20agent%3F&doi=10.1017%2FCBO9780511978036.013&pages=151-161&publication_year=2011&author=Sullins%2CJ) 
    
*   Tegmark, M. (2018). _Life 3.0: Being human in the age of artificial intelligence_. Vintage.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Life%203.0%3A%20Being%20human%20in%20the%20age%20of%20artificial%20intelligence&publication_year=2018&author=Tegmark%2CM) 
    
*   Totschnig, W. (2019). The problem of superintelligence: Political, not technological. _AI Soc,_ _34_(4), 907–920.
    
    [Article](https://link.springer.com/doi/10.1007/s00146-017-0753-0)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=The%20problem%20of%20superintelligence%3A%20Political%2C%20not%20technological&journal=AI%20Soc&doi=10.1007%2Fs00146-017-0753-0&volume=34&issue=4&pages=907-920&publication_year=2019&author=Totschnig%2CW) 
    
*   Turkle, S. (2011). Authenticity in the age of digital companions. In M. Anderson & S. L. Anderson (Eds.), _Machine ethics_ (pp. 62–76). Cambridge University Press.
    
    [Chapter](https://doi.org/10.1017%2FCBO9780511978036.008)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Authenticity%20in%20the%20age%20of%20digital%20companions&doi=10.1017%2FCBO9780511978036.008&pages=62-76&publication_year=2011&author=Turkle%2CS) 
    
*   Véliz, C. (2021). Moral zombies: Why algorithms are not moral agents. _AI Soc,_ _36_(2), 487–497.
    
    [Article](https://link.springer.com/doi/10.1007/s00146-021-01189-x)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Moral%20zombies%3A%20Why%20algorithms%20are%20not%20moral%20agents&journal=AI%20Soc&doi=10.1007%2Fs00146-021-01189-x&volume=36&issue=2&pages=487-497&publication_year=2021&author=V%C3%A9liz%2CC) 
    
*   Verbeek, P. P. (2005). _What things do? Philosophical reflections on technology, agency, and design_. Pennsylvania State University Press.
    
    [Book](https://doi.org/10.1515%2F9780271033228)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=What%20things%20do%3F%20Philosophical%20reflections%20on%20technology%2C%20agency%2C%20and%20design&doi=10.1515%2F9780271033228&publication_year=2005&author=Verbeek%2CPP) 
    
*   Verbeek, P. P. (2008a). Cyborg intentionality: Rethinking the phenomenology of human–technology relations. _Phenom Cogn Sci,_ _7_(3), 387–395.
    
    [Article](https://link.springer.com/doi/10.1007/s11097-008-9099-x)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Cyborg%20intentionality%3A%20Rethinking%20the%20phenomenology%20of%20human%E2%80%93technology%20relations&journal=Phenom%20Cogn%20Sci&doi=10.1007%2Fs11097-008-9099-x&volume=7&issue=3&pages=387-395&publication_year=2008&author=Verbeek%2CPP) 
    
*   Verbeek, P. P. (2008b). Obstetric ultrasound and the technological mediation of morality: A postphenomenological analysis. _Hum Stud,_ _31_(1), 11–26.
    
    [Article](https://link.springer.com/doi/10.1007/s10746-007-9079-0)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Obstetric%20ultrasound%20and%20the%20technological%20mediation%20of%20morality%3A%20A%20postphenomenological%20analysis&journal=Hum%20Stud&doi=10.1007%2Fs10746-007-9079-0&volume=31&issue=1&pages=11-26&publication_year=2008&author=Verbeek%2CPP) 
    
*   Verbeek, P. P. (2011). _Moralizing technology: Understanding and designing the morality of things_. Chicago University Press.
    
    [Book](https://doi.org/10.7208%2Fchicago%2F9780226852904.001.0001)  [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Moralizing%20technology%3A%20Understanding%20and%20designing%20the%20morality%20of%20things&doi=10.7208%2Fchicago%2F9780226852904.001.0001&publication_year=2011&author=Verbeek%2CPP) 
    
*   Warren, M. A. (1997). _Moral status: Obligations to persons and other living things_. Clarendon Press.
    
    [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Moral%20status%3A%20Obligations%20to%20persons%20and%20other%20living%20things&publication_year=1997&author=Warren%2CMA) 
    
*   Weber, M. (1920/1993). _The sociology of religion_. Beacon Press.
    
*   Winner, L. (1986/2010). _The whale and the reactor: A search for limits in an age of high technology_. University of Chicago Press.
