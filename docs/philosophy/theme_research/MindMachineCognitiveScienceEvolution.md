# **Mind as Machine, Machine as Mind: The Co-Evolution of Philosophy, AI, and Cognitive Science**

## **I. Introduction: The Crucible of Mind and Machine**

The middle decades of the 20th century, particularly the period from the 1950s through the 1970s, witnessed a remarkable intellectual convergence. Analytic philosophy of mind, the nascent field of Artificial Intelligence (AI), and the emerging interdisciplinary domain of Cognitive Science engaged in a period of intense, reciprocal interaction. This report explores the rich intellectual ecosystem of this era, arguing that these fields did not merely develop in parallel but were profoundly intertwined, co-evolving through shared conceptual frameworks, mutual methodological inspiration, and complex feedback loops. The central theme, encapsulated by the phrase "Mind as Machine, Machine as Mind," reflects the pervasive influence of computational ideas, which served as both a powerful explanatory metaphor and a concrete engineering blueprint.

At the heart of this convergence lay the Computational Theory of Mind (CTM), the view that the mind is, in some fundamental sense, an information processing system, and that cognition itself is a form of computation.1 Emerging against the backdrop of behaviorism's decline and dissatisfaction with existing philosophical accounts of the mind, the computational metaphor offered a compelling new paradigm. It promised a mechanistic, scientifically respectable way to understand internal mental processes—the very "black box" that behaviorism had eschewed—without resorting to problematic dualistic or purely introspective accounts.3 The rapid development of digital computers provided not only a powerful metaphor but also a tangible tool for modeling and simulating cognitive functions.6

This report will trace the intricate co-evolution of these fields. It begins by examining the historical context of the cognitive revolution, focusing on the limitations of behaviorism and the appeal of computational alternatives. It then delves into the key philosophical theories, notably functionalism and the Language of Thought hypothesis, that drew inspiration from and provided justification for computational approaches. Subsequently, it analyzes the foundational work of AI pioneers like Alan Turing, Allen Newell, and Herbert Simon, whose contributions functioned simultaneously as engineering projects and theories of cognition. The report explores the crucial role of language, particularly Noam Chomsky's linguistic theories, in shaping ideas about mental representation across disciplines. It investigates the transfer and transformation of core concepts—representation, computation, information, algorithm, symbol—as they migrated across disciplinary boundaries, highlighting the "trading zones" where these ideas were exchanged and reinterpreted. Furthermore, it examines the philosophical assumptions embedded within early AI systems and the conceptual challenges, such as the symbol grounding problem, that arose from these endeavors. The institutionalization of cognitive science as a mediating interdisciplinary field is discussed, followed by an analysis of the key internal debates, such as the symbolic versus connectionist and representationalist versus anti-representationalist divides. Finally, the report assesses the enduring legacy and inherent limitations of the computational metaphor, considering its impact on contemporary AI ethics and philosophy of mind. Through this historical and philosophical analysis, the profound interdependence that shaped our modern understanding of both mind and machine becomes evident.

## **II. Escaping Behaviorism: The Cognitive Revolution's Dawn**

The intellectual landscape of mid-20th century American psychology was largely dominated by behaviorism.3 Championed by figures like J. B. Watson and B. F. Skinner, behaviorism sought to establish psychology as a natural science by focusing exclusively on observable behavior—specifically, the learned associations between environmental stimuli and behavioral responses.3 Methodologically, it emphasized empirical observation and experimentation, often using animal models, while theoretically, it dismissed internal mental states, consciousness, and introspection as unscientific, subjective, or irrelevant.4 Mental life, if acknowledged at all, was considered epiphenomenal or reducible to behavioral dispositions.8

However, by the 1950s, significant cracks began to appear in the behaviorist edifice. Researchers found it increasingly difficult to explain complex human behaviors, particularly higher cognitive functions like problem-solving, planning, and language, solely through stimulus-response chains and reinforcement histories.4 Behaviorism struggled to account for the novelty and creativity inherent in language use—the ability of individuals to produce and understand sentences they have never encountered before.10 The internal processes of thinking, reasoning, and representing the world seemed essential for explaining intelligent action, yet behaviorism offered no conceptual tools to investigate them.4 This created a conceptual vacuum, a need for a framework that could scientifically address the internal workings of the mind.

The "cognitive revolution," an intellectual movement coalescing around the mid-1950s, emerged in direct response to these limitations.3 A key catalyst was the influx of ideas from fields outside traditional psychology, particularly cybernetics, information theory, and the burgeoning field of computer science.3 Figures like Claude Shannon provided mathematical tools for quantifying information, while the development of programmable digital computers demonstrated the possibility of complex processes arising from rule-based symbol manipulation.15 A pivotal moment often cited is the 1956 Symposium on Information Theory at MIT, featuring seminal presentations by cognitive science founders like George Miller, Noam Chomsky, Allen Newell, and Herbert Simon.6

Computational models became the central pillar of this revolution, offering a powerful alternative to behaviorist explanations.3 The computer provided a compelling metaphor: the mind, like a computer, could be understood as an information processing system that operates on internal representations according to formal rules or algorithms.3 This approach allowed researchers to hypothesize about internal mental structures and processes (like memory stores, grammars, or problem-solving heuristics) and test these hypotheses by designing experiments and building computational simulations.3 Crucially, this computational framework offered a path forward that avoided both the perceived subjectivism of introspection and the perceived inadequacies of behaviorism and earlier philosophical positions like mind-body identity theory.4

Noam Chomsky's devastating critique of B. F. Skinner's behaviorist account of language, particularly his 1959 review of Skinner's *Verbal Behavior*, was a landmark event in the cognitive revolution.10 Chomsky argued forcefully that behaviorist principles like imitation and reinforcement were fundamentally incapable of explaining the rapidity and creativity of language acquisition.10 He introduced the "poverty of the stimulus" argument, contending that the linguistic data children are exposed to is too limited and degenerate to account for the complex grammatical knowledge they attain.10 Children routinely produce and understand novel sentences, suggesting they possess an internalized system of grammatical rules.10 To explain this, Chomsky posited an innate "Language Acquisition Device" (LAD) equipped with principles of "Universal Grammar"—an underlying blueprint common to all human languages.10 This emphasis on innate, rule-governed structures provided strong support for the necessity of internal mental representations and computational procedures, aligning perfectly with the burgeoning computational view of the mind.4

The historical context reveals that the rise of computational models was not merely a matter of choosing one theory among many equally viable alternatives. Behaviorism's strictures against discussing internal states 4 and the philosophical difficulties associated with mind-body identity theories 25 left a significant gap for those seeking a scientific understanding of cognition. Chomsky's critique, in particular, demanded an explanation grounded in internal rules and structures.10 The concepts emerging from computer science—information, computation, algorithm, representation—provided a novel, mechanistic, and seemingly objective vocabulary to discuss precisely these internal complexities.3 Thus, the computational framework functioned as an essential "escape hatch," providing the necessary conceptual tools and scientific legitimacy for psychologists and philosophers to move beyond behaviorism and explore the intricacies of the mind within a materialist worldview.5 Its adoption was driven, in large part, by the perceived failures of the dominant paradigm and the lack of other compelling, scientifically tractable alternatives at that historical juncture.

## **III. Philosophical Frameworks for the Computational Mind**

As the cognitive revolution gained momentum, new philosophical theories of mind emerged that actively engaged with and drew upon the concepts of computation. These theories provided crucial conceptual foundations for both cognitive science and artificial intelligence, moving beyond the limitations of behaviorism and type-identity theory.

Functionalism arose in the 1960s as a prominent alternative.5 Spearheaded by philosophers like Hilary Putnam and Jerry Fodor, functionalism proposed that mental states should be defined not by their internal physical constitution, but by their *function* or *causal role* within the cognitive system.9 What makes something a belief, a desire, or a pain is how it is typically caused (e.g., by sensory inputs or other mental states) and what it typically causes (e.g., other mental states or behavioral outputs).26 This contrasted sharply with behaviorism, which focused only on input-output relations, and with the type-identity theory (popularized by Place, Feigl, and Smart 25), which identified mental state types (like pain) with specific physical state types (like C-fiber stimulation).25

Hilary Putnam, in particular, developed a version known as "machine-state functionalism," explicitly drawing an analogy between the mind and a Turing machine.5 He proposed that any creature with a mind could be viewed as a probabilistic automaton, whose operations are specified by a "machine table" – a set of instructions defining transitions between states and production of outputs based on current state and input.5 Mental states, in this view, are identified with the abstract "logical states" or "machine table states" of this automaton.5 These states are defined purely by their functional relations within the system described by the machine table.5 This formulation directly imported concepts from theoretical computer science into the philosophy of mind.26

A crucial implication of functionalism, strongly advocated by Putnam, is the principle of *multiple realizability*.5 Since mental states are defined by their functional roles rather than their physical implementation, the same mental state could, in principle, be realized by vastly different physical systems.5 Pain, defined functionally, might be realized by neural activity in humans, by silicon-based processes in hypothetical Martians, or by complex hydraulic systems in imagined androids, provided these different physical states fulfill the same causal role specified by the functional definition.26 This idea was highly appealing because it countered the perceived "species-chauvinism" of the identity theory, which seemed to restrict mental states to creatures with human-like brains.26 More significantly for the burgeoning field of AI, multiple realizability provided a philosophical justification for the possibility that machines could possess genuine mental states.17

Building on functionalism, the Computational Theory of Mind (CTM) emerged as a more specific and influential view, gaining prominence particularly through the work of Jerry Fodor.1 CTM holds that the mind is not merely *like* a computer, but that it *literally is* a computational system, and that cognitive processes, including thinking, are computations.1 Often viewed as a specific variant of functionalism (sometimes termed "computational functionalism" 5), CTM typically incorporates the Representational Theory of Mind (RTM), the view that mental states involve relations to internal mental representations.4 Within CTM, these representations are the structures over which computations are performed.4 CTM enjoyed orthodox status within cognitive science for many years, providing a dominant framework for understanding cognition.7

The development of functionalism, particularly Putnam's machine-state version, demonstrates a critical feedback loop. While drawing inspiration *from* computer science (Turing machines), it simultaneously provided philosophical groundwork *for* AI.5 The identity theory, by tying mental states rigidly to specific neural states 25, posed a potential philosophical barrier to the idea of machine intelligence.26 Functionalism, however, by defining mental states abstractly in terms of their causal roles 9, effectively decoupled mind from substrate. The principle of multiple realizability 27 explicitly stated that the "hardware" didn't matter for the instantiation of mind, only the functional organization—the "software"—did. This provided a powerful, materialism-compatible philosophical framework 26 that legitimized the core aspiration of "strong AI": the notion that an appropriately programmed computer could possess genuine mental states, such as beliefs, desires, and perhaps even consciousness, rather than merely simulating them.17 Functionalism thus offered not just an analogy, but a philosophical *license* for pursuing the creation of artificial minds.

## **IV. AI Pioneers: Engineering Minds, Theorizing Cognition**

The theoretical developments in philosophy and psychology ran parallel to, and were deeply influenced by, groundbreaking work in the nascent field of artificial intelligence. The pioneers of AI were not merely engineers building machines; their work often embodied and tested fundamental hypotheses about the nature of intelligence, computation, and thought itself.

Alan Turing stands as a pivotal figure, laying crucial theoretical groundwork long before AI emerged as a distinct field. His 1936 paper introduced the concept of the *Turing machine*, an abstract model of computation involving a scanner manipulating symbols on an infinite tape according to a set of instructions.34 Crucially, he described the *universal Turing machine*, a single machine capable of simulating any other Turing machine given the right program encoded on its tape.34 This concept established the theoretical foundation for general-purpose, programmable computers and the very idea of universal computation.35 Turing's work also established fundamental limits to computation, such as the undecidability of the halting problem.35 Later, in his seminal 1950 paper "Computing Machinery and Intelligence," Turing directly addressed the question "Can machines think?".36 Finding the question itself "too meaningless" due to the ambiguity of "think," he proposed the *Imitation Game*, now famously known as the *Turing Test*.34 This operational test involved a human interrogator trying to distinguish between a human and a machine based purely on textual conversation.37 If the machine could consistently fool the interrogator, Turing suggested, we should consider it capable of thinking.34 The Turing Test had an immediate and lasting philosophical impact, shifting the debate towards behavioral criteria, challenging anthropocentric views of intelligence, and setting a long-term (though highly debated) benchmark for AI research.36 Turing also foresaw the importance of machine learning, suggesting that allowing machines to alter their own instructions was key.34

Building on the theoretical possibilities opened by computation, Allen Newell and Herbert A. Simon became central figures in establishing AI as an experimental science and linking it directly to human cognition. Their most significant theoretical contribution was the *Physical Symbol System Hypothesis (PSSH)*, formally articulated in their 1976 Turing Award lecture but developed through their work in the preceding decades.42 The PSSH asserts that "a physical symbol system has the necessary and sufficient means for general intelligent action".42 A physical symbol system was defined as a machine that manipulates physical patterns (symbols), combines them into complex structures (expressions), and transforms these structures according to rules (processes).43

Crucially, Newell and Simon conceived of the PSSH as having a dual role.43 On one hand, it served as the foundational hypothesis for AI research, suggesting that the path to artificial general intelligence lay in creating sophisticated symbol manipulation systems.42 Early AI programs developed by them and their colleagues, such as the *Logic Theorist* (which proved theorems from *Principia Mathematica*) and the *General Problem Solver (GPS)* (which used means-ends analysis to solve formalized problems), were seen as empirical evidence supporting the sufficiency claim of the PSSH.43 On the other hand, the PSSH was proposed as a scientific theory of *human* cognition.42 Newell and Simon conducted extensive psychological experiments analyzing human problem-solving protocols, particularly for puzzles and logic tasks.43 They observed that humans appeared to engage in step-by-step symbolic manipulation, exploring possibilities and applying heuristics.43 They argued that their AI programs simulated these very processes, concluding that humans themselves are instances of physical symbol systems.42 Relatedly, they proposed the *Heuristic Search Hypothesis*, stating that problem-solving largely consists of searching through a problem space represented by symbol structures, guided by heuristics to manage the combinatorial explosion of possibilities.47

The work of these AI pioneers transcends mere engineering. Turing's formulation of the Universal Machine and the Turing Test were deeply philosophical acts, aimed at defining computation and providing operational criteria for intelligence.35 Similarly, Newell and Simon's PSSH was explicitly presented as an empirical hypothesis about both machines and minds, grounded in psychological observation.42 Their AI programs, like Logic Theorist and GPS, were not just demonstrations of programming skill; they were constructed *as* simulations and tests of their theories about human reasoning and problem-solving.43 In this sense, early AI research functioned as a form of empirical philosophy and computational psychology. The very act of building systems that could perform tasks previously considered uniquely human—proving theorems, solving problems, playing chess 34—served as a powerful, concrete argument for the computational view of intelligence, operationalizing abstract philosophical and psychological ideas in a way that had never before been possible. The engineering endeavor itself became a method for investigating the foundations of thought.

## **V. Language, Thought, and Symbols: The Representational Core**

Central to the converging frameworks of philosophy, AI, and cognitive science in this period was the concept of representation, particularly the idea that thought involves the manipulation of internal, symbolic representations. The Representational Theory of Mind (RTM), the view that cognitive states like beliefs and desires are relations between an agent and internal mental representations, became a cornerstone assumption.4

Jerry Fodor's *Language of Thought Hypothesis (LOTH)*, introduced in his influential 1975 book *The Language of Thought*, provided a specific and highly influential articulation of RTM within a computational framework.31 Fodor argued that thinking occurs in an innate, internal language system, dubbed "Mentalese," which possesses a combinatorial syntax and compositional semantics analogous to natural language.31 Simple concepts (Mentalese "words") combine systematically according to grammatical rules to form complex thoughts (Mentalese "sentences").50 Fodor explicitly linked LOTH to the Computational Theory of Mind (CTM), proposing that mental representations are symbolic tokens in this Language of Thought, and mental processes are computations defined over the syntactic (formal, structural) properties of these tokens.31 This provided a potential solution to the problem of mental causation within a physicalist framework: thoughts (propositional attitudes like believing that *p* or desiring that *q*) could have causal effects on behavior because the syntactic form of their underlying Mentalese representations makes them causally relevant to computational processes, much like the form of symbols in a computer program determines its execution.31 Fodor supported LOTH with arguments from the *productivity* (the potential infinity of thoughts we can entertain) and *systematicity* (the regular patterns in our cognitive abilities, e.g., if one can think 'John loves Mary', one can typically also think 'Mary loves John') of thought, arguing these properties are best explained by a language-like combinatorial system.50 The LOTH resonated strongly with the concurrent work in symbolic AI (GOFAI), which also relied on structured symbolic representations and rule-based manipulation.31

Simultaneously, Noam Chomsky's revolution in linguistics provided crucial support for the idea of complex, internal representations, particularly in the domain of language. As discussed earlier, his critique of behaviorism hinged on the need for innate mental structures to explain language acquisition.10 His theory of *generative grammar* proposed that human linguistic competence is based on an internalized system of rules (a mental grammar) that can generate all and only the grammatically correct sentences of a language.4 This grammar involves abstract structures (like deep structure and surface structure) and transformations operating upon them.22 Chomsky's work powerfully reinforced the general notion within cognitive science that complex cognitive abilities rely on sophisticated, rule-governed internal representations.4

Furthermore, Chomsky's formal approach had a direct and significant impact on early AI research in Natural Language Processing (NLP).20 Generative grammar provided AI researchers with a formal toolkit—concepts like phrase structure rules, parsing, and transformational grammar—for analyzing the syntax of natural language and attempting to build systems that could understand or generate sentences.22 Early NLP systems often explicitly tried to implement Chomskyan grammatical frameworks.59 While later NLP moved towards statistical and machine learning methods, Chomsky's initial framework was instrumental in launching the computational study of language.

The relationship between Fodor's LOTH and symbolic AI exemplifies the symbiotic nature of the interactions during this period. LOTH provided a compelling philosophical and cognitive justification for the approach taken by symbolic AI researchers like Newell and Simon. If human thought itself operates like a computational process over a structured symbolic language (Mentalese), then attempting to build artificial intelligence through the manipulation of formal symbols according to rules seems like the most promising, indeed the most theoretically grounded, strategy.31 Conversely, the apparent successes of early symbolic AI programs in domains requiring reasoning and problem-solving (such as Logic Theorist proving theorems 48 or STUDENT solving algebra word problems 43) lent empirical plausibility to the abstract claims of LOTH and CTM. These programs demonstrated that symbol manipulation could, in fact, produce behaviors that appeared intelligent, seemingly validating the idea that computation over symbolic representations was the key to cognition.43 This created a powerful feedback loop where philosophical theory justified AI practice, and AI practice seemed to provide evidence for philosophical theory.

## **VI. Trading Zones: The Flow of Foundational Concepts**

The co-evolution of philosophy of mind, AI, and cognitive science was facilitated by the movement and transformation of key concepts across disciplinary boundaries. Terms like "representation," "computation," "information," "algorithm," and "symbol" formed a shared vocabulary, creating "trading zones" where researchers from different backgrounds could interact. However, the meanings of these terms were often fluid and context-dependent, reflecting the differing assumptions and goals of each field.

* **Representation:** This concept had deep roots in philosophy, tied to notions of intentionality, meaning, and the mind's capacity to be "about" the world.32 In the context of RTM and LOTH, mental representations were seen as structured, language-like entities with semantic content.31 In AI, "representation" often referred more concretely to the data structures used within programs to stand for objects, properties, concepts, or knowledge about a domain.12 The focus was often on the formal structure and manipulability of these representations. Cognitive science employed "mental representation" as a core theoretical construct to explain cognitive capacities, bridging philosophical ideas and AI implementations, often assuming representations were computational structures.4 The later emergence of anti-representationalist views highlighted the contested nature of this concept.63  
* **Computation:** Originating in mathematical logic with Turing's precise definition of effective procedures (computability via Turing machines) 34, "computation" became the central metaphor and explanatory mechanism in CTM and functionalism, signifying the rule-governed manipulation of symbols as the essence of thought.1 In AI, computation referred to the actual processes executed by programs.48 Within cognitive science, the term was often used more broadly, sometimes becoming almost synonymous with "information processing" or any internal process explaining cognition, leading to potential ambiguities and stretching of the original concept.14 Distinctions between digital and analog computation were also discussed.14  
* **Information:** This term carried a fundamental ambiguity. Claude Shannon's mathematical theory of information provided a rigorous, quantitative measure related to the reduction of uncertainty, essentially a syntactic concept.15 However, in cognitive science and philosophy, "information" was frequently used in a semantic sense, referring to meaningful content, knowledge, or the propositional content of mental states.3 The cybernetics movement attempted to fuse Shannon's theory with computational ideas, but the distinction between the quantitative/syntactic and the qualitative/semantic senses of information was often blurred, leading to conceptual confusion.14  
* **Algorithm:** Directly imported from mathematics and computer science, an algorithm signified a well-defined, step-by-step procedure for solving a problem or achieving a goal.16 In AI, designing algorithms was the core task of programming intelligent behavior.48 Cognitive science adopted algorithms as models for mental processes, hypothesizing that thinking involved executing specific cognitive algorithms.4 Philosophically, algorithms underpinned CTM's view of thinking as computation.16  
* **Symbol:** In formal logic and symbolic AI (especially under the PSSH), symbols were conceived as discrete physical tokens manipulated purely based on their form (syntax) according to rules.43 In Fodor's LOTH, symbols (Mentalese words) were mental representations possessing intrinsic semantic content.50 This difference highlighted the crucial question of how formal, uninterpreted symbols in a system like a computer (or the human brain, viewed computationally) could acquire meaning—the symbol grounding problem.66

The transfer of these concepts occurred through various mechanisms. Philosophers like Putnam explicitly borrowed computational concepts 26, while AI researchers like Newell and Simon integrated ideas from logic and psychology.43 The overarching computer metaphor provided a general framework influencing thought across disciplines.2 Crucially, interdisciplinary forums—conferences like the 1956 Dartmouth workshop 15, research centers at institutions like MIT and CMU 48, and later, dedicated journals and societies 12—acted as "trading zones." In these zones, concepts were exchanged, debated, and often reinterpreted to fit the specific needs and perspectives of each participating field.12 The earlier cybernetics movement had already laid groundwork for such cross-disciplinary exchange.12

To illustrate the varying interpretations, consider the following table:

**Table 1: Conceptual Transfer \- Definitions of Key Terms (c. 1950-1975)**

| Term | Philosophy of Mind | Artificial Intelligence (GOFAI) | Psychology/Cognitive Science |
| :---- | :---- | :---- | :---- |
| Representation | Mental states with intentionality/meaning; relations to internal structures (RTM, LOTH) 31 | Formal data structures; symbols standing for external entities/knowledge 16 | Internal mental structures/models posited to explain cognition; often assumed computational 4 |
| Computation | The essential nature of thought (CTM); rule-governed state transitions (Functionalism) 1 | Formal manipulation of symbols based on algorithms/rules; program execution 43 | Information processing; rule-governed manipulation of representations; often digital 3 |
| Information | Semantic content; knowledge; propositional content of mental states 14 | Data input/output; content encoded in representations 16 | Often conflated: Shannon's quantitative measure and/or semantic content 3 |
| Algorithm | Abstract step-by-step procedure underlying thought processes (in CTM) 16 | Specific set of instructions implemented in a program to solve a task 65 | Hypothesized step-by-step mental procedure explaining a cognitive ability 4 |
| Symbol | Meaningful mental token (LOTH); element with semantic properties 50 | Formal, physical token manipulated based on shape/syntax (PSSH) 43 | Element in a computational model of mind, often assumed to have representational content 4 |

The fluidity and sometimes ambiguous nature of these core terms played a complex role. On one hand, this flexibility was arguably necessary for enabling communication and collaboration across disciplines with different methodologies and theoretical commitments. A shared, albeit loosely defined, vocabulary centered around computation and information allowed researchers to rally under the banner of the emerging cognitive science.12 On the other hand, this very ambiguity contained the seeds of future conflict and misunderstanding.14 As the implications of different interpretations were explored more deeply within each field, disagreements arose about fundamental questions: What truly constitutes computation? Is representation necessary for intelligence? Can syntax give rise to semantics? The initial conceptual borrowing, facilitated by ambiguity, thus paved the way for later, more critical debates as the fields matured and confronted the harder problems inherent in the computational paradigm.

## **VII. Code and Cognition: Assumptions and Challenges**

The early AI systems developed during this period were not just technical achievements; they were concrete embodiments of specific philosophical and psychological assumptions about the nature of intelligence, language, and problem-solving. The design choices made in programming languages and landmark AI programs reflected, and in turn influenced, the theoretical landscape.

* **LISP (List Processing):** Developed by John McCarthy in the late 1950s, LISP quickly became the dominant programming language for AI research.48 Its design choices were deeply intertwined with the assumptions of symbolic AI. LISP excels at manipulating symbols and lists, making it ideal for representing knowledge and implementing rule-based reasoning.48 Key features like recursion mirrored hypothesized structures in language and thought, while capabilities like dynamic typing, garbage collection, and treating code as data (allowing programs to modify themselves) facilitated the development of flexible systems capable of complex symbolic manipulation and potentially learning or adaptation.48 The prevalence of LISP reinforced the view that intelligence was fundamentally about processing symbolic structures.  
* **General Problem Solver (GPS):** Developed by Newell, Shaw, and Simon, GPS was a direct implementation of their theoretical commitments, namely the PSSH and the Heuristic Search hypothesis.47 It aimed to simulate human problem-solving strategies in a general way. Its core mechanism, *means-ends analysis*, involved identifying differences between the current state and the goal state, and applying operators (symbolic rules) to reduce those differences, potentially breaking the problem into subgoals.48 GPS thus embodied the assumption that intelligent problem-solving is a formal process of heuristic search within a symbolically represented state space, mirroring the step-by-step processes they observed in human subjects.43  
* **SHRDLU:** Created by Terry Winograd in the early 1970s, SHRDLU represented a significant advance in natural language understanding within a limited domain—a simulated "blocks world".48 Operating in LISP and Micro Planner, SHRDLU embodied the assumption that language understanding is not merely syntactic analysis but requires integration with knowledge representation, reasoning, planning, and interaction with a world (even a simulated one).48 It could parse complex commands, interpret them semantically in relation to its internal model of the blocks world, ask clarifying questions, execute actions (moving virtual blocks), and understand discourse context (like pronoun references).48 SHRDLU's success suggested that meaning and understanding, at least within a constrained environment, could arise from the interaction of linguistic processing with a symbolic world model and goal-directed procedures.

Despite the successes of systems like SHRDLU, symbolic AI faced a fundamental conceptual challenge: how could the purely formal, syntactic manipulation of symbols give rise to genuine meaning (semantics) and intentionality (the property of mental states being *about* something)?.33 This question became acutely focused through two related critiques:

* **Searle's Chinese Room Argument:** John Searle's 1980 thought experiment directly attacked the claims of "strong AI"—the view, aligned with CTM and functionalism, that an appropriately programmed computer could literally possess understanding and other cognitive states.33 By imagining a person manipulating Chinese symbols according to rules without understanding Chinese, Searle argued that syntactic manipulation alone is insufficient for semantic understanding.33 Since computers, according to the computational view, operate purely syntactically, Searle concluded they could never achieve genuine understanding or consciousness, regardless of how intelligently they behaved.33 The argument highlighted the gap between formal symbol processing and meaningful thought.  
* **The Symbol Grounding Problem:** Formulated explicitly by Stevan Harnad in 1990, but reflecting earlier concerns, this problem asks how the symbols within a formal system (like an AI program or potentially the brain's "language of thought") become connected to the real-world things they are supposed to represent.66 How can meaning be made intrinsic to the system, rather than being merely projected onto it by an external human interpreter?.75 Harnad used the analogy of trying to learn Chinese solely from a Chinese-Chinese dictionary—one would be trapped in a circle of meaningless symbols.75 He proposed that symbols must ultimately be "grounded" in non-symbolic representations derived from sensory experience, such as iconic (analog) representations and categorical representations learned through interaction with the world, potentially via connectionist mechanisms.75 This critique suggested that purely symbolic systems, detached from perceptual and motor interaction, could not achieve genuine meaning.

Analyzing these early AI systems reveals them as more than just technological artifacts; they functioned as concrete arguments within the philosophical and psychological debates of the time. GPS, for instance, was a direct instantiation of the PSSH view, attempting to demonstrate that general intelligence could arise from formal heuristic search.47 Its successes and limitations provided empirical data relevant to that hypothesis. SHRDLU, while still operating within a symbolic framework, implicitly argued for a more integrated and situated view of cognition, particularly language, by linking symbolic processing tightly to a world model, perception (simulated), and action.48 Its impressive capabilities within its micro-world seemed to support the idea that understanding requires grounding, even if only in a simulated reality. The challenges these systems faced, culminating in critiques like the Chinese Room and the symbol grounding problem, further fueled the debate, pushing researchers to confront the deep issues surrounding meaning, representation, and the relationship between formal systems and the world they aim to model.

## **VIII. Forging a Field: The Institutionalization of Cognitive Science**

The recognition that understanding the mind required insights from multiple disciplines—psychology, linguistics, computer science/AI, philosophy, neuroscience, and anthropology—led to efforts to establish cognitive science as a distinct, integrated field of study.4 Progress on fundamental questions about intelligence, representation, and learning seemed to demand a framework that could bridge the theoretical, empirical, and computational approaches inherent in these contributing disciplines.15

The institutionalization process gained significant momentum in the late 1970s. Key research centers, often located at universities with strong programs in the contributing fields like MIT 6 and Carnegie Mellon University 15, served as early hubs for interdisciplinary collaboration. J.C.R. Licklider's work at the MIT Sloan School of Management, using computer memory as models for cognition, represents one of the earliest instances of cognitive science experiments within an academic setting.12

Crucial financial support came from the Alfred P. Sloan Foundation through its "Particular Program in Cognitive Science" launched in the late 1970s.13 This program provided substantial grants to a select group of universities specifically to foster the growth of this nascent interdisciplinary field.13 This funding was instrumental in establishing dedicated research programs and training initiatives, lending institutional legitimacy to cognitive science. However, the process was not without friction. An internal 1978 report commissioned by the Sloan Foundation revealed significant "tensions" and lack of consensus among researchers regarding the field's definition, scope, methods, and direction.13 The report encountered such strong opposition that it was never published, indicating deep divisions and competing paradigms even during the field's formative stages.13

Despite these internal debates, formal structures emerged to solidify the field. The *Cognitive Science Society (CSS)* was founded in 1979, following an inaugural meeting at UC San Diego.12 Its stated mission was, and remains, to promote cognitive science as a discipline and foster interchange among researchers from its diverse constituent areas.70 The society launched the annual *Cognitive Science Conference* (CogSci), providing a regular international forum for presenting interdisciplinary research.79 Concurrently, dedicated academic journals were established, most notably the journal *Cognitive Science* itself (founded in 1977 13), followed later by others like *Topics in Cognitive Science* (TopiCS).70 These journals and conferences created essential platforms for communication, peer review, and the development of a shared identity for the field.12

Cognitive science was often envisioned as playing a mediating role, providing a common ground where the abstract theories of philosophy, the empirical methods of psychology, and the constructive approaches of AI could converge.4 The shared language often revolved around the concepts of computation and information processing, offering a potentially unifying framework.4 It aimed to integrate insights from different levels of analysis—from neural mechanisms (neuroscience) to individual cognitive processes (psychology, linguistics, AI) to social and cultural contexts (anthropology).78

The process of institutionalization, however, carried inherent complexities. While essential for establishing cognitive science as a recognized field, fostering collaboration, and securing resources, the creation of formal structures (societies, journals, funding priorities, curricula) likely influenced its trajectory. The initial dominance of computational and representational ideas, championed by many of the field's founders 4, may have been reinforced by these institutional mechanisms. This could have made it more challenging, at least initially, for alternative perspectives (such as those emphasizing embodiment, dynamic systems, or non-computational aspects of mind) to gain equal footing. Indeed, later critiques have suggested that cognitive science, despite its interdisciplinary aims, sometimes struggled to achieve true integration and risked becoming dominated by the methods and assumptions of cognitive psychology.13 Thus, the very structures that enabled the field's birth may also have shaped its development in ways that reflected the specific intellectual currents prevalent at its inception.

## **IX. Internal Fissures: Debates Shaping the Disciplines**

While the computational metaphor provided a unifying theme for early cognitive science and AI, the field was far from monolithic. Significant internal debates emerged, challenging core assumptions and driving theoretical development across philosophy, AI, and psychology. Two of the most prominent fissures concerned the nature of computation and the necessity of representation.

**Symbolic vs. Connectionist Approaches:**

Although symbolic AI (GOFAI), based on rule-governed manipulation of explicit symbols, dominated the field from the mid-1950s to the mid-1980s 46, an alternative approach rooted in modeling brain-like networks had early precursors. The work of McCulloch and Pitts on logical neurons 12 and Frank Rosenblatt's Perceptron 58 explored computation in networks of simple processing units. However, these connectionist ideas were largely eclipsed during the "AI winter" of the 1970s and the peak of GOFAI.48

The debate reignited dramatically in the mid-1980s with the publication of the influential *Parallel Distributed Processing (PDP)* volumes by Rumelhart, McClelland, and the PDP Research Group.86 This marked the resurgence of *connectionism*, which proposed that cognition arises not from manipulating discrete symbols according to explicit rules, but from the collective activity of large networks of simple, interconnected units (artificial neurons).12 Connectionist models emphasized learning through the adjustment of connection strengths based on experience (data), distributed representations (where concepts are represented by patterns of activity across many units), and parallel processing.86

This led to a sometimes-heated debate between the symbolic and connectionist camps throughout the late 1980s and 1990s.85 Connectionists argued that their approach was more biologically plausible, better equipped to handle noisy data and pattern recognition, and could explain learning without requiring pre-programmed knowledge.85 Some proponents claimed connectionism could supersede symbolic AI entirely.86 Symbolic AI proponents, conversely, criticized connectionist models for their opacity, their difficulties in representing complex compositional structures (like language syntax), and their struggles with high-level reasoning and planning.85 They argued that explicit knowledge representation and rule-based inference were essential for general intelligence.88 Philosophically, the debate was sometimes framed as a modern incarnation of the empiricism (connectionism, learning from data) versus rationalism (symbolic AI, innate knowledge/structures) divide.86 This debate played out across AI, cognitive science, and philosophy, forcing researchers to reconsider the fundamental mechanisms of computation and learning in the mind.85

**Representationalism vs. Anti-Representationalism:**

The classical view, underpinning both GOFAI and mainstream cognitive science, was strongly *representationalist*: cognition fundamentally involves creating and manipulating internal representations of the external world.4 These representations were typically conceived as symbolic structures within a computational system.

This orthodoxy faced a significant challenge from philosopher Hubert Dreyfus, beginning with his critiques in the 1960s and 70s.90 Drawing heavily on continental philosophers like Heidegger and Merleau-Ponty, Dreyfus launched a sustained attack on the core assumptions of GOFAI.90 He argued that human intelligence, particularly expert skill, does not primarily rely on conscious deliberation over symbolic representations according to formal rules.43 Instead, expertise involves an intuitive, embodied "knowing-how" that arises from experience and situated practice.90 As individuals acquire skills, they move from explicit rule-following (like a novice) to fluid, context-sensitive action that bypasses conscious representation and calculation.90 Furthermore, Dreyfus emphasized the role of the unconscious "background"—a vast web of shared cultural practices, assumptions, and bodily skills—that shapes our perception and understanding of situations, allowing us to grasp relevance and act appropriately without needing to represent everything explicitly.90 He argued that this background understanding is inherently non-representational and cannot be formalized into the discrete facts and rules required by symbolic AI.90 Dreyfus attacked what he called the "psychological assumption" (that the mind operates on information like a computer) and the "epistemological assumption" (that all knowledge can be formalized symbolically).43

Dreyfus's critique, along with related work, helped inspire alternative approaches in AI and cognitive science that downplayed or rejected the centrality of internal symbolic representations. These include *embodied cognition* (emphasizing the role of the body in shaping thought), *situated robotics* (e.g., Rodney Brooks' work on robots that interact directly with their environment without complex internal models 64), and *enactivism* (viewing cognition as sense-making emerging from the dynamic interaction between an organism and its environment).63 This representationalism vs. anti-representationalism debate forced a critical re-examination of the foundational role of representation in cognitive theories.63

These internal fissures were more than just intellectual disagreements; they were crucial engines of theoretical and empirical progress. The challenges posed by connectionism forced symbolic AI proponents to address issues of learning, robustness, and biological plausibility, eventually leading towards hybrid neuro-symbolic approaches.46 Similarly, Dreyfus's phenomenological critique compelled the field to take seriously the roles of embodiment, skill, context, and non-conscious processing, pushing beyond the purely abstract, disembodied view of mind often associated with early computationalism.90 The ensuing debates led to a clarification of assumptions, the identification of weaknesses in existing paradigms, and the exploration of entirely new theoretical frameworks. This dialectical process, playing out across philosophy, AI, and psychology, ultimately resulted in a richer, more diverse, and more nuanced understanding of the complexities involved in modeling mind and intelligence.

## **X. Echoes in the Present: Legacy and Limits of the Computational Metaphor**

The intense period of co-evolution between philosophy, AI, and cognitive science in the mid-20th century left an indelible legacy that continues to shape these fields today. The concepts and frameworks forged in that era, particularly the computational view of mind, remain foundational, yet their limitations are also increasingly apparent.

**The Enduring Legacy:**

The cognitive revolution, fueled by computational ideas, permanently shifted the landscape of psychology and related fields away from strict behaviorism, establishing the study of internal mental processes as a legitimate scientific endeavor.3 Cognitive science itself, as an interdisciplinary field, is a direct product of this era, institutionalizing the collaboration between psychology, AI, linguistics, philosophy, and neuroscience.12

Core concepts popularized during this time—computation, representation, information processing, algorithm, symbol manipulation—became the standard vocabulary for discussing mental phenomena and designing intelligent systems.4 Philosophical theories born from this interaction, especially functionalism and the computational theory of mind, remain central topics in contemporary philosophy of mind, even if they face more challenges now.2

In artificial intelligence, the legacy of GOFAI persists. While deep learning and connectionist approaches currently dominate many applications, symbolic AI techniques remain crucial for tasks involving explicit knowledge representation, logical reasoning, planning, and explainability.46 Furthermore, the limitations of purely connectionist or purely symbolic approaches have spurred growing interest in *hybrid architectures* (e.g., neuro-symbolic AI) that seek to combine the strengths of both traditions—a direction implicitly acknowledging the value of the symbolic reasoning paradigm pioneered by GOFAI.46 The fundamental goal of modeling cognitive processes, central to the cognitive revolution, continues to inspire AI research seeking to understand and replicate human-like intelligence.95

**Critiques and Limitations of the Computational Metaphor:**

Despite its productivity, the computational metaphor for the mind faces significant limitations and criticisms, many of which echo the challenges identified during its formative period:

1. **Consciousness and Qualia:** Perhaps the most persistent challenge is explaining subjective experience, or *qualia*—the "what it's like" aspect of consciousness—within a purely computational framework.2 Critics argue that computation, being defined by formal symbol manipulation or functional roles, inherently fails to capture the qualitative nature of experience. Arguments like Searle's Chinese Room (questioning understanding based on symbol manipulation) and philosophical thought experiments concerning qualia (like Jackson's Knowledge Argument) suggest that something essential is missing from computational accounts.2 Can a system merely executing algorithms truly *feel* pain or *see* red?  
2. **Embodiment and Situatedness:** Classical computationalism often treated the mind as an abstract information processor, largely divorced from the body and the environment—a "brain in a vat" running software.38 Critics like Dreyfus, and proponents of embodied, embedded, enactive, and extended (4E) cognition, argue that this neglects the crucial role of the physical body, sensory-motor interactions, and the environmental context in shaping cognition.63 Intelligence may not reside solely "in the head" but emerge from the dynamic interplay between brain, body, and world.  
3. **Meaning and Understanding (Symbol Grounding):** The symbol grounding problem remains a fundamental issue.33 How do the internal symbols manipulated by a computational system (whether a GOFAI program or potentially even the brain's neural code) acquire genuine meaning and refer to things in the world? Searle's argument that syntax does not suffice for semantics continues to resonate.33 Without grounding in perceptual experience and action, computational symbols risk being meaningless tokens, manipulated according to rules but lacking real understanding.67 This challenge applies even to modern AI, raising questions about whether large language models truly "understand" the text they process.  
4. **Oversimplification and Reductionism:** There is concern that the computational metaphor, while powerful, might oversimplify the richness and complexity of mental life.16 Reducing thought, emotion, creativity, and consciousness to mere computation risks overlooking essential non-computational or qualitatively different aspects of mind.  
5. **Physical Limits:** Some recent arguments even question whether the brain, as a physical system, has the necessary information storage capacity to implement the kind of classical digital computation required to encode the richness and historical dependency of conscious experience.97 This suggests potential physical limitations to the literal interpretation of the brain-as-digital-computer model.  
6. **Metaphor vs. Literal Truth:** It is crucial to distinguish between the *metaphor* of the mind being like a computer, which can be a useful heuristic, and the *literal claim* of CTM that the mind *is* a computational system.1 Many critiques target the stronger, literal claim, arguing that computation is either insufficient or not the right kind of process to constitute mind and consciousness.96

The computational metaphor undeniably acted as a powerful catalyst, enabling the cognitive revolution and providing a unifying framework that spurred decades of research in multiple fields. Its emphasis on mechanism, information processing, and formal models brought scientific rigor to the study of the mind and provided the blueprint for artificial intelligence. However, its very success and elegance may have led to its overextension, potentially obscuring or undervaluing aspects of cognition—consciousness, embodiment, semantics, intuition—that fit less neatly into a purely computational mold. The persistent challenges and critiques highlight the metaphor's limitations, driving ongoing research into alternative and complementary paradigms for understanding the intricate relationship between mind, brain, and computation. The dialogue sparked in the mid-20th century continues, fueled by the enduring power and the recognized limits of viewing the mind as a machine.

## **XI. Conclusion: Mind, Machine, and the Unfolding Dialogue**

The mid-20th century represents a pivotal crucible in the history of ideas about the mind. The period witnessed an unprecedented convergence and co-evolution of analytic philosophy of mind, the nascent field of artificial intelligence, and the emerging discipline of cognitive science. This report has traced the intricate web of influence, demonstrating that these fields were not isolated developments but participants in a dynamic intellectual ecosystem, bound together by the powerful, pervasive, yet ultimately contested, framework of computation.

The journey began with the decline of behaviorism, which created a conceptual space filled by the computational metaphor, offering a seemingly scientific way to explore the internal workings of the mind. Philosophical theories like functionalism, particularly Putnam's machine-state variant, drew directly from computer science concepts while simultaneously providing philosophical legitimacy for the strong AI project through the notion of multiple realizability. Fodor's Language of Thought hypothesis further cemented the link, proposing that thought itself is computation over a symbolic mental language, a view that resonated deeply with the methods of symbolic AI (GOFAI). Concurrently, AI pioneers like Turing, Newell, and Simon developed work that functioned as both engineering feats and empirical tests of cognitive and philosophical theories, operationalizing ideas about intelligence, reasoning, and problem-solving. Chomsky's linguistic revolution provided crucial support for internal representations and rule-based systems, directly influencing early AI approaches to language.

This co-evolution was facilitated by the transfer of core concepts—representation, computation, information, algorithm, symbol—across disciplinary boundaries, often through interdisciplinary forums and the mediating structure of the newly institutionalized field of cognitive science. Yet, the very ambiguity that allowed these concepts to travel also masked underlying differences, leading to fundamental challenges like the symbol grounding problem, articulated powerfully by Searle's Chinese Room argument. Internal debates, such as the symbolic versus connectionist divide and the critique of representationalism led by figures like Dreyfus, further shaped the trajectory of these fields, exposing limitations and driving theoretical refinement.

The legacy of this era is profound and undeniable. The conceptual toolkit forged during this period continues to underpin much of contemporary cognitive science, AI, and philosophy of mind. Functionalism and computationalism remain central philosophical positions, while symbolic AI principles inform aspects of modern AI systems, particularly in hybrid approaches. The very existence of cognitive science as an interdisciplinary endeavor is a testament to the vision of integration born in this period.

However, the limitations of the purely computational paradigm, particularly regarding consciousness, meaning, and embodiment, also represent a crucial part of this legacy. The critiques raised by Searle, Dreyfus, and others highlight the aspects of mind that seem to resist straightforward computational explanation, fueling ongoing research into alternative frameworks like connectionism, dynamic systems theory, and embodied cognition. Understanding the historical origins of the computational metaphor—its initial necessity as an escape from behaviorism, its powerful synergy with early AI, and the philosophical assumptions it carried—provides essential context for navigating contemporary debates. Issues in modern AI ethics, such as the potential for machine consciousness, the nature of understanding in large language models, and the biases embedded in algorithms, are deeply connected to the foundational questions about representation, computation, and meaning debated decades ago. Similarly, the enduring philosophical quest to understand consciousness and the mind-body problem continues to grapple with the implications and shortcomings of the computational view.

In conclusion, the "Mind as Machine, Machine as Mind" framing, born in the mid-20th century crucible, was extraordinarily generative, launching new fields and transforming our understanding of intelligence. Yet, it also revealed deep conceptual challenges that remain unresolved. The ongoing dialogue between philosophy, cognitive science, AI, and neuroscience—a dialogue profoundly shaped by the interactions explored in this report—remains crucial as we continue to probe the mysteries of both natural and artificial minds, constantly negotiating the power and the peril of our metaphors.

#### **Works cited**

1. The Computational Theory of Mind (Stanford Encyclopedia of Philosophy/Winter 2006), accessed April 21, 2025, [https://plato.stanford.edu/archIves/win2006/entries/computational-mind/](https://plato.stanford.edu/archIves/win2006/entries/computational-mind/)  
2. Computational theory of mind \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Computational\_theory\_of\_mind](https://en.wikipedia.org/wiki/Computational_theory_of_mind)  
3. Cognitive revolution \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Cognitive\_revolution](https://en.wikipedia.org/wiki/Cognitive_revolution)  
4. Cognitive Science (Stanford Encyclopedia of Philosophy), accessed April 21, 2025, [https://plato.stanford.edu/entries/cognitive-science/](https://plato.stanford.edu/entries/cognitive-science/)  
5. Hilary Putnam and computational functionalism \- HUJI OpenScholar, accessed April 21, 2025, [https://openscholar.huji.ac.il/sites/default/files/oronshagrir/files/putnam\_and\_computational\_functionalism\_chapter\_8.pdf](https://openscholar.huji.ac.il/sites/default/files/oronshagrir/files/putnam_and_computational_functionalism_chapter_8.pdf)  
6. The beginning of the cognitive revolution began in 1956, the ye \- Norm Friesen, accessed April 21, 2025, [https://www.normfriesen.info/papers/edtechinreverse.html](https://www.normfriesen.info/papers/edtechinreverse.html)  
7. The Computational Theory of Mind \- Stanford Encyclopedia of Philosophy, accessed April 21, 2025, [https://plato.stanford.edu/entries/computational-mind/](https://plato.stanford.edu/entries/computational-mind/)  
8. Behaviorism | Internet Encyclopedia of Philosophy, accessed April 21, 2025, [https://iep.utm.edu/behaviorism/](https://iep.utm.edu/behaviorism/)  
9. Functionalism (philosophy of mind) \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Functionalism\_(philosophy\_of\_mind)](https://en.wikipedia.org/wiki/Functionalism_\(philosophy_of_mind\))  
10. Student Question : What are Chomsky's criticisms of Behaviorism in the context of language acquisition? | Education Studies | QuickTakes, accessed April 21, 2025, [https://quicktakes.io/learn/education-studies/questions/what-are-chomskys-criticisms-of-behaviorism-in-the-context-of-language-acquisition](https://quicktakes.io/learn/education-studies/questions/what-are-chomskys-criticisms-of-behaviorism-in-the-context-of-language-acquisition)  
11. How did Chomsky debunk behaviorism? : r/askphilosophy \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/askphilosophy/comments/9hcchx/how\_did\_chomsky\_debunk\_behaviorism/](https://www.reddit.com/r/askphilosophy/comments/9hcchx/how_did_chomsky_debunk_behaviorism/)  
12. Cognitive science \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Cognitive\_science](https://en.wikipedia.org/wiki/Cognitive_science)  
13. aaron-zimmerman.com, accessed April 21, 2025, [https://aaron-zimmerman.com/wp-content/uploads/2022/02/Nunez-What-happened-to-Cog-Sci-2019.pdf](https://aaron-zimmerman.com/wp-content/uploads/2022/02/Nunez-What-happened-to-Cog-Sci-2019.pdf)  
14. Information processing, computation, and cognition \- PMC, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC3006465/](https://pmc.ncbi.nlm.nih.gov/articles/PMC3006465/)  
15. Cognitive Science: History \- William Bechtel, accessed April 21, 2025, [https://mechanism.ucsd.edu/\~bill/teaching/w07/philpsych/bechtel.cogscihistory.pdf](https://mechanism.ucsd.edu/~bill/teaching/w07/philpsych/bechtel.cogscihistory.pdf)  
16. The Mind as a Computer: The Computational Model Explained \- Philosophy Institute, accessed April 21, 2025, [https://philosophy.institute/philosophy-of-technology/mind-as-computer-computational-model/](https://philosophy.institute/philosophy-of-technology/mind-as-computer-computational-model/)  
17. Functionalism in Philosophy of the Mind | Evolution News and Science Today, accessed April 21, 2025, [https://evolutionnews.org/2015/11/functionalism\_i/](https://evolutionnews.org/2015/11/functionalism_i/)  
18. Language Acquisition Theory \- Simply Psychology, accessed April 21, 2025, [https://www.simplypsychology.org/language.html](https://www.simplypsychology.org/language.html)  
19. Noam Chomsky's Theory of Language Acquisition | Listening, accessed April 21, 2025, [https://www.listening.com/blog/noam-chomskys-theory-of-language-acquisition](https://www.listening.com/blog/noam-chomskys-theory-of-language-acquisition)  
20. Noam Chomsky \- (Intro to Cognitive Science) \- Vocab, Definition, Explanations | Fiveable, accessed April 21, 2025, [https://fiveable.me/key-terms/introduction-cognitive-science/noam-chomsky](https://fiveable.me/key-terms/introduction-cognitive-science/noam-chomsky)  
21. Language acquisition device \- (Intro to Linguistics) \- Vocab, Definition, Explanations, accessed April 21, 2025, [https://library.fiveable.me/key-terms/introduction-linguistics/language-acquisition-device](https://library.fiveable.me/key-terms/introduction-linguistics/language-acquisition-device)  
22. Chomsky's Theory \- Structural Learning, accessed April 21, 2025, [https://www.structural-learning.com/post/chomskys-theory](https://www.structural-learning.com/post/chomskys-theory)  
23. Generative grammar \- (Intro to Humanities) \- Vocab, Definition, Explanations | Fiveable, accessed April 21, 2025, [https://library.fiveable.me/key-terms/introduction-humanities/generative-grammar](https://library.fiveable.me/key-terms/introduction-humanities/generative-grammar)  
24. Noam Chomsky \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Noam\_Chomsky](https://en.wikipedia.org/wiki/Noam_Chomsky)  
25. The Mind/Brain Identity Theory \- Stanford Encyclopedia of Philosophy, accessed April 21, 2025, [https://plato.stanford.edu/entries/mind-identity/](https://plato.stanford.edu/entries/mind-identity/)  
26. Functionalism (Stanford Encyclopedia of Philosophy/Fall 2017 Edition), accessed April 21, 2025, [https://plato.stanford.edu/archivES/FALL2017/entries/functionalism/](https://plato.stanford.edu/archivES/FALL2017/entries/functionalism/)  
27. Functionalism (Stanford Encyclopedia of Philosophy), accessed April 21, 2025, [https://plato.stanford.edu/entries/functionalism/](https://plato.stanford.edu/entries/functionalism/)  
28. Functionalism \- Internet Encyclopedia of Philosophy, accessed April 21, 2025, [https://iep.utm.edu/functism/](https://iep.utm.edu/functism/)  
29. Functionalism (Stanford Encyclopedia of Philosophy/Spring 2010 Edition), accessed April 21, 2025, [https://plato.stanford.edu/archIves/spr2010/entries/functionalism/](https://plato.stanford.edu/archIves/spr2010/entries/functionalism/)  
30. Hilary Putnam \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Hilary\_Putnam](https://en.wikipedia.org/wiki/Hilary_Putnam)  
31. Computational Theory of Mind | Internet Encyclopedia of Philosophy, accessed April 21, 2025, [https://iep.utm.edu/computational-theory-of-mind/](https://iep.utm.edu/computational-theory-of-mind/)  
32. Mental Representation (Stanford Encyclopedia of Philosophy/Spring 2013 Edition), accessed April 21, 2025, [https://plato.stanford.edu/ARCHIVES/SPR2013/ENTRIES/mental-representation/](https://plato.stanford.edu/ARCHIVES/SPR2013/ENTRIES/mental-representation/)  
33. Chinese Room Argument | Internet Encyclopedia of Philosophy, accessed April 21, 2025, [https://iep.utm.edu/chinese-room-argument/](https://iep.utm.edu/chinese-room-argument/)  
34. History of artificial intelligence | Dates, Advances, Alan Turing, ELIZA, & Facts | Britannica, accessed April 21, 2025, [https://www.britannica.com/science/history-of-artificial-intelligence](https://www.britannica.com/science/history-of-artificial-intelligence)  
35. Turing Invents the Universal Turing Machine | EBSCO Research Starters, accessed April 21, 2025, [https://www.ebsco.com/research-starters/computer-science/turing-invents-universal-turing-machine](https://www.ebsco.com/research-starters/computer-science/turing-invents-universal-turing-machine)  
36. History of Artificial Intelligence: The Turing test \- ICT Institute, accessed April 21, 2025, [https://ictinstitute.nl/history-of-artificial-intelligence-the-turing-test/](https://ictinstitute.nl/history-of-artificial-intelligence-the-turing-test/)  
37. Turing test \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Turing\_test](https://en.wikipedia.org/wiki/Turing_test)  
38. History, motivations and core themes of AI \- University of Memphis Digital Commons, accessed April 21, 2025, [https://digitalcommons.memphis.edu/cgi/viewcontent.cgi?article=1029\&context=ccrg\_papers](https://digitalcommons.memphis.edu/cgi/viewcontent.cgi?article=1029&context=ccrg_papers)  
39. The Turing Test (Stanford Encyclopedia of Philosophy), accessed April 21, 2025, [https://plato.stanford.edu/entries/turing-test/](https://plato.stanford.edu/entries/turing-test/)  
40. History of artificial intelligence \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/History\_of\_artificial\_intelligence](https://en.wikipedia.org/wiki/History_of_artificial_intelligence)  
41. Turing's Test, a Beautiful Thought Experiment \- IEEE Computer Society, accessed April 21, 2025, [https://www.computer.org/csdl/magazine/an/2024/03/10614793/1Z0o1iK0CY0](https://www.computer.org/csdl/magazine/an/2024/03/10614793/1Z0o1iK0CY0)  
42. The Physical Symbol System Hypothesis: Status and Prospects \- Stanford AI Lab, accessed April 21, 2025, [https://ai.stanford.edu/\~nilsson/OnlinePubs-Nils/PublishedPapers/pssh.pdf](https://ai.stanford.edu/~nilsson/OnlinePubs-Nils/PublishedPapers/pssh.pdf)  
43. Physical symbol system \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Physical\_symbol\_system](https://en.wikipedia.org/wiki/Physical_symbol_system)  
44. Physical Symbol Systems' \- Carnegie Mellon University, accessed April 21, 2025, [http://iiif.library.cmu.edu/file/Newell\_box00042\_fld03481\_doc0001/Newell\_box00042\_fld03481\_doc0001.pdf](http://iiif.library.cmu.edu/file/Newell_box00042_fld03481_doc0001/Newell_box00042_fld03481_doc0001.pdf)  
45. The Rise of Cognitive Science in the 20th Century \- PhilArchive, accessed April 21, 2025, [https://philarchive.org/archive/FIGTRO-9](https://philarchive.org/archive/FIGTRO-9)  
46. GOFAI \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/GOFAI](https://en.wikipedia.org/wiki/GOFAI)  
47. symsearch\_small.txt \- Advances in Cognitive Systems, accessed April 21, 2025, [http://cogsys.org/courses/langley/aicogsys11/notes/symsearch\_small.pdf](http://cogsys.org/courses/langley/aicogsys11/notes/symsearch_small.pdf)  
48. Symbolic artificial intelligence \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Symbolic\_artificial\_intelligence](https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence)  
49. (PDF) Philosophical Foundations of AI \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/221471984\_Philosophical\_Foundations\_of\_AI](https://www.researchgate.net/publication/221471984_Philosophical_Foundations_of_AI)  
50. The Language of Thought Hypothesis (Stanford Encyclopedia of Philosophy), accessed April 21, 2025, [https://plato.stanford.edu/entries/language-thought/](https://plato.stanford.edu/entries/language-thought/)  
51. Jerry Fodor \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Jerry\_Fodor](https://en.wikipedia.org/wiki/Jerry_Fodor)  
52. Representation in Artificial Intelligence \- Bibliography \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/browse/representation-in-artificial-intelligence](https://philpapers.org/browse/representation-in-artificial-intelligence)  
53. Language of thought hypothesis \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Language\_of\_thought\_hypothesis](https://en.wikipedia.org/wiki/Language_of_thought_hypothesis)  
54. Language of Thought Hypothesis | Internet Encyclopedia of Philosophy, accessed April 21, 2025, [https://iep.utm.edu/lot-hypo/](https://iep.utm.edu/lot-hypo/)  
55. Syntactic Semantics and the Proper Treatment of Computationalism, accessed April 21, 2025, [http://www.cse.buffalo.edu/\~rapaport/Papers/rapaport2018-SynSemProperTreatmentComplete.pdf](http://www.cse.buffalo.edu/~rapaport/Papers/rapaport2018-SynSemProperTreatmentComplete.pdf)  
56. Noam Chomsky publishes his groundbreaking book "Syntactic Structures" | February 14, 1957 | HISTORY, accessed April 21, 2025, [https://www.history.com/this-day-in-history/february-14/noam-chomsky-publishes-syntactic-structures](https://www.history.com/this-day-in-history/february-14/noam-chomsky-publishes-syntactic-structures)  
57. Noam Chomsky | Linguistics \- The University of Arizona, accessed April 21, 2025, [https://linguistics.arizona.edu/person/noam-chomsky](https://linguistics.arizona.edu/person/noam-chomsky)  
58. History Of Natural Language Processing \- Let's Data Science, accessed April 21, 2025, [https://letsdatascience.com/learn/history/history-of-natural-language-processing/](https://letsdatascience.com/learn/history/history-of-natural-language-processing/)  
59. Chomsky Model \- Lark, accessed April 21, 2025, [https://www.larksuite.com/en\_us/topics/ai-glossary/chomsky-model](https://www.larksuite.com/en_us/topics/ai-glossary/chomsky-model)  
60. Atlantis Press, accessed April 21, 2025, [https://www.atlantis-press.com/article/25869679.pdf](https://www.atlantis-press.com/article/25869679.pdf)  
61. The computational origin of representation \- PMC \- PubMed Central, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC8300595/](https://pmc.ncbi.nlm.nih.gov/articles/PMC8300595/)  
62. Methods in Mind: Explanation in Cognitive Science Andrew Richmond Submitted in partial fulfillment of the requirements for the d \- Columbia Academic Commons, accessed April 21, 2025, [https://academiccommons.columbia.edu/doi/10.7916/nxec-6v88/download](https://academiccommons.columbia.edu/doi/10.7916/nxec-6v88/download)  
63. Representationalism or Anti-representationalism? \- NTNU, accessed April 21, 2025, [https://www.ntnu.edu/documents/38274365/0/Structural+collaboration+project\_2011\_+final.pdf/d3fb5c0f-2ad9-0f90-2f09-467c0f061cc8?t=1709107751997](https://www.ntnu.edu/documents/38274365/0/Structural+collaboration+project_2011_+final.pdf/d3fb5c0f-2ad9-0f90-2f09-467c0f061cc8?t=1709107751997)  
64. AI without Representation? \- Bibliography \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/browse/ai-without-representation](https://philpapers.org/browse/ai-without-representation)  
65. Mixing Cognitive Science Concepts with Computer Science Algorithms and Data Structures: An Integrative Approach to Strong AI \- AAAI, accessed April 21, 2025, [https://cdn.aaai.org/Symposia/Spring/2006/SS-06-02/SS06-02-018.pdf](https://cdn.aaai.org/Symposia/Spring/2006/SS-06-02/SS06-02-018.pdf)  
66. Symbol grounding problem \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Symbol\_grounding\_problem](https://en.wikipedia.org/wiki/Symbol_grounding_problem)  
67. Minds, Machines, and Metaphors \- DiVA portal, accessed April 21, 2025, [http://www.diva-portal.org/smash/get/diva2:1878889/FULLTEXT01.pdf](http://www.diva-portal.org/smash/get/diva2:1878889/FULLTEXT01.pdf)  
68. A new chapter for a key partner | Carney Institute for Brain Science | Brown University, accessed April 21, 2025, [https://carney.brown.edu/news/2025-03-27/copsy](https://carney.brown.edu/news/2025-03-27/copsy)  
69. Department of Brain and Cognitive Sciences | MIT Course Catalog, accessed April 21, 2025, [https://catalog.mit.edu/schools/science/brain-cognitive-sciences/](https://catalog.mit.edu/schools/science/brain-cognitive-sciences/)  
70. Cognitive Science Society: Home, accessed April 21, 2025, [https://cognitivesciencesociety.org/](https://cognitivesciencesociety.org/)  
71. UC Merced \- Proceedings of the Annual Meeting of the Cognitive Science Society \- eScholarship, accessed April 21, 2025, [https://escholarship.org/content/qt0m78k9jj/qt0m78k9jj.pdf?t=ssy992](https://escholarship.org/content/qt0m78k9jj/qt0m78k9jj.pdf?t=ssy992)  
72. Chinese room \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Chinese\_room](https://en.wikipedia.org/wiki/Chinese_room)  
73. Understanding SHRDLU: A Pioneering AI in Language and Reasoning \- CryptLabs, accessed April 21, 2025, [https://cryptlabs.com/understanding-shrdlu-a-pioneering-ai-in-language-and-reasoning/](https://cryptlabs.com/understanding-shrdlu-a-pioneering-ai-in-language-and-reasoning/)  
74. The Chinese Room \- Bibliography \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/browse/the-chinese-room](https://philpapers.org/browse/the-chinese-room)  
75. www.cs.ox.ac.uk, accessed April 21, 2025, [https://www.cs.ox.ac.uk/activities/ieg/e-library/sources/harnad90\_sgproblem.pdf](https://www.cs.ox.ac.uk/activities/ieg/e-library/sources/harnad90_sgproblem.pdf)  
76. The Difficulties in Symbol Grounding Problem and the Direction for Solving It \- MDPI, accessed April 21, 2025, [https://www.mdpi.com/2409-9287/7/5/108](https://www.mdpi.com/2409-9287/7/5/108)  
77. Philosophy of artificial intelligence – Knowledge and References \- Taylor & Francis, accessed April 21, 2025, [https://taylorandfrancis.com/knowledge/Engineering\_and\_technology/Artificial\_intelligence/Philosophy\_of\_artificial\_intelligence/](https://taylorandfrancis.com/knowledge/Engineering_and_technology/Artificial_intelligence/Philosophy_of_artificial_intelligence/)  
78. (PDF) Why Cognitive Science Needs Philosophy and Vice Versa, accessed April 21, 2025, [https://www.researchgate.net/publication/227689005\_Why\_Cognitive\_Science\_Needs\_Philosophy\_and\_Vice\_Versa](https://www.researchgate.net/publication/227689005_Why_Cognitive_Science_Needs_Philosophy_and_Vice_Versa)  
79. Future Conferences \- Cognitive Science Society, accessed April 21, 2025, [https://cognitivesciencesociety.org/future-conferences/](https://cognitivesciencesociety.org/future-conferences/)  
80. Proceedings of the Annual Meeting of the Cognitive Science Society, Volume 43 \- eScholarship.org, accessed April 21, 2025, [https://escholarship.org/uc/cognitivesciencesociety/43/43](https://escholarship.org/uc/cognitivesciencesociety/43/43)  
81. Proceedings of the Annual Meeting of the Cognitive Science Society, Volume 45 \- eScholarship.org, accessed April 21, 2025, [https://escholarship.org/uc/cognitivesciencesociety/45/45](https://escholarship.org/uc/cognitivesciencesociety/45/45)  
82. Topics in Cognitive Science \- Impact Factor & Score 2025 | Research.com, accessed April 21, 2025, [https://research.com/journal/topics-in-cognitive-science](https://research.com/journal/topics-in-cognitive-science)  
83. Upcoming events in Philosophy of Cognitive Science \- PhilEvents, accessed April 21, 2025, [https://philevents.org/search/topic/599](https://philevents.org/search/topic/599)  
84. A Brief History of AI — Making Things Think \- Holloway, accessed April 21, 2025, [https://www.holloway.com/g/making-things-think/sections/a-brief-history-of-ai](https://www.holloway.com/g/making-things-think/sections/a-brief-history-of-ai)  
85. Connectionism \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Connectionism](https://en.wikipedia.org/wiki/Connectionism)  
86. ojs.aaai.org, accessed April 21, 2025, [https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/download/15111/18883](https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/download/15111/18883)  
87. AI for Beginners \- The Difference Between Symbolic & Connectionist AI \- RE•WORK Blog, accessed April 21, 2025, [https://blog.re-work.co/the-difference-between-symbolic-ai-and-connectionist-ai/](https://blog.re-work.co/the-difference-between-symbolic-ai-and-connectionist-ai/)  
88. ojs.aaai.org, accessed April 21, 2025, [https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/download/15111/18883\#:\~:text=While%20symbolic%20AI%20posits%20the,is%20crucial%20for%20understanding%20behavior.](https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/download/15111/18883#:~:text=While%20symbolic%20AI%20posits%20the,is%20crucial%20for%20understanding%20behavior.)  
89. Looking Back, Looking Ahead: Symbolic versus Connectionist AI \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/368526819\_Looking\_Back\_Looking\_Ahead\_Symbolic\_versus\_Connectionist\_AI](https://www.researchgate.net/publication/368526819_Looking_Back_Looking_Ahead_Symbolic_versus_Connectionist_AI)  
90. Hubert Dreyfus's views on artificial intelligence \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Hubert\_Dreyfus%27s\_views\_on\_artificial\_intelligence](https://en.wikipedia.org/wiki/Hubert_Dreyfus%27s_views_on_artificial_intelligence)  
91. Artificial Intelligence \- CORE, accessed April 21, 2025, [https://core.ac.uk/download/pdf/82441912.pdf](https://core.ac.uk/download/pdf/82441912.pdf)  
92. Why Dreyfus' Frame Problem Argument Cannot Justify Anti-Representational AI \- PhilArchive, accessed April 21, 2025, [https://philarchive.org/archive/SALWDF](https://philarchive.org/archive/SALWDF)  
93. Dreyfus | Minds and Brains, accessed April 21, 2025, [https://philosophyandpsychology.wordpress.com/tag/dreyfus/](https://philosophyandpsychology.wordpress.com/tag/dreyfus/)  
94. Influence of Cognitive Neuroscience on Contemporary Philosophy of Science \- PMC, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC6487795/](https://pmc.ncbi.nlm.nih.gov/articles/PMC6487795/)  
95. Initiative to support interaction between cognitive sciences and artificial intelligence, accessed April 21, 2025, [https://ai.princeton.edu/news/2024/initiative-support-interaction-between-cognitive-sciences-and-artificial-intelligence](https://ai.princeton.edu/news/2024/initiative-support-interaction-between-cognitive-sciences-and-artificial-intelligence)  
96. Why Computers Can't Be Conscious \- UX Magazine, accessed April 21, 2025, [https://uxmag.com/articles/why-computers-cant-be-conscious](https://uxmag.com/articles/why-computers-cant-be-conscious)  
97. Why the Brain Cannot Be a Digital Computer: History-Dependence and the Computational Limits of Consciousness \- arXiv, accessed April 21, 2025, [https://arxiv.org/html/2503.10518](https://arxiv.org/html/2503.10518)  
98. AI won't be conscious, and here is why (A reply to Susan Schneider), accessed April 21, 2025, [https://www.bernardokastrup.com/2023/01/ai-wont-be-conscious-and-here-is-why.html](https://www.bernardokastrup.com/2023/01/ai-wont-be-conscious-and-here-is-why.html)