# **From Metaphysical Unity to Disciplinary Divergence? Contemporary Relations Between Philosophy of Mind, AI, and Cognitive Science**

## **1\. Introduction: The Cognitive Triangle in Flux**

### **1.1. Setting the Stage**

The mid-twentieth century witnessed the birth of a revolutionary intellectual movement: the cognitive revolution. Emerging from perceived limitations of behaviorism, this movement sought to reinstate the mind as a legitimate object of scientific inquiry. Central to this endeavor was the convergence of three disciplines: philosophy of mind, providing the conceptual frameworks and foundational questions; artificial intelligence (AI), offering new tools for modeling and potentially replicating mental processes; and cognitive science, aiming to be the unifying interdisciplinary science of mind and intelligence.1 In its nascent stages, this "cognitive triangle" shared a powerful, unifying vision often centered on the concept of computation. The mind was conceived as an information processing system, akin in crucial respects to the newly developed digital computer, and thinking was understood as a form of computation.1 This computational metaphor provided a common language and a set of theoretical tools that promised to bridge disciplinary divides. Early cognitive science saw blurred boundaries, with active participation and cross-pollination of ideas among philosophers, psychologists, linguists, and computer scientists.1

### **1.2. The Central Question: Metaphysical Entanglement and Divergence**

This report investigates the evolution of the relationship between philosophy of mind, AI, and cognitive science, focusing specifically on their metaphysical entanglements and divergences from the 1980s to the present day \[User Query\]. The initial promise of unity, largely predicated on the computational paradigm, has faced numerous challenges and transformations over the past four decades. This analysis seeks to understand the trajectory of these fields' underlying assumptions about the fundamental nature of mind, cognition, computation, and representation.

Several core questions guide this investigation \[User Query\]:

* Have the significant technical and methodological shifts within AI—from symbolic systems to connectionism and deep learning—reflected or driven corresponding shifts in metaphysical orientation regarding the nature of computation and cognition?  
* How has the rise of alternative frameworks within philosophy and cognitive science, such as embodied, embedded, enactive, and extended (4E) cognition, impacted the traditional alliance, and why has their influence on mainstream AI been limited?  
* Does contemporary AI, particularly large language models (LLMs) and multimodal systems, still operate under the metaphysical assumptions of earlier eras (like computational functionalism or representationalism), or do these systems represent a fundamental break?  
* How has the increasing prominence of neuroscience reshaped the dialogue and alliances between philosophy, AI, and cognitive science, particularly concerning computational frameworks?  
* What persistent, and potentially unexamined, metaphysical assumptions (e.g., representationalism, information processing frameworks) continue to shape research across these fields, and what critiques are offered by non-Anglo-American philosophical traditions?  
* How have institutional forces, such as funding trends and commercial imperatives, influenced the interaction and potential decoupling of philosophical inquiry from AI development?  
* Are new metaphysical frameworks emerging in response to contemporary AI capabilities, and has the pragmatic success of AI diminished or stimulated interest in foundational philosophical questions about mind and cognition?

Ultimately, this report assesses the extent to which these fields have metaphysically diverged or fragmented, identifying hidden assumptions and evaluating the ongoing relevance of philosophical inquiry in the age of advanced AI \[User Query\].

### **1.3. Defining Key Terms**

For clarity, the following definitions will be employed:

* **Metaphysics:** Within this report's context, metaphysics refers primarily to the fundamental assumptions made within philosophy of mind, AI, and cognitive science concerning the nature of reality, particularly the nature of mental phenomena (mind, consciousness, intentionality), cognition, computation, information, representation, and causality.10 It involves examining the ontological commitments (what exists) and conceptual frameworks underlying these fields.  
* **Philosophy of Mind:** The branch of philosophy dedicated to understanding the nature of the mind, mental properties, consciousness, mental events, and their relationship to the physical body and the world.22  
* **Artificial Intelligence (AI):** The theory and development of computer systems able to perform tasks normally requiring human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages. It encompasses a wide range of techniques, from logic-based symbolic reasoning to data-driven machine learning.4  
* **Cognitive Science:** The interdisciplinary scientific study of the mind and its processes, drawing on philosophy, psychology, AI, neuroscience, linguistics, and anthropology to understand perception, language, memory, reasoning, and other aspects of cognition.1

The boundaries between these fields, particularly between philosophy and cognitive science, can be porous, with researchers often contributing across disciplines.1 This report acknowledges this interdisciplinarity while focusing on the evolution of their metaphysical relationships.

### **1.4. Roadmap**

This report proceeds as follows: Section 2 details the classical era of the 1980s, dominated by symbolic AI and the Computational Theory of Mind, establishing the initial metaphysical baseline. Section 3 examines the rise of connectionism in the late 1980s and 1990s and the intense philosophical debates it provoked, particularly regarding representation and systematicity. Section 4 analyzes the emergence of 4E cognition as a radical challenge to traditional views and explores its limited impact on mainstream AI. Section 5 investigates the growing influence of neuroscience and its complex effects on the cognitive triangle. Section 6 turns to contemporary AI, specifically deep learning and LLMs, assessing whether they signify a metaphysical break or continuity. Section 7 identifies persistent metaphysical assumptions, such as representationalism and the information processing metaphor, and incorporates critiques from non-Anglo-American philosophical traditions. Section 8 considers the role of institutional factors, including funding and commercialization, in potentially decoupling philosophical inquiry from AI development. Section 9 explores emerging theoretical frameworks like predictive processing and the Bayesian brain hypothesis, and evaluates the overall impact of AI's pragmatic success on foundational philosophical questions. Finally, Section 10 synthesizes the analysis, evaluating the degree of metaphysical divergence versus fragmentation and offering concluding thoughts on the future relationship between these fields.

The framing of this inquiry around an initial "Metaphysical Unity" \[User Query\] necessitates a careful examination of the classical era's dominant paradigm. While computationalism provided a powerful unifying framework 1, Section 2 will establish this baseline while also acknowledging the inherent tensions and immediate critiques that suggest this unity was perhaps more aspirational or programmatic than fully realized, setting the stage for subsequent diversification and divergence.

## **2\. The Classical Era (circa 1980s): The Reign of Symbolic AI and CTM**

### **2.1. The GOFAI Paradigm**

The landscape of artificial intelligence and cognitive science in the early 1980s was largely dominated by what John Haugeland later termed "Good Old-Fashioned AI" (GOFAI), or symbolic AI.5 This approach conceived of intelligence primarily as the manipulation of discrete, physical symbols according to explicit, formal rules.6 These symbols were intended to represent objects, properties, concepts, and facts about the world, possessing assigned semantics, much like words in a language.24 The core belief was that cognitive processes, particularly high-level reasoning, could be effectively modeled and replicated by designing algorithms that operated on these symbolic structures.

This paradigm drew heavily from the Western rationalist philosophical tradition, which posits abstract reason as the highest human faculty.33 GOFAI researchers aimed to capture this faculty through computational means. A key theoretical underpinning was the Physical Symbol System Hypothesis (PSSH), formulated by Allen Newell and Herbert Simon, which proposed that "a physical symbol system has the necessary and sufficient means for general intelligent action".6 This hypothesis provided a powerful justification for the symbolic approach, suggesting that the capacity for symbol manipulation was the very essence of intelligence, whether natural or artificial.

The 1980s saw a boom in GOFAI, fueled by earlier successes in simulating logical deduction, algebraic problem-solving, and planning 33, as well as the practical achievements of expert systems. Programs like MYCIN (medical diagnosis) and Dendral (chemical analysis) demonstrated the feasibility of encoding expert knowledge in rule-based systems.39 The deployment of the R1 (XCON) system at Digital Equipment Corporation, which reportedly saved the company millions annually by configuring computer orders, dramatically showcased the commercial potential of AI.39 This success led to a surge in corporate investment and government funding initiatives worldwide, including Japan's Fifth Generation Computer Project, the UK's Alvey project, the US Microelectronics and Computer Technology Corporation (MCC), and significantly increased DARPA funding through the Strategic Computing Initiative.39 This era emphasized "knowledge-based systems" and "knowledge engineering," reflecting the belief that intelligence depended crucially on large amounts of explicitly represented domain knowledge.39

### **2.2. Metaphysical Foundations: CTM, RTM, and Functionalism**

The GOFAI research program was deeply intertwined with specific philosophical theories about the nature of mind and cognition, which provided its metaphysical foundations.

* **Computational Theory of Mind (CTM):** At the heart of the classical era lay the Computational Theory of Mind (CTM). Championed in its modern form by Hilary Putnam and significantly developed by Jerry Fodor, CTM proposed that the mind *is* fundamentally a computational system, and that mental processes *are* computations.1 This computation was typically understood by analogy with a Turing machine, involving the manipulation of symbols according to algorithms.7 CTM offered a way to naturalize the mind, explaining mental operations in mechanistic, information-processing terms.1 It was more than just a metaphor; CTM asserted that the mind *literally is* a specific kind of computer, physically implemented by neural activity in the brain.9  
* **Representational Theory of Mind (RTM):** CTM was almost invariably coupled with the Representational Theory of Mind (RTM).7 RTM posits that mental states, particularly propositional attitudes like believing that p or desiring that q, consist in relations between an agent and internal mental representations.9 These representations possess semantic content – they are *about* things in the world and have properties like truth or accuracy.11 Cognitive science under this view aimed to identify these representations (often conceived as data structures) and the computational processes (algorithms) that operate over them.1 Mental representations were thought to be semantically selective, diverse, and complex, mirroring the richness of human thought and perception.109  
* **Language of Thought Hypothesis (LOTH):** Jerry Fodor provided the most influential articulation of the CTM+RTM framework through his Language of Thought Hypothesis (LOTH).9 LOTH proposed that the mental representations underlying thought constitute a language-like system, "Mentalese," with a combinatorial syntax and semantics.9 Complex thoughts are built systematically from simpler conceptual constituents, much like sentences are built from words. Mental processes, particularly reasoning, were seen as computations defined over the syntactic structure of these Mentalese sentences.9 LOTH was central to explaining two key features of thought: *productivity* (the ability to entertain a potentially infinite number of thoughts) and *systematicity* (the fact that the ability to think certain thoughts is intrinsically linked to the ability to think structurally related thoughts, e.g., if you can think "John loves Mary," you can also think "Mary loves John").7  
* **Functionalism (Machine Functionalism):** CTM and RTM found a natural metaphysical home in functionalism.7 Functionalism defines mental states not by their physical constitution but by their functional or causal role within a system – their relations to inputs, outputs, and other mental states.7 Machine functionalism, specifically, identified mental states with the machine states of a computational system (like a Turing machine or probabilistic automaton).7 CTM provided the computational architecture that realized these functional roles. A key implication, attractive to many, was *multiple realizability*: the idea that the same mental state (defined functionally) could be implemented in different physical substrates (brains, silicon chips, etc.), suggesting psychology's autonomy from neuroscience.22

### **2.3. Core Metaphysical Assumptions of the Era**

Synthesizing these interconnected theories, the classical era operated under a set of core metaphysical assumptions:

1. **Mind as Computation:** The essence of mind and cognition is computation, specifically understood as the rule-governed manipulation of symbols.7  
2. **Cognition as Information Processing:** Mental activity is fundamentally information processing, involving the encoding, storage, retrieval, and transformation of data.1  
3. **Representational Realism:** Mental states involve relations to real, internal mental representations that carry semantic content.7  
4. **Symbolic/Propositional Representations:** These representations are typically conceived as discrete, symbolic structures, often possessing a language-like or propositional format (Mentalese).9  
5. **Syntax Drives Semantics (Formalism):** Mental processes are driven by the syntactic (formal, structural) properties of representations, which reliably track their semantic properties. As Haugeland put it, if you take care of the syntax, the semantics will take care of itself.22  
6. **Rationality as Rule-Following:** Rational thought is understood as the mechanical application of formal (often logical) rules to symbolic representations.7  
7. **Substrate Independence (Potential):** The specific physical material implementing the computation (neurons, silicon) is considered less important than the computational structure itself, allowing for multiple realizability.22  
8. **Implicit Cartesian/Rationalist Heritage:** An underlying assumption often prioritized abstract, disembodied reason and logical thought as the pinnacle of intelligence, sometimes neglecting embodied or intuitive aspects.33

### **2.4. Early Cracks and Critiques**

Despite its dominance, the classical computationalist framework faced significant philosophical challenges almost from its consolidation.

* **Searle's Chinese Room Argument (1980):** John Searle's famous thought experiment posed a direct challenge to the claim that computation, understood as symbol manipulation, is sufficient for genuine understanding or intentionality (the "Strong AI" thesis).22 Searle imagined himself locked in a room following formal rules to manipulate Chinese symbols, producing appropriate outputs without understanding any Chinese himself. He argued that a computer running a program operates analogously – manipulating symbols based on syntax without grasping their meaning (semantics).22 This highlighted a potential gap between syntactic processing and semantic understanding, questioning whether CTM could account for the meaningfulness of thought.105  
* **Dreyfus's Phenomenological Critique:** Hubert Dreyfus, drawing on continental philosophers like Heidegger and Merleau-Ponty, launched a sustained critique of GOFAI's foundational assumptions.24 He argued that human intelligence relies heavily on a vast background of tacit, embodied skills and "common sense" knowledge acquired through interaction with the world.70 This background understanding, Dreyfus contended, cannot be fully formalized into the explicit, context-free symbols and rules required by GOFAI systems.68 He identified several questionable assumptions underlying AI research, including the psychological assumption (that the mind processes information in discrete steps like a computer), the epistemological assumption (that all knowledge can be formalized), the ontological assumption (that reality consists of independent facts describable in context-free language), and the biological assumption (that the brain processes information discretely).70 Dreyfus argued that the failure of AI to achieve genuine intelligence stemmed from these flawed philosophical presuppositions.

These early critiques, targeting the core metaphysical tenets of the classical paradigm—particularly the relationship between syntax and semantics, and the nature and representability of knowledge—exposed fault lines within the seemingly unified computationalist front. While often characterized by the dominance of CTM/RTM, this apparent metaphysical unity was contested from the outset. Foundational issues, such as how symbols acquire meaning (the symbol grounding problem) or how systems deal with the combinatorial explosion of irrelevant facts (the frame problem) 25, remained persistent challenges within the symbolic framework itself. The critiques from Searle and Dreyfus further underscored these difficulties, questioning the sufficiency of formal symbol manipulation for understanding and the feasibility of capturing human intelligence within a purely symbolic, disembodied framework. This suggests the "unity" of the era was perhaps more a reflection of a dominant, well-funded research program 39 than a fully coherent and universally accepted metaphysical settlement, foreshadowing the diversification and fragmentation to come. Furthermore, the tight coupling of CTM, RTM, LOTH, and functionalism meant that challenges to one aspect, such as the nature of representation or the possibility of formalizing all knowledge, inevitably reverberated through the entire theoretical structure, setting the stage for potentially disruptive paradigm shifts.

## **3\. The Connectionist Wave (late 1980s \- 1990s): A Paradigm Shift?**

### **3.1. Rise of Connectionism/Parallel Distributed Processing (PDP)**

Following the perceived limitations and theoretical challenges facing GOFAI, the late 1980s witnessed a dramatic resurgence of interest in connectionist models, also known as artificial neural networks (ANNs) or Parallel Distributed Processing (PDP) systems.6 While early forms of connectionism existed in the 1940s-60s (e.g., McCulloch & Pitts, Rosenblatt's Perceptron), they faced theoretical limitations (highlighted by Minsky & Papert's 1969 critique) and limited computational power, leading to a period of reduced interest.5

The "new connectionism" of the 1980s, however, gained significant momentum, driven by new learning algorithms (like backpropagation, popularized by Rumelhart, Hinton, and Williams), increased computational resources, and a growing sense that GOFAI struggled with tasks like pattern recognition, learning, fault tolerance, and biological plausibility.6 Key figures like David Rumelhart, James McClelland, Geoffrey Hinton, and the PDP Research Group published influential works, notably the two-volume *Parallel Distributed Processing* (1986/1987), which became foundational texts for the movement.72

Connectionist models drew inspiration from the structure of the brain.43 They typically consist of large networks of simple, neuron-like processing units (nodes) connected by weighted links (synapse analogs).6 Information processing occurs through the parallel propagation of activation signals across these units, where each unit typically sums its weighted inputs and applies an activation function (often non-linear) to determine its output.6 Crucially, learning occurs not by manipulating explicit symbols, but by adjusting the strengths (weights) of the connections based on experience, often using algorithms designed to minimize the difference between the network's output and a desired target (supervised learning) or to discover statistical regularities in the input (unsupervised learning).43

### **3.2. The Connectionist Challenge to Classical Metaphysics**

Connectionism was often presented not just as a different modeling technique, but as a fundamental challenge to the metaphysical assumptions underpinning classical cognitive science and GOFAI.43

* **Implicit Rules and Statistical Learning:** A core challenge was the idea that intelligent behavior could emerge from the network learning statistical associations between inputs and outputs, encoded implicitly in the connection weights, rather than requiring explicitly stored, propositionally formatted rules.43 This questioned the necessity of the rule-governed symbol manipulation central to CTM.  
* **Distributed Representation:** Connectionism championed distributed representations, where concepts or features are encoded as patterns of activation across many units, rather than residing in a single symbolic token (localist representation).43 This raised questions about whether such representations possessed the kind of constituent structure deemed necessary for complex thought in the classical framework. Could a pattern of activation truly *represent* in the same way a symbol could?  
* **Subsymbolic Computation:** The processing in connectionist networks, involving numerical activation values and weight adjustments, was often described as "subsymbolic".44 This suggested a level of processing below the level of meaningful symbols posited by LOTH, potentially offering a different foundation for cognition.  
* **Biological Plausibility and Embodiment:** Proponents emphasized the neural inspiration and potential biological plausibility of ANNs, contrasting them with the abstract, disembodied nature of Turing machine models and symbolic AI.43 This aligned connectionism more closely with neuroscience and hinted at the importance of the brain's specific architecture, challenging the strong multiple realizability claims of functionalism.

### **3.3. The Systematicity Debate (Fodor & Pylyshyn vs. Connectionism)**

The most pointed philosophical challenge to connectionism came from Jerry Fodor and Zenon Pylyshyn in their highly influential 1988 paper, "Connectionism and Cognitive Architecture: A Critical Analysis".47

* **Fodor & Pylyshyn's Argument:** They argued that human cognition exhibits systematicity and productivity – properties that, they claimed, could only be explained by an architecture possessing combinatorial syntax and semantics, namely, a language of thought.112 Systematicity, the idea that the ability to think/understand certain propositions is intrinsically linked to the ability to think/understand others with related structures (e.g., "John loves the girl" implies the ability to think "the girl loves John"), was presented as a core empirical fact about cognition.112 Fodor and Pylyshyn argued that connectionist models, lacking explicit constituent structure in their representations, could not inherently guarantee systematicity. While a network might be *trained* to handle both "John loves Mary" and "Mary loves John," there was no architectural principle ensuring that if it could process one, it could necessarily process the other.114 Systematicity in connectionist models would be, at best, a learned contingency, not a consequence of the underlying architecture, failing to explain why human thought *is* systematic.114 They argued systematicity must be explained as a matter of "nomic necessity"—a lawful property of the cognitive architecture.114  
* **Connectionist Responses:** This critique sparked a major debate.110 Connectionists and their philosophical allies responded in various ways 110:  
  * Some questioned the empirical claim, arguing Fodor and Pylyshyn exaggerated the extent or universality of systematicity in human thought.110  
  * Others attempted to demonstrate that connectionist networks *could* exhibit systematicity, for example, by developing architectures with structured representations (e.g., tensor product representations proposed by Smolensky) or using recurrent networks capable of processing sequential, structured data.110  
  * Some argued that Fodor and Pylyshyn's argument was flawed, perhaps by underestimating the capabilities of distributed representations 133 or by implicitly assuming a classical framework was the only possibility.134 David Chalmers, for instance, argued that F\&P's critique failed to properly account for the potential of distributed representations and would wrongly rule out even connectionist implementations of classical systems.133  
  * Still others suggested that connectionism might best be understood as describing the *implementation* level of a classical symbolic architecture, rather than replacing it at the cognitive level.110

### **3.4. Metaphysical Reorientation or Implementation?**

The debate raised fundamental questions about the metaphysical status of connectionism.48 Was it offering a genuinely new metaphysics of mind, replacing computation-as-symbol-manipulation with computation-as-pattern-transformation-in-networks? Or was it providing a more biologically plausible account of how classical symbolic computation might be implemented in the brain?.43

The clash was not merely technical but reflected deeper philosophical divergences. Connectionism's emphasis on learning from statistical regularities in data, its distributed representations, and its appeal to neural plausibility resonated with empiricist and associationist traditions in philosophy and psychology.43 This contrasted sharply with the rationalist heritage of GOFAI, with its focus on innate structures (like LOTH) and explicit logical rules.33 The debate thus foregrounded a fundamental tension within cognitive science regarding the origins of knowledge and the nature of cognitive architecture.

Furthermore, connectionism forced a critical re-examination of the concept of "representation" itself.48 Classical CTM offered a relatively clear, albeit debated, notion of representation as discrete, structured symbols in Mentalese.9 Connectionism introduced ambiguity: were patterns of activation, weight matrices, or points in vector space truly *representations* in the same sense? Did they possess the necessary semantic properties and compositional structure?.43 Fodor and Pylyshyn argued they did not, unless they merely implemented classical symbols.112 Others argued for broadening the notion of representation or even abandoning it for certain levels of explanation.48 This fracturing of the concept of representation, moving away from the relatively unified symbolic view of the classical era, marked a significant point of potential metaphysical fragmentation, sowing seeds of ambiguity that persist in discussions of contemporary AI. The connectionist wave, therefore, did not simply offer new tools; it posed fundamental metaphysical questions about the nature of computation, representation, and learning, significantly diversifying the theoretical landscape of cognitive science and its relationship with philosophy and AI.

## **4\. The Rise of 4E Cognition: Challenging the Brain-Bound Mind**

Concurrent with, and sometimes reacting against, both classical cognitivism and connectionism, another cluster of approaches emerged, broadly challenging the idea that cognition is solely an affair of the brain manipulating internal representations. These are often grouped under the umbrella term "4E Cognition," emphasizing that cognition is Embodied, Embedded, Enactive, and/or Extended.1 While diverse, these perspectives share a critique of traditional computationalism's perceived neglect of the body and the environment.51

### **4.1. Introducing Embodied, Embedded, Enactive, Extended (4E) Cognition**

The "4Es" represent overlapping but distinct lines of research 50:

* **Embodied Cognition:** Argues that cognitive processes are deeply dependent upon, or even constituted by, features of the agent's physical body beyond the brain, such as sensorimotor capacities.50 The way an organism perceives, thinks, and acts is shaped by the kind of body it has.57  
* **Embedded Cognition:** Highlights the crucial role of the environment in structuring and supporting cognitive processes.50 Organisms often rely heavily on environmental structures and affordances, "off-loading" cognitive work onto the world rather than performing complex internal computations.50  
* **Enactive Cognition:** Views cognition not as internal representation and computation, but as "sense-making" that emerges from the dynamic interaction and coupling between an autonomous agent and its environment.17 Perception is seen as action-guided exploration, and cognition is fundamentally linked to the organism's active engagement with its world.51 This approach is often strongly anti-representationalist.17  
* **Extended Cognition (Hypothesis of Extended Cognition \- HEC):** Proposes that cognitive processes can literally extend beyond the boundaries of the organism (skin and skull) to include external resources.50 Tools like notebooks, calculators, or smartphones are argued not merely to aid cognition but, under certain conditions (e.g., constant availability, reliability, easy access, automatic endorsement), to become constitutive parts of the cognitive process itself.115

### **4.2. Philosophical Roots and Metaphysical Commitments**

4E approaches draw inspiration from diverse sources, often outside the mainstream Anglo-American analytic tradition that heavily influenced CTM.143 Key influences include:

* **Phenomenology:** Particularly the work of Maurice Merleau-Ponty and Martin Heidegger, emphasizing lived bodily experience, skilled coping, being-in-the-world, and the critique of detached, objective representation.17  
* **Ecological Psychology:** James J. Gibson's work on direct perception and affordances, suggesting that organisms perceive environmental opportunities for action directly, without needing elaborate internal computations or representations.53  
* **Dynamical Systems Theory:** Viewing cognition as the behavior of a complex, dynamic system comprising the brain, body, and environment, unfolding over time, rather than a sequence of discrete computational steps.17  
* **Pragmatism:** Influences from thinkers like John Dewey emphasizing action and interaction with the world as central to thought.52

These influences lead to distinct metaphysical commitments that often stand in stark contrast to classical computationalism:

* **Anti-Cartesianism:** A strong rejection of mind-body dualism and often a critique of the "brain-in-a-vat" thinking that implicitly separates the cognitive system from the body and world.52  
* **Relational Ontology:** Emphasis on the dynamic coupling and reciprocal causation between organism and environment as the locus of cognition, rather than solely internal states.17  
* **Anti-Representationalism (Radical Forms):** Many enactivist and dynamicist versions argue that cognition, especially basic sensorimotor intelligence, can and should be explained *without* recourse to internal mental representations.17 They argue representations are unnecessary explanatory posits for many cognitive phenomena, particularly skilled coping.54 Some argue that representation-talk should be eliminated entirely from cognitive science, or at least restricted to specific, derived cases (e.g., involving language).54 This challenges not only CTM but also standard interpretations of connectionism that rely on distributed representations.56  
* **Challenge to Metaphysical Realism:** Some anti-representationalist arguments, particularly those drawing on phenomenology or dynamical systems, can be interpreted as challenging metaphysical realism (the view that the world exists independently of our minds) by suggesting that the "world" we cognize is partly constituted by our actions and sensorimotor capacities (enactivism) or that the focus should be on the dynamics of the agent-environment system rather than on accurately modeling an independent reality.17

### **4.3. The Disconnect with Mainstream AI**

Despite gaining significant traction in philosophy of mind and certain areas of cognitive science (like developmental psychology and robotics), 4E approaches have had a relatively limited impact on mainstream AI research, particularly the dominant trends in machine learning and deep learning.52 Several factors contribute to this disconnect:

* **Metaphysical and Foundational Differences:** Mainstream AI, inheriting from the classical and connectionist traditions, largely operates within a computational and often implicitly representationalist framework. Its goal is often to build systems that process information, learn patterns from data, and solve specific problems, often abstract or disembodied ones (e.g., language translation, image classification, game playing).46 4E cognition, with its emphasis on embodiment, action, dynamic coupling, and frequent skepticism about representation, starts from fundamentally different metaphysical premises about what cognition *is* and where it occurs.53 This difference in foundational assumptions creates a significant barrier to integration.  
* **Methodological Divergence:** AI research heavily relies on computational modeling, large datasets, statistical learning, and performance benchmarks on defined tasks.139 4E research often employs different methodologies, including phenomenological analysis, dynamical systems modeling, evolutionary robotics, and qualitative studies of agent-environment interactions.51 Formalizing core 4E concepts like "sense-making" or "enaction" into computationally tractable forms suitable for mainstream AI techniques remains a challenge.  
* **Differing Research Goals:** Much AI research is driven by engineering objectives: creating systems that perform specific tasks effectively and efficiently, often surpassing human capabilities in narrow domains.53 4E cognition research is often more focused on understanding the fundamental principles of biological, adaptive intelligence and the nature of lived experience.50 While embodied AI and robotics exist as subfields 53, they haven't permeated the core of large-scale machine learning research.  
* **The Problem of Scaling and Abstraction:** Critics of 4E approaches sometimes argue that while they might explain basic sensorimotor skills, they struggle to scale up to explain "representation-hungry" cognitive phenomena like abstract thought, long-term planning, counterfactual reasoning, or language comprehension involving absent or abstract entities.53 Mainstream AI, particularly LLMs, excels at precisely these kinds of abstract, language-based tasks, making 4E approaches seem less relevant to these currently dominant areas of AI success.  
* **Institutional and Funding Factors:** As discussed later (Section 8), funding and commercial interests in AI tend to favor data-driven, scalable approaches with clear applications, rather than foundational research into embodied intelligence or critiques of representationalism, which may be seen as less directly applicable or profitable.165

The 4E movement, therefore, constitutes a significant metaphysical counter-current to both classical computationalism and standard connectionism. Its philosophical roots, often in continental traditions, and its core tenets regarding the constitutive role of the body and environment in cognition represent a fundamental departure from the brain-centric, representation-heavy views that have dominated much of AI and cognitive science. The limited uptake of 4E ideas in mainstream AI underscores a deep divergence, likely rooted not just in methodological preferences or technical hurdles, but in conflicting metaphysical assumptions about the nature and locus of intelligence. The anti-representationalist strains within 4E pose a particularly radical challenge, questioning the foundational concept of representation that implicitly or explicitly underpins much of both classical and contemporary AI, thereby highlighting a major fault line in the conceptual landscape.

**Table 1: Comparative Overview of Metaphysical Frameworks (circa 1980s-2000s)**

| Feature | Classical (GOFAI/CTM) | Connectionism (PDP) | 4E Cognition (Embodied/Enactive Focus) |
| :---- | :---- | :---- | :---- |
| **Core Metaphor/View** | Mind as digital computer; Information processor | Mind/Brain as neural network; Statistical pattern learner | Mind as embodied agent-environment system; Sense-maker |
| **Nature of Computation** | Rule-governed symbol manipulation (Syntactic) | Parallel distributed processing; Weight adjustment | Dynamic coupling; Continuous reciprocal causation |
| **Nature of Representation** | Explicit, symbolic, structured (e.g., LOTH/Mentalese) | Distributed patterns of activation; Subsymbolic | Often denied/rejected (anti-representationalism); Action-oriented |
| **Locus of Cognition** | Primarily Brain/Internal Computation | Primarily Brain/Network dynamics | Brain-Body-Environment System |
| **Role of Body** | Peripheral; Implementation detail (Multiple Realizability) | Inspiration; Implementation substrate | Constitutive; Fundamentally shapes cognition |
| **Role of Environment** | Input/Output source | Source of training data/stimuli | Constitutive; Part of the cognitive system; Affordances |
| **Key Phil. Influences** | Rationalism, Logicism, Functionalism | Empiricism, Associationism | Phenomenology, Pragmatism, Ecological Psych., DST |
| **Metaphysical Stance** | Representational Realism; Functionalism | Often Implicit Representationalism; Empiricist leaning | Often Anti-Representationalist; Relational Ontology |
| **Key Critiques Faced** | Symbol grounding, Frame problem, Brittleness, Biological implausibility (Searle, Dreyfus) | Systematicity, Compositionality, Interpretability (Fodor & Pylyshyn) | Scaling to abstract thought, Formalization difficulty, Vagueness |
| **Relation to AI (Mainstream)** | Foundational paradigm (early AI) | Influential paradigm (esp. leading to Deep Learning) | Limited direct impact; Influence in robotics/niche areas |

*(Sources: 1)*

## **5\. The Neurocentric Turn: Cognitive Science and the Brain**

### **5.1. Neuroscience's Ascendancy**

Starting significantly in the 1980s and accelerating through the 1990s (often dubbed the "Decade of the Brain") and beyond, neuroscience began to exert an increasingly dominant influence within cognitive science.84 This "neurocentric turn" was propelled by conceptual shifts recognizing the brain's foundational role for cognition, alongside dramatic technological advancements in brain imaging and measurement techniques.1 Methods like functional magnetic resonance imaging (fMRI), positron emission tomography (PET), electroencephalography (EEG), transcranial magnetic stimulation (TMS), and optogenetics provided unprecedented ways to observe and interact with brain activity during cognitive tasks, moving beyond behavioral measures alone.1 Cognitive neuroscience emerged as a distinct and highly influential field, aiming explicitly to bridge the gap between mental processes and their neural substrates.1

### **5.2. Impact on Philosophy-AI-Cognitive Science Relations**

The rise of neuroscience had complex and multifaceted effects on the relationships within the cognitive triangle:

* **Grounding for Connectionism:** Neuroscience provided significant inspiration and a source of validation for connectionist models.1 The brain's network structure, parallel processing, and synaptic plasticity offered a biological analogue for ANNs, lending them an air of plausibility that purely symbolic models often lacked.43 Computational neuroscience emerged as a field dedicated to building mathematical models of neural systems, often employing connectionist principles.7  
* **Challenges to Classical Views:** Neuroscientific findings were increasingly marshaled to challenge tenets of classical computationalism and functionalism.28 Evidence for distributed processing and the overlapping involvement of brain regions in multiple tasks questioned strong versions of Fodorian modularity. Findings suggesting species-specific neural architectures or dependencies between cognitive functions and specific neural structures were used to argue against the strong version of multiple realizability, a cornerstone of functionalism that asserted the independence of mental states from their physical implementation.28  
* **Rise of Neurophilosophy:** The empirical findings of neuroscience began to be applied directly to traditional philosophical problems concerning consciousness, intentionality, free will, morality, and the self, giving rise to "neurophilosophy".13 Philosophers like Patricia and Paul Churchland argued forcefully that philosophical theories of mind must be constrained by and co-evolve with neuroscientific discoveries.28 This involved both using neuroscience to critique existing philosophical views (e.g., folk psychology) and developing new philosophical accounts grounded in neural mechanisms (e.g., state-space semantics).28  
* **Emphasis on Mechanistic Explanation:** There was a growing emphasis on providing mechanistic explanations – detailing the components, operations, and organization of neural systems that produce cognitive phenomena.13 This contrasted with the more abstract, functional-level explanations often favored in classical AI and philosophy.  
* **Shifting Alliances and Disciplinary Focus:** The neurocentric turn arguably weakened the tight alliance between philosophy and symbolic AI that characterized the early cognitive revolution.84 Cognitive science, as a whole, became more empirically grounded, looking increasingly towards experimental psychology and neuroscience for data and theoretical constraints.1 AI, particularly as it moved towards connectionism and later deep learning, also drew inspiration from neuroscience, but often with engineering goals prioritized over detailed biological accuracy.34 Philosophy, in turn, engaged with neuroscience through neurophilosophy and philosophy of neuroscience, but this sometimes occurred in parallel with, rather than in deep integration with, AI developments.

### **5.3. Metaphysical Implications**

The increasing focus on the brain had significant metaphysical implications:

* **Reinforcement of Physicalism:** Neuroscience provided powerful empirical evidence against substance dualism and bolstered physicalist or materialist views of the mind, grounding mental processes firmly in the physical activity of the brain.22  
* **Intensification of Reductionism/Eliminativism Debates:** The ability to correlate mental states with specific brain activity fueled debates about the ultimate relationship between the mental and the neural. Reductive physicalists argued that mental states could ultimately be identified with or reduced to neural states (a modern form of identity theory).25 Eliminative materialists, notably the Churchlands, argued that our common-sense "folk psychology" (with concepts like belief and desire) is a flawed theory that will eventually be eliminated and replaced by a mature neuroscientific vocabulary.25 Connectionist models, inspired by neuroscience, were sometimes offered as an alternative framework that might supersede folk psychology.28  
* **Questioning Substrate Independence:** By highlighting the intricate relationship between cognitive functions and specific neural structures and processes, neuroscience challenged the strong functionalist claim that the physical substrate is irrelevant.28 While weaker forms of multiple realizability might still hold, the idea that cognition could be understood entirely independently of its neural implementation became less tenable for many.  
* **New Perspectives on Representation:** While neuroscience inspired connectionist models often interpreted in representational terms, some interpretations of neural activity, particularly those emphasizing dynamical systems or the complexity of neural coding, led to skepticism about traditional notions of neural representation.85 Researchers began questioning whether patterns of neural firing truly function as discrete, content-bearing representations in the way assumed by CTM or even standard connectionism.85

The ascent of neuroscience did not forge a new, unified metaphysical framework for the cognitive sciences. Instead, it acted as a powerful empirical catalyst, intensifying existing debates within physicalism (reduction vs. elimination, the nature of representation) and introducing new data and constraints that philosophical theories of mind had to accommodate. By pulling cognitive science closer to its biological roots, it arguably increased the field's divergence from the more abstract, formal approaches prevalent in early AI and some branches of philosophy of mind, particularly strong functionalism.1 The focus shifted towards understanding the brain's mechanisms, making the specific details of implementation seem crucial, not incidental, to understanding cognition.

Furthermore, the advent of powerful neuroimaging tools like fMRI created a complex interplay between empirical research and philosophical interpretation.27 On one hand, it enabled "experimental philosophy" – using empirical methods to investigate questions traditionally addressed through armchair reflection, such as the neural basis of moral judgments or intentionality attribution.60 On the other hand, the interpretation of neuroimaging data itself became a subject of philosophical scrutiny.60 The limitations of fMRI (e.g., indirect measure of activity, temporal/spatial resolution issues) and the logical pitfalls of inferring specific cognitive processes solely from patterns of brain activation (the problem of "reverse inference") highlighted the need for careful conceptual analysis alongside empirical investigation.60 This created a dynamic where neuroscience both informed and was critically examined by philosophy, further complicating the interdisciplinary landscape.

## **6\. Contemporary AI (Deep Learning, LLMs): Metaphysical Echoes and New Puzzles**

### **6.1. The Deep Learning Revolution**

The past fifteen years have been marked by the "deep learning revolution" in AI.130 Building on connectionist principles but leveraging vastly increased computational power, massive datasets, and architectural innovations (e.g., many layers of processing, specific architectures like convolutional neural networks and transformers), deep neural networks (DNNs) have achieved state-of-the-art, often superhuman, performance on a wide array of tasks, including image recognition, game playing (Chess, Go), natural language processing, and protein folding prediction.72 Large language models (LLMs) like GPT-3/4, Gemini, and Claude, trained on internet-scale text data, have demonstrated remarkable abilities in generating fluent text, translating languages, answering questions, and even writing code, capturing significant public and academic attention.81 While rooted in connectionism, the scale and capabilities of these systems represent a significant leap, prompting renewed philosophical debate.130

### **6.2. Do LLMs Embody CTM/RTM Assumptions?**

A central question is whether these advanced AI systems, despite their different architecture and training methods, still operate under the core metaphysical assumptions of the classical CTM/RTM framework, or if they represent a fundamental departure.

* **Arguments for Continuity:** From one perspective, DNNs and LLMs can be seen as sophisticated information processing systems.7 They take inputs, transform them through layers of computation, and produce outputs. Research in interpretability often focuses on identifying the "representations" learned by these models – features, concepts, or relationships encoded in the patterns of activation or connection weights (often as high-dimensional vectors or embeddings).63 Some argue that the success of these models relies on their ability to learn hierarchical representations of increasing abstraction.187 Furthermore, one could interpret their behavior through a functionalist lens, defining their internal states by their role in mapping inputs to outputs, potentially aligning them with a form of computational functionalism.9 The very idea of processing language, even statistically, involves manipulating symbols (words, tokens) based on learned rules (statistical patterns), which could be seen as a complex form of symbol manipulation, albeit different from GOFAI's explicit rules.9  
* **Arguments for Discontinuity/Break:** Conversely, deep learning systems differ significantly from classical models. They typically lack explicitly programmed symbolic rules or a predefined "language of thought".94 Their knowledge is implicit in the learned weights derived from statistical patterns in vast datasets, not stored as discrete propositions.94 Debates continue about whether they truly achieve systematicity and compositionality in the strong sense Fodor and Pylyshyn demanded; while they show impressive generalization, failures in systematic reasoning persist, suggesting their underlying mechanisms may differ from human compositional thought.114 Critics argue that LLMs are essentially sophisticated pattern-matching systems or "stochastic parrots," mimicking linguistic forms without genuine understanding, intentionality, or grounding in the world.81 Their ability seems tied to the statistical distributions in their training data, raising questions about whether they possess genuine concepts or beliefs.194  
* **The Nature of Representation in DL:** The debate hinges partly on what constitutes "representation" in these systems. The vector embeddings learned by LLMs represent words and concepts in high-dimensional spaces where proximity reflects semantic similarity.139 While these are clearly information-bearing structures crucial to the models' function, it remains contested whether they qualify as representations in the sense required by classical RTM (i.e., possessing discrete constituents, compositional semantics, truth conditions) or whether they constitute a fundamentally different kind of statistical or structural representation.63

### **6.3. The "Black Box" Problem and Philosophical Interpretation**

A significant feature complicating the philosophical assessment of deep learning models is their opacity, often referred to as the "black box" problem.63 Unlike GOFAI programs, where the rules and symbolic representations were explicitly designed and inspectable, the internal workings of large DNNs, with billions of parameters adjusted through complex optimization processes, are often inscrutable even to their creators.63

This inscrutability poses several challenges for philosophical interpretation:

* **Assessing Metaphysical Commitments:** It becomes difficult to definitively determine whether a DNN embodies specific metaphysical assumptions. Does it operate on representations with compositional structure? Does it follow logical rules implicitly? Without clear insight into the internal mechanisms, interpretations often rely on behavioral analogies, which can be misleading.63  
* **Understanding vs. Mimicry:** The black box nature fuels the debate about whether these systems genuinely understand or merely simulate understanding. Since the process is opaque, it's hard to distinguish between flexible, generalizable reasoning based on underlying models and sophisticated pattern matching that mimics intelligent behavior within the training distribution.169  
* **Trust and Explainability:** The lack of transparency raises significant ethical and practical concerns about trust, bias detection, and accountability, particularly in high-stakes applications.169 This has spurred the field of Explainable AI (XAI), which seeks methods to interpret and explain DNN decisions, although the reliability and philosophical adequacy of current explanation methods are themselves debated.63

The opacity of contemporary AI systems allows them to function as a kind of Rorschach test for different philosophical viewpoints. Those inclined towards computationalism or functionalism may interpret their impressive performance as evidence for the power of information processing and learned representations.9 Critics skeptical of strong AI or proponents of alternative views (like 4E cognition) may point to the lack of transparency, failures in systematic reasoning, or absence of grounding as evidence that these systems lack genuine mentality.158 The black box nature thus permits multiple, often conflicting, philosophical interpretations to coexist, hindering definitive conclusions about the systems' underlying metaphysical commitments based solely on their behavior.

### **6.4. Multimodal AI**

The development of multimodal AI systems, which integrate information across different modalities like text, images, audio, and video 35, adds another layer of complexity. Can these systems develop more "grounded" representations by linking language to perceptual data?.158 Does integrating sensorimotor data (in robotics) push AI towards a more embodied framework?.190 Or do these systems simply learn statistical correlations across modalities without achieving deeper, integrated understanding? These questions are actively being explored, but the integration of multiple data types challenges traditional philosophical models of mind that often prioritized abstract, propositional thought and raises new questions about the nature of representation and grounding in artificial systems.

The success of deep learning, particularly LLMs, potentially offers support for empiricist ideas over strong nativism, suggesting complex abilities can emerge from learning statistical regularities in massive datasets rather than requiring pre-programmed symbolic structures.45 However, the *way* these systems learn – typically through passive absorption of vast amounts of curated data, often disembodied and decontextualized – differs markedly from the active, embodied, environmentally situated learning central to traditional empiricist philosophies and 4E theories.53 This suggests that deep learning may represent a distinct learning paradigm with its own unique metaphysical implications, rather than simply validating older empiricist views.

## **7\. Persistent and Unexamined Metaphysical Assumptions**

Despite the paradigm shifts from symbolic AI to connectionism and now deep learning, and the challenges posed by 4E cognition and neuroscience, certain foundational metaphysical assumptions inherited from the early days of cognitive science appear remarkably resilient, often operating implicitly in contemporary research across philosophy, AI, and cognitive science.

### **7.1. The Resilience of Representationalism**

The idea that cognition fundamentally involves internal states or structures that represent the world remains pervasive, even when explicit adherence to classical RTM or LOTH is abandoned.10 Talk of "information processing," "encoding sensory input," "neural codes," "feature detection," and "internal models" is commonplace in cognitive neuroscience and AI.8 Connectionist and deep learning models are frequently analyzed in terms of the representations they learn or employ, whether these are distributed patterns, vector embeddings, or hierarchical features.43

However, critics like William Ramsey have argued that the term "representation" is often used loosely in cognitive science and AI, applied to any internal state that mediates between input and output or correlates with an external feature, without demonstrating that positing representational content provides genuine explanatory purchase beyond a purely causal description.163 Ramsey's "job description challenge" asks what explanatory work the concept of representation actually *does* in a given theory.163 He argues that many uses, particularly those equating representation with mere causal mediation or feature detection (e.g., "edge detector representations" in vision), fail this challenge and risk trivializing the concept.163 This suggests that representationalism might persist partly due to conceptual inertia or its utility as a descriptive shorthand, rather than as a rigorously defended metaphysical commitment in all cases.163 Even anti-representationalist critiques often define themselves *against* representationalism, inadvertently reinforcing its centrality as a default assumption.17 The persistence of representationalist language across different paradigms indicates it may function as a deeply embedded conceptual framework shaping how researchers approach and interpret cognition, potentially obscuring alternative, non-representational explanations.

### **7.2. The Information Processing Metaphor**

Closely related to representationalism is the enduring metaphor of the mind/brain as an information processing system, drawing heavily on the analogy with digital computers.1 This metaphor structures thinking about cognition in terms of inputs, outputs, storage (memory stages like sensory, short-term, long-term), encoding, retrieval, and processing limitations.8 While foundational for cognitive psychology and classical AI, the metaphor has faced criticism for overlooking crucial differences between brains and current computers.8 Brains exhibit massive parallelism, rely on electrochemical signaling, are inherently plastic and context-sensitive, develop through interaction, and are deeply integrated with bodily states and emotions – features often absent or poorly captured in standard computational models.8 Critics argue the metaphor encourages a disembodied, overly simplistic, and potentially misleading view of mental processes, neglecting aspects like creativity, emotion, play, and the holistic nature of understanding.8 While some argue the metaphor functions merely as a useful heuristic 218, its pervasiveness raises the question of whether it functions as an unexamined metaphysical commitment, shaping the very questions asked and the kinds of explanations sought within cognitive science and AI.216

### **7.3. Computational Functionalism's Shadow**

Although explicit CTM in its classical Fodorian form might be less dominant, the underlying functionalist assumption – that mental states can be defined by their causal roles, often specified computationally – may persist implicitly.7 Much AI research focuses on achieving specific input-output functions or task performance, evaluating systems based on their behavioral capabilities rather than their internal processes or physical substrate.23 This focus on function and behavior, while pragmatically necessary for engineering, can inadvertently align with a functionalist metaphysics where the "how" of implementation is secondary to the "what" of the function performed. This potentially downplays the significance of biological embodiment (contra 4E) or the specific nature of computation (contra debates about symbolic vs. connectionist processing).

### **7.4. Critiques from Outside Anglo-American Traditions**

The dominant paradigms in AI and cognitive science have largely emerged from the Anglo-American analytic philosophy tradition, inheriting some of its metaphysical assumptions. Critiques from other philosophical traditions often target these deeper, potentially culturally specific, presuppositions.

* **Phenomenology:** As noted earlier (Section 2.4, 4.2), phenomenologists like Dreyfus (drawing on Heidegger and Merleau-Ponty) critique the abstract, detached, representationalist view of mind inherent in GOFAI and much of cognitive science.33 Phenomenology emphasizes the primacy of lived, embodied experience (the *Lebenswelt*), intentionality as world-directedness, and the role of tacit skills and social context.36 It questions the subject-object split often assumed in representationalist models and the focus on third-person, objective descriptions at the expense of first-person experience.67 The journal *Phenomenology and the Cognitive Sciences* explicitly fosters dialogue on these intersections.67 This perspective suggests that the metaphysical foundations of mainstream cognitive science may be inadequate for capturing the richness of conscious experience and embodied agency.  
* **Critical Theory:** This tradition, encompassing thinkers from the Frankfurt School onwards, focuses on analyzing power structures, ideology, social critique, and emancipation.222 A critical theory perspective might analyze the metaphysical assumptions of AI and cognitive science not as neutral scientific postulates, but as reflecting or reinforcing specific societal power dynamics or ideologies.222 For example, the emphasis on rationality, control, and prediction in computational models could be seen as aligning with instrumental reason or capitalist modes of production. AI ethics, when viewed through this lens, becomes not just about mitigating harms but about analyzing and challenging the power relations embedded in AI development and deployment (e.g., bias, surveillance, algorithmic control).12  
* **Postcolonial/Non-Western Perspectives:** These perspectives challenge the purported universality of philosophical frameworks derived predominantly from Western (specifically Anglo-American analytic or European continental) traditions.86 They raise concerns about cultural biases embedded within AI and cognitive science's core concepts, such as definitions of intelligence, rationality, selfhood, and knowledge.86 For instance, the focus on individualistic, logic-based reasoning might neglect collectivist or intuitive forms of cognition emphasized in other cultures. Arguments for philosophical pluralism suggest that engaging with diverse traditions (Buddhist, Confucian, Indigenous, African philosophies, etc.) is crucial for avoiding parochialism and developing more robust and globally relevant understandings of mind and AI alignment.86 Some critiques specifically warn that deploying AI systems based on Western epistemologies globally could lead to the marginalization or erasure of non-Western knowledge systems.192 Alternative metaphysical frameworks, such as process philosophy (emphasizing becoming over being, events over substances) 20, also offer different ways to conceptualize reality and cognition that contrast with the often static, object-oriented assumptions of traditional metaphysics.

These critiques from outside the dominant Anglo-American framework suggest that many of the metaphysical debates within AI and cognitive science might be taking place within a relatively narrow philosophical space. They highlight potentially unexamined assumptions rooted in specific cultural and philosophical lineages – such as the subject-object dichotomy, the emphasis on explicit representation, the definition of rationality, and the nature of the self – and argue that a truly comprehensive science of mind and ethically responsible AI development requires engagement with a broader spectrum of metaphysical perspectives.

## **8\. Institutional Forces and the Decoupling of Inquiry**

The trajectory and focus of research in philosophy, AI, and cognitive science are not solely determined by intellectual currents and internal debates. Institutional structures, funding priorities, and commercial interests play a significant role in shaping research agendas, fostering or hindering interdisciplinary collaboration, and potentially influencing the perceived relevance of foundational metaphysical questions.

### **8.1. The Influence of Funding**

From the inception of AI and cognitive science, government funding agencies, particularly military ones like the Defense Advanced Research Projects Agency (DARPA) in the US, have played a pivotal role.39 Early funding supported foundational research at key institutions like MIT, Stanford, and CMU, often with broad mandates that allowed for exploration of fundamental questions about intelligence and computation.3 Large initiatives like DARPA's Strategic Computing Initiative in the 1980s, Japan's Fifth Generation project, and the UK's Alvey project channeled significant resources into AI, often focusing on symbolic approaches and expert systems during that era.39

However, funding priorities shift. The infamous "AI Winters" (periods of reduced funding and interest, notably in the mid-1970s and late 1980s/early 1990s) occurred partly because AI failed to deliver on overly optimistic promises, leading funding agencies to redirect resources.99 More recently, DARPA initiatives like Explainable AI (XAI) 229, Lifelong Learning Machines (L2M) 230, and programs focused on cognitive capabilities 230 or deontic reasoning 200 indicate a continued interest in pushing AI beyond simple pattern recognition towards more human-like reasoning and adaptability. Yet, the goals are often framed in terms of specific capabilities relevant to defense or national security.98 Similarly, civilian funding agencies like the National Science Foundation (NSF) or initiatives like the Spencer Foundation's AI and Education program shape research by setting priorities, which may emphasize specific applications (like education 232), ethical considerations, or particular technical approaches over others.72 The need to align research proposals with the stated goals and perceived interests of funding bodies can subtly steer research away from purely philosophical or highly speculative metaphysical inquiry towards projects with more demonstrable short-term outcomes or alignment with agency missions.233

### **8.2. Commercialization and Industrial AI**

Perhaps the most significant institutional shift in recent decades has been the massive influx of private investment and the migration of cutting-edge AI research, particularly in deep learning, from academia to large technology corporations like Google (DeepMind), Meta, Microsoft, and OpenAI.188 While this has fueled rapid technological progress and deployment 215, it has profound implications for the relationship between AI development and foundational research, including philosophy.

Commercial imperatives prioritize developing profitable products and services, achieving competitive advantages through proprietary algorithms and datasets, enhancing efficiency, and scaling solutions rapidly.215 This environment often favors engineering-driven approaches focused on performance metrics and practical applications over the slower, more exploratory pace of foundational philosophical investigation.233 Questions about the ultimate nature of mind, consciousness, or the metaphysical grounding of meaning may be seen as secondary or irrelevant to the immediate goals of building and deploying commercially viable AI systems.233 While some companies employ ethicists or researchers with philosophical backgrounds 236, their work is often framed within the context of responsible AI deployment, risk mitigation, or aligning AI with corporate values, rather than open-ended metaphysical inquiry.234 The intense competition and "racing" dynamics incentivize secrecy and the control of data, potentially hindering the open sharing of knowledge necessary for broader scientific and philosophical progress.235 This shift towards commercialized, often proprietary, AI research creates strong structural pressures that risk decoupling the rapid advancement of AI technology from sustained engagement with the deep philosophical questions it raises.

### **8.3. Interdisciplinarity: Challenges and Opportunities**

Cognitive science was founded on the promise of interdisciplinary integration.1 AI, too, draws from multiple fields. However, achieving genuine, fruitful collaboration across disciplines like philosophy, psychology, neuroscience, and computer science faces persistent challenges.1 These fields often have different:

* **Goals:** (e.g., foundational understanding vs. empirical explanation vs. building functional systems) 4  
* **Methodologies:** (e.g., conceptual analysis vs. experimentation vs. computational modeling) 15  
* **Epistemic Values:** (e.g., rigor vs. predictive accuracy vs. explanatory depth)  
* **Languages and Concepts:** Leading to misunderstandings or talking past one another 233  
* **Publication Cultures and Reward Structures:** Often incentivizing specialization within disciplinary boundaries.233

These barriers can hinder the integration of philosophical perspectives into AI and cognitive science research, and vice versa. Institutional structures, such as university department organization, grant review processes, and conference formats, can either exacerbate these divisions or actively promote cross-disciplinary dialogue.15 Initiatives explicitly designed to foster interaction, like Princeton's Natural and Artificial Minds initiative 73 or dedicated interdisciplinary journals and conferences 40, represent attempts to overcome these challenges. However, the risk remains that cognitive science could fragment, with different sub-communities aligning more closely with either neuroscience, AI engineering, or philosophy, losing the original vision of a unified science of mind and potentially marginalizing philosophical inquiry within the more empirically or commercially driven subfields.78

The overall institutional context—shaped by funding priorities, commercial interests, and the inherent difficulties of deep interdisciplinarity—therefore exerts a powerful, often underestimated, influence on the metaphysical landscape. It shapes which questions are deemed important, which frameworks are considered viable, and the extent to which foundational philosophical reflection remains coupled to the rapidly advancing frontiers of AI and cognitive science.

## **9\. Emerging Frameworks and Future Directions**

Amidst the diversification and potential fragmentation of the cognitive triangle, new theoretical frameworks have emerged, attempting to offer unifying perspectives or address the challenges posed by previous paradigms and contemporary AI. Furthermore, the very success of AI continues to generate new philosophical puzzles and reshape the debate about the relevance of foundational inquiry.

### **9.1. Predictive Processing and Bayesian Approaches**

One of the most prominent theoretical developments in recent cognitive science and philosophy of mind is the Predictive Processing (PP) framework, also referred to as predictive coding, the free energy principle, or the Bayesian brain hypothesis.61 Originating primarily in computational neuroscience, PP posits that the brain is fundamentally a prediction engine.76 Its core idea is that the brain constantly generates hierarchical models of the causes of its sensory input and attempts to minimize the "prediction error" – the mismatch between its top-down predictions and the bottom-up sensory evidence.76 This error minimization process is thought to underpin perception (updating the internal model), action (sampling the environment to make sensations conform to predictions, known as active inference), and learning (refining the generative model).76

PP offers a potentially unifying framework by proposing a single computational principle (prediction error minimization, often formalized using Bayesian inference) to explain a wide range of cognitive phenomena across perception, action, attention, learning, and even potentially consciousness and mental disorders.76 Its proponents highlight its potential neural plausibility, citing evidence for hierarchical processing and distinct neural populations potentially encoding predictions and errors in the cortex.76

Metaphysically, PP raises intriguing questions:

* **Representation:** Are the brain's generative models genuine representations of the world? They function to predict sensory causes, suggesting a representational role, but their probabilistic, hierarchical nature differs from classical symbols.61 Some interpretations lean towards representationalism, while others see potential compatibility with anti-representationalist or enactive views, especially through active inference.61  
* **Kantian Echoes:** The framework's emphasis on top-down construction of perception based on internal models (priors) resonates with Kantian philosophy, where the mind imposes structure on sensory experience.252 PP is sometimes described as offering a computationally tractable version of a "Kantian brain".252  
* **Embodiment and Action:** Through active inference, PP attempts to integrate perception and action within a single framework, potentially bridging the gap with embodied and enactive approaches by emphasizing the role of action in shaping sensory input to minimize prediction error.76  
* **Fundamental Principle?** Is prediction error minimization a fundamental principle of all cognition, or even all self-organizing systems (as suggested by the Free Energy Principle formulation 76), or is it a specific mechanism applicable to certain cognitive domains? Its status as a scientific theory versus a broader metaphysical framework remains debated.76

While PP and Bayesian approaches offer a powerful synthesis of ideas from neuroscience, AI (Bayesian methods), and potentially philosophy, their own metaphysical implications are complex and contested. The interpretation of core concepts like "generative model," "prediction error," and "precision" varies, leading to ongoing debates about representation, consciousness, and the framework's ultimate scope.87 Rather than definitively resolving past divergences, these frameworks may be generating new lines of philosophical inquiry and potential fragmentation based on differing interpretations of their core tenets.

### **9.2. Neuro-Symbolic AI and Hybrid Models**

Recognizing the limitations of purely connectionist or purely symbolic approaches, there is growing interest in neuro-symbolic AI – hybrid architectures that aim to combine the learning capabilities and pattern recognition strengths of neural networks with the explicit reasoning, abstraction, and compositionality associated with symbolic systems.33 These approaches seek to leverage the best of both worlds, potentially overcoming connectionism's systematicity challenges while retaining its ability to learn from data. From a metaphysical standpoint, it remains an open question whether these hybrid models represent a genuine synthesis of the underlying metaphysical assumptions of classical and connectionist views, or if they are primarily pragmatic engineering solutions that bracket deeper philosophical incompatibilities.

### **9.3. AI and New Philosophical Questions**

The sheer capabilities demonstrated by contemporary AI systems, especially LLMs and multimodal models, are actively generating new philosophical questions and forcing a reconsideration of long-standing ones.21 Key areas include:

* **Meaning, Understanding, and Intentionality:** Can systems trained solely on statistical patterns in language truly understand meaning or possess genuine intentionality?.23 What are the necessary conditions for understanding, and do LLMs meet them? This revives debates related to Searle's Chinese Room in a new context.194 Does meaning arise from distributional semantics alone, or is grounding in perception and action necessary?.195  
* **Consciousness:** Could consciousness emerge from sufficiently complex computations or specific AI architectures?.9 Do LLMs exhibit properties (like apparent self-reflection or processing internal states) relevant to theories of consciousness?.197 The possibility of machine consciousness challenges traditional views and raises profound ethical questions.26  
* **Creativity and Cognition:** Can AI systems be genuinely creative, or do they merely recombine existing patterns?.26 How does AI impact human creativity and critical thinking?.165  
* **Agency, Selfhood, and Personhood:** Can AI systems be considered agents with goals and autonomy?.16 Do LLMs possess anything resembling a stable self or identity?.21 What are the criteria for personhood, and could AI ever meet them?  
* **The Nature of Intelligence:** AI successes challenge anthropocentric definitions of intelligence.35 If machines can outperform humans on tasks previously considered hallmarks of intelligence (e.g., strategic games, reasoning tests), what constitutes intelligence?.81 Does intelligence require consciousness, understanding, or embodiment?.1

### **9.4. The Impact of Pragmatic Success**

The undeniable pragmatic success and rapid commercialization of AI, particularly deep learning, raises a crucial question about its impact on foundational philosophical inquiry \[User Query\].

* **Diminished Interest?** One perspective is that the focus on engineering results, performance metrics, and commercial applications de-emphasizes or even discourages engagement with deep, abstract metaphysical questions about the nature of mind, meaning, or consciousness.233 If AI systems *work* effectively and generate economic value, the argument goes, perhaps the underlying philosophical debates become less relevant for practical purposes. The institutional pressures discussed in Section 8 reinforce this tendency, potentially leading to a decoupling where AI development proceeds largely atheoretically or with only implicit, unexamined metaphysical assumptions.  
* **Renewed Engagement?** An alternative view is that AI's very success *forces* a renewed and urgent engagement with foundational questions.21 The capabilities of LLMs, for example, make questions about machine understanding, intentionality, and potential consciousness seem less like science fiction and more like pressing contemporary issues.62 The "black box" problem necessitates philosophical reflection on explanation and interpretation.205 Ethical concerns surrounding AI bias, autonomy, and societal impact inevitably lead back to fundamental questions about values, agency, and the nature of intelligence.36 From this perspective, AI acts as a powerful catalyst, providing new phenomena, tools (like computational models as "thought experiments" 37), and a sense of urgency for philosophical inquiry, potentially demanding entirely new metaphysical frameworks to make sense of artificial minds.21

The reality likely involves a dialectical tension between these two forces. Commercial and pragmatic pressures may indeed pull resources and attention away from foundational research in some sectors. Simultaneously, however, the profound capabilities and societal impact of advanced AI systems generate unavoidable philosophical challenges that demand attention from philosophers, cognitive scientists, and AI researchers alike, ensuring the continued, albeit perhaps transformed, relevance of metaphysical inquiry.

## **10\. Conclusion: Divergence, Fragmentation, and the Future of the Cognitive Triangle**

The relationship between philosophy of mind, artificial intelligence, and cognitive science has undergone a complex evolution since the 1980s, moving from a period of relative, albeit contested, unity under the banner of classical computationalism towards a more diverse, pluralistic, and arguably fragmented landscape. This report has traced this trajectory, focusing on the shifting metaphysical assumptions and the interplay between theoretical developments, technological advancements, and institutional forces.

### **10.1. Synthesis of Findings**

The classical era of the 1980s was characterized by the dominance of symbolic AI (GOFAI) and the Computational Theory of Mind (CTM), often intertwined with the Representational Theory of Mind (RTM), Fodor's Language of Thought Hypothesis (LOTH), and functionalism. This framework posited mind as symbol manipulation, cognition as information processing over discrete representations, and rationality as rule-following, drawing heavily on the digital computer metaphor and rationalist philosophical traditions. However, this apparent unity faced immediate challenges concerning symbol grounding and the limits of formalization, notably from Searle's Chinese Room and Dreyfus's phenomenological critiques.

The connectionist wave of the late 1980s and 1990s offered a neurally inspired alternative, emphasizing parallel distributed processing, learning through weight adjustment, and distributed representations. This sparked intense debate, particularly Fodor and Pylyshyn's systematicity challenge, which questioned whether connectionist architectures could intrinsically support the compositional nature of thought. This period highlighted a deeper clash between rationalist and empiricist leanings and fractured the previously unified concept of representation.

Emerging concurrently, 4E cognition (Embodied, Embedded, Enactive, Extended) presented a more radical challenge, questioning the brain-bound, representationalist assumptions of both classical and connectionist views. Drawing on phenomenology, ecological psychology, and dynamical systems theory, 4E approaches emphasized the constitutive role of the body and environment in cognition, with some strands advocating for anti-representationalism. Its limited impact on mainstream AI highlights a significant divergence potentially rooted in differing metaphysical starting points and research goals.

The increasing influence of neuroscience further complicated the picture. While providing empirical grounding for physicalism and inspiration for connectionism, it also fueled debates between reductionism and eliminativism, challenged strong functionalism via implementation details, and, in some interpretations, questioned traditional notions of neural representation. Neuroimaging created new avenues for empirical philosophy but also introduced significant interpretive challenges.

Contemporary AI, dominated by deep learning and LLMs, presents new puzzles. These systems exhibit remarkable capabilities but their opaque "black box" nature allows for conflicting philosophical interpretations regarding their alignment with classical CTM/RTM assumptions, the nature of their internal representations, and whether they possess genuine understanding or intentionality. Their success challenges strong nativism but doesn't straightforwardly align with traditional empiricist or 4E learning theories.

### **10.2. Metaphysical Divergence vs. Fragmentation**

Rather than a simple divergence into two or three distinct, coherent paradigms, the trajectory suggests a complex *fragmentation*.31 The initial CTM framework, despite its internal tensions, provided a relatively unified (if contested) metaphysical foundation. Subsequent developments introduced multiple, often competing, frameworks (connectionism, 4E, PP/Bayesian) and intensified debates over core concepts like computation and representation.

While clear divergences exist (e.g., between strong representationalism and radical enactivism), the landscape is characterized by a proliferation of approaches with overlapping concerns but differing metaphysical commitments and methodologies. Cognitive science itself appears increasingly fragmented, with subfields aligning differently with philosophy, neuroscience, or AI engineering.88 Even potentially unifying frameworks like Predictive Processing are subject to diverse metaphysical interpretations, potentially generating new divergences.61 However, a shared conceptual heritage, rooted in the cognitive revolution's questions about mind, information, and intelligence, arguably persists across these fields, even as interpretations diverge.10 The relationship is less a clean split and more an ongoing, complex negotiation of metaphysical commitments within and between increasingly specialized domains.

### **10.3. Unacknowledged Metaphysical Commitments**

Despite decades of debate, assumptions like representationalism and the information-processing metaphor remain deeply embedded, often functioning as implicit background frameworks rather than explicitly defended theses.10 Their persistence across different technical paradigms suggests they are powerful conceptual tools, but also potential sources of unexamined bias.10 Contemporary deep learning systems, particularly due to their opacity, likely harbor hidden metaphysical commitments regarding the nature of learned representations, the relationship between statistical patterns and meaning, and the criteria for intelligence, all requiring further philosophical scrutiny.185 Critiques from non-Anglo-American traditions further suggest that assumptions about rationality, individualism, and the subject-object distinction, inherited from specific Western philosophical lineages, may constitute unacknowledged biases shaping the research landscape.33

### **10.4. The Role of Renewed Interdisciplinary Engagement**

The increasing specialization and potential fragmentation underscore the need for renewed, critical interdisciplinary engagement.3 Such dialogue is crucial for:

* **Revealing Hidden Assumptions:** Making explicit the often-implicit metaphysical commitments underlying different research programs in AI, cognitive science, and philosophy.  
* **Conceptual Clarification:** Refining key concepts like "computation," "representation," "information," and "understanding" in light of new technologies and theoretical perspectives.  
* **Bridging Gaps:** Fostering communication and mutual understanding between fields with different methodologies and goals, potentially leading to more integrated approaches.  
* **Addressing Ethical Challenges:** Ensuring that the development and deployment of AI are informed by robust philosophical reflection on its implications for human cognition, agency, and values.

However, genuine integration faces significant institutional and intellectual hurdles, requiring conscious effort and structural support to overcome disciplinary silos.15

### **10.5. Final Reflection**

The relationship between AI's pragmatic success and foundational philosophical inquiry appears complex and dialectical.1 While commercial pressures and the sheer pace of technological development risk sidelining deep metaphysical reflection in favor of immediate engineering goals 233, the very power and pervasiveness of contemporary AI systems simultaneously generate profound philosophical questions that cannot be ignored.36 Questions about machine understanding, the nature of intelligence, the possibility of artificial consciousness, and the ethical implications of autonomous systems demand philosophical engagement with renewed urgency.81

The future of the cognitive triangle will likely involve navigating this tension. AI will continue to provide new tools and phenomena that stimulate and challenge philosophical thinking, while philosophy (along with cognitive science and neuroscience) will remain essential for critically examining AI's foundations, interpreting its capabilities, and guiding its development responsibly. The journey from the perceived metaphysical unity of the classical era has led not to a simple divergence, but to a richer, more complex, and more contested landscape. Understanding the metaphysical assumptions, divergences, and potential points of re-engagement across philosophy of mind, AI, and cognitive science remains crucial for navigating the future of intelligence, both natural and artificial.

#### **Works cited**

1. Cognitive Science \- Stanford Encyclopedia of Philosophy, accessed April 21, 2025, [https://plato.stanford.edu/entries/cognitive-science/](https://plato.stanford.edu/entries/cognitive-science/)  
2. Cognitive Science: History \- William Bechtel, accessed April 21, 2025, [https://mechanism.ucsd.edu/bill/teaching/w07/philpsych/bechtel.cogscihistory.pdf](https://mechanism.ucsd.edu/bill/teaching/w07/philpsych/bechtel.cogscihistory.pdf)  
3. THE RESISTIBLE RISE OF COGNITIVE SCIENCE \- PhilArchive, accessed April 21, 2025, [https://philarchive.org/archive/LANTRR](https://philarchive.org/archive/LANTRR)  
4. How Cognitive Science and Artificial Intelligence Are Intertwined \- UX Magazine, accessed April 21, 2025, [https://uxmag.com/articles/how-cognitive-science-and-artificial-intelligence-are-intertwined](https://uxmag.com/articles/how-cognitive-science-and-artificial-intelligence-are-intertwined)  
5. THE HISTORY OF COGNITIVE SCIENCE: SEVEN KEY DATES\* Margaret A. Boden (maggieb@cogs.susx.ac.uk) Abstract, accessed April 21, 2025, [https://cse.buffalo.edu/\~rapaport/Papers/Papers.by.Others/boden-7keydates.pdf](https://cse.buffalo.edu/~rapaport/Papers/Papers.by.Others/boden-7keydates.pdf)  
6. Scientific models, connectionist networks, and cognitive science \- York University, accessed April 21, 2025, [http://www.yorku.ca/christo/papers/models-TP2.htm](http://www.yorku.ca/christo/papers/models-TP2.htm)  
7. The Computational Theory of Mind \- Stanford Encyclopedia of Philosophy, accessed April 21, 2025, [https://plato.stanford.edu/entries/computational-mind/](https://plato.stanford.edu/entries/computational-mind/)  
8. Information Processing Theory In Psychology, accessed April 21, 2025, [https://www.simplypsychology.org/information-processing.html](https://www.simplypsychology.org/information-processing.html)  
9. Computational theory of mind \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Computational\_theory\_of\_mind](https://en.wikipedia.org/wiki/Computational_theory_of_mind)  
10. Philosophy of Mind and Cognitive Science since 1980 \- Professor John Sutton, accessed April 21, 2025, [https://johnsutton.net/wp-content/uploads/2017/01/2014-philosophy-of-mind-and-cognitive-science-since-1980.pdf](https://johnsutton.net/wp-content/uploads/2017/01/2014-philosophy-of-mind-and-cognitive-science-since-1980.pdf)  
11. Philosophy of Mind and Cognitive Science since 1980 \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/259742165\_Philosophy\_of\_Mind\_and\_Cognitive\_Science\_since\_1980](https://www.researchgate.net/publication/259742165_Philosophy_of_Mind_and_Cognitive_Science_since_1980)  
12. GOFAI \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/372392913\_GOFAI](https://www.researchgate.net/publication/372392913_GOFAI)  
13. Philosophy of Neuroscience \- Bibliography \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/browse/philosophy-of-neuroscience](https://philpapers.org/browse/philosophy-of-neuroscience)  
14. Cognitive Science and Philosophy of Mind, accessed April 21, 2025, [https://www.cmu.edu/dietrich/philosophy/research/areas/science-methodology/cognitive-science.html](https://www.cmu.edu/dietrich/philosophy/research/areas/science-methodology/cognitive-science.html)  
15. Making Interdisciplinary Collaboration Work \- Computer Science, accessed April 21, 2025, [https://www.cs.hunter.cuny.edu/\~epstein/papers/collaboration.pdf](https://www.cs.hunter.cuny.edu/~epstein/papers/collaboration.pdf)  
16. Metaphysical Biases in the Discourse of Artificial Intelligence \- eScholarship.org, accessed April 21, 2025, [https://escholarship.org/uc/item/80q3d4x3](https://escholarship.org/uc/item/80q3d4x3)  
17. Representationalism or Anti-representationalism? \- NTNU, accessed April 21, 2025, [https://www.ntnu.edu/documents/38274365/0/Structural+collaboration+project\_2011\_+final.pdf/d3fb5c0f-2ad9-0f90-2f09-467c0f061cc8?t=1709107751997](https://www.ntnu.edu/documents/38274365/0/Structural+collaboration+project_2011_+final.pdf/d3fb5c0f-2ad9-0f90-2f09-467c0f061cc8?t=1709107751997)  
18. Challenges to Metaphysical Realism \- Stanford Encyclopedia of Philosophy, accessed April 21, 2025, [https://plato.stanford.edu/entries/realism-sem-challenge/](https://plato.stanford.edu/entries/realism-sem-challenge/)  
19. Anthony Patrick Chemero, How to Be an Anti-Representationalist \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/rec/CHEHTB](https://philpapers.org/rec/CHEHTB)  
20. Process Philosophy, accessed April 21, 2025, [https://plato.stanford.edu/entries/process-philosophy/](https://plato.stanford.edu/entries/process-philosophy/)  
21. Ai and the philosophy of mind : r/askphilosophy \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/askphilosophy/comments/1i59scc/ai\_and\_the\_philosophy\_of\_mind/](https://www.reddit.com/r/askphilosophy/comments/1i59scc/ai_and_the_philosophy_of_mind/)  
22. John R. Searle's Chinese room argument, accessed April 21, 2025, [https://cse.buffalo.edu/\~rapaport/Papers/Papers.by.Others/reingold-on-searle.html](https://cse.buffalo.edu/~rapaport/Papers/Papers.by.Others/reingold-on-searle.html)  
23. Exploring the Connection of Philosophy and Artificial Intelligence, accessed April 21, 2025, [https://www.apu.apus.edu/area-of-study/arts-and-humanities/resources/exploring-the-connection-of-philosophy-and-artificial-intelligence/](https://www.apu.apus.edu/area-of-study/arts-and-humanities/resources/exploring-the-connection-of-philosophy-and-artificial-intelligence/)  
24. Philosophy of artificial intelligence \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Philosophy\_of\_artificial\_intelligence](https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence)  
25. The computational-representational theory of thought (CRTT) \- Britannica, accessed April 21, 2025, [https://www.britannica.com/topic/philosophy-of-mind/The-computational-representational-theory-of-thought-CRTT](https://www.britannica.com/topic/philosophy-of-mind/The-computational-representational-theory-of-thought-CRTT)  
26. Beyond the Physical: Exploring the Nature of the Mind, accessed April 21, 2025, [https://mindmatters.ai/2025/01/beyond-the-physical-exploring-the-nature-of-the-mind/](https://mindmatters.ai/2025/01/beyond-the-physical-exploring-the-nature-of-the-mind/)  
27. Cognitive Science and the Philosophy of Mind \- Rational Realm, accessed April 21, 2025, [https://www.rationalrealm.com/philosophy/metaphysics/cognitive-science-philosophy-mind.html](https://www.rationalrealm.com/philosophy/metaphysics/cognitive-science-philosophy-mind.html)  
28. The Philosophy of Neuroscience (Stanford Encyclopedia of ..., accessed April 21, 2025, [https://plato.stanford.edu/entries/neuroscience/](https://plato.stanford.edu/entries/neuroscience/)  
29. Question about the role of philosophy of mind for neuroscience and psychology \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/askphilosophy/comments/svbpe8/question\_about\_the\_role\_of\_philosophy\_of\_mind\_for/](https://www.reddit.com/r/askphilosophy/comments/svbpe8/question_about_the_role_of_philosophy_of_mind_for/)  
30. Chat GPT creates a Philosophy using Philosophy, Psychology, Information Science, etc, accessed April 21, 2025, [https://thephilosophyforum.com/discussion/15909/chat-gpt-creates-a-philosophy-using-philosophy-psychology-information-science-etc/latest/comment](https://thephilosophyforum.com/discussion/15909/chat-gpt-creates-a-philosophy-using-philosophy-psychology-information-science-etc/latest/comment)  
31. CogSciNotes.htm \- University of Houston, accessed April 21, 2025, [https://uh.edu/\~garson/CogSciNotes.htm](https://uh.edu/~garson/CogSciNotes.htm)  
32. Cognitive psychology-based artificial intelligence review \- PMC, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC9582153/](https://pmc.ncbi.nlm.nih.gov/articles/PMC9582153/)  
33. GOFAI \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/GOFAI](https://en.wikipedia.org/wiki/GOFAI)  
34. Aspects of Cognitive Neuroscience for the Solution of Problems Found in Contemporary Philosophy of Science \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/364894359\_Aspects\_of\_Cognitive\_Neuroscience\_for\_the\_Solution\_of\_Problems\_Found\_in\_Contemporary\_Philosophy\_of\_Science](https://www.researchgate.net/publication/364894359_Aspects_of_Cognitive_Neuroscience_for_the_Solution_of_Problems_Found_in_Contemporary_Philosophy_of_Science)  
35. AI and Human Futures: What Should Christians Think? | Dignitas Vol. 30, No. 4 (Winter 2023), accessed April 21, 2025, [https://www.cbhd.org/dignitas-articles/ai-and-human-futures-what-should-christians-think](https://www.cbhd.org/dignitas-articles/ai-and-human-futures-what-should-christians-think)  
36. Phenomenology, Cognition, and Artificial Intelligence – BSP Online, accessed April 21, 2025, [https://www.britishphenomenology.org.uk/phenomenology-cognition-and-artificial-intelligence/](https://www.britishphenomenology.org.uk/phenomenology-cognition-and-artificial-intelligence/)  
37. Daniel Andler, Phenomenology in cognitive science and artificial intelligence \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/rec/ANDPIC](https://philpapers.org/rec/ANDPIC)  
38. Daniel Andler, Phenomenology in Artificial Intelligence and Cognitive Science \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/rec/ANDPIA-6](https://philpapers.org/rec/ANDPIA-6)  
39. History of artificial intelligence \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/History\_of\_artificial\_intelligence](https://en.wikipedia.org/wiki/History_of_artificial_intelligence)  
40. Introduction to 'Cognitive artificial intelligence' | Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences \- Journals, accessed April 21, 2025, [https://royalsocietypublishing.org/doi/10.1098/rsta.2022.0051](https://royalsocietypublishing.org/doi/10.1098/rsta.2022.0051)  
41. Computational-representational understanding of mind \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Computational-representational\_understanding\_of\_mind](https://en.wikipedia.org/wiki/Computational-representational_understanding_of_mind)  
42. Theory of Mind and Preference Learning at the Interface of Cognitive Science, Neuroscience, and AI: A Review \- Frontiers, accessed April 21, 2025, [https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2022.778852/full](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2022.778852/full)  
43. Connectionism | Internet Encyclopedia of Philosophy, accessed April 21, 2025, [https://iep.utm.edu/connectionism-cognition/](https://iep.utm.edu/connectionism-cognition/)  
44. A Brief History of Connectionism, accessed April 21, 2025, [http://web.uvic.ca/\~dmedler/files/ncs98.pdf](http://web.uvic.ca/~dmedler/files/ncs98.pdf)  
45. 4.19: What Is Connectionist Cognitive Science? \- Social Sci LibreTexts, accessed April 21, 2025, [https://socialsci.libretexts.org/Bookshelves/Psychology/Cognitive\_Psychology/Mind\_Body\_World\_-\_Foundations\_of\_Cognitive\_Science\_(Dawson)/04%3A\_Elements\_of\_Connectionist\_Cognitive\_Science/4.19%3A\_What\_Is\_Connectionist\_Cognitive\_Science%3F](https://socialsci.libretexts.org/Bookshelves/Psychology/Cognitive_Psychology/Mind_Body_World_-_Foundations_of_Cognitive_Science_\(Dawson\)/04%3A_Elements_of_Connectionist_Cognitive_Science/4.19%3A_What_Is_Connectionist_Cognitive_Science%3F)  
46. ojs.aaai.org, accessed April 21, 2025, [https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/download/15111/18883](https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/download/15111/18883)  
47. The Architecture of Cognition: Rethinking Fodor and Pylyshyn's Systematicity Challenge | MIT Press Scholarship Online | Oxford Academic, accessed April 21, 2025, [https://academic.oup.com/mit-press-scholarship-online/book/18439](https://academic.oup.com/mit-press-scholarship-online/book/18439)  
48. Connectionism, Learning and Meaning \- CiteSeerX, accessed April 21, 2025, [https://citeseerx.ist.psu.edu/document?repid=rep1\&type=pdf\&doi=87353201c518d6858fb1bb318a4628242974c746](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=87353201c518d6858fb1bb318a4628242974c746)  
49. Problems of Connectionism \- MDPI, accessed April 21, 2025, [https://www.mdpi.com/2409-9287/9/2/41](https://www.mdpi.com/2409-9287/9/2/41)  
50. 4E Cognition. A philosophical paradigm \- UniTrentoMag, accessed April 21, 2025, [https://webmagazine.unitn.it/evento/cogsci/120875/4e-cognition-a-philosophical-paradigm](https://webmagazine.unitn.it/evento/cogsci/120875/4e-cognition-a-philosophical-paradigm)  
51. How does 4E Cognition compare to other contemporary theories of philosophy of mind? : r/askphilosophy \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/askphilosophy/comments/fx2ze8/how\_does\_4e\_cognition\_compare\_to\_other/](https://www.reddit.com/r/askphilosophy/comments/fx2ze8/how_does_4e_cognition_compare_to_other/)  
52. Minds in movement: embodied cognition in the age of artificial ..., accessed April 21, 2025, [https://royalsocietypublishing.org/doi/10.1098/rstb.2023.0144](https://royalsocietypublishing.org/doi/10.1098/rstb.2023.0144)  
53. Embodied Cognition (Stanford Encyclopedia of Philosophy), accessed April 21, 2025, [https://plato.stanford.edu/entries/embodied-cognition/](https://plato.stanford.edu/entries/embodied-cognition/)  
54. Embodied cognition and temporally extended agency \- CORE, accessed April 21, 2025, [https://core.ac.uk/download/pdf/131210284.pdf](https://core.ac.uk/download/pdf/131210284.pdf)  
55. Anti-Representationalism and the Dynamical Stance \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/249081399\_Anti-Representationalism\_and\_the\_Dynamical\_Stance](https://www.researchgate.net/publication/249081399_Anti-Representationalism_and_the_Dynamical_Stance)  
56. View of The many problems with S-representation (and how to solve them), accessed April 21, 2025, [https://philosophymindscience.org/index.php/phimisci/article/view/9758/10058](https://philosophymindscience.org/index.php/phimisci/article/view/9758/10058)  
57. Stanford Encyclopedia of Philosophy \- Clark Buckner, accessed April 21, 2025, [http://clarkbuckner.com/wp-content/uploads/2019/04/embodied-cognition-STANFORD-BUCKNER.pdf](http://clarkbuckner.com/wp-content/uploads/2019/04/embodied-cognition-STANFORD-BUCKNER.pdf)  
58. A. Wilson Robert & Foglia Lucia, Embodied cognition \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/rec/WILEC](https://philpapers.org/rec/WILEC)  
59. Cognitive Neuroscience \- Upcyte, accessed April 21, 2025, [https://www.upcyte.com/read/cognitive-neuroscience-1237.html](https://www.upcyte.com/read/cognitive-neuroscience-1237.html)  
60. Using fMRI in experimental philosophy: Exploring the prospects Rodrigo Díaz Abstract \- PhilArchive, accessed April 21, 2025, [https://philarchive.org/archive/DAZUFI](https://philarchive.org/archive/DAZUFI)  
61. Full article: Introduction, accessed April 21, 2025, [https://www.tandfonline.com/doi/full/10.1080/13869795.2018.1479440](https://www.tandfonline.com/doi/full/10.1080/13869795.2018.1479440)  
62. What Does a Large Language Model Know? \- Neuronline \- Society for Neuroscience, accessed April 21, 2025, [https://neuronline.sfn.org/scientific-research/what-does-a-large-language-model-know](https://neuronline.sfn.org/scientific-research/what-does-a-large-language-model-know)  
63. Raphaël Millière & Cameron Buckner, Interventionist Methods for Interpreting Deep Neural Networks \- PhilArchive, accessed April 21, 2025, [https://philarchive.org/rec/MILIMF-2](https://philarchive.org/rec/MILIMF-2)  
64. Tim Räz & Claus Beisbart, The Importance of Understanding Deep Learning \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/rec/RZTIO](https://philpapers.org/rec/RZTIO)  
65. AI without Representation? \- Bibliography \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/browse/ai-without-representation](https://philpapers.org/browse/ai-without-representation)  
66. Cognitive Science and the Information Processing Metaphor \- Ways of Knowing, accessed April 21, 2025, [https://woknowing.wordpress.com/2010/10/13/cognitive-science-and-the-information-processing-metaphor/](https://woknowing.wordpress.com/2010/10/13/cognitive-science-and-the-information-processing-metaphor/)  
67. (PDF) "Phenomenology" in the service of "Artificial Intelligence"? A ..., accessed April 21, 2025, [https://www.researchgate.net/publication/378872371\_Phenomenology\_in\_the\_service\_of\_Artificial\_Intelligence\_A\_Heideggerian\_Critique](https://www.researchgate.net/publication/378872371_Phenomenology_in_the_service_of_Artificial_Intelligence_A_Heideggerian_Critique)  
68. Existential Phenomenology and Cognitive Science, accessed April 21, 2025, [https://scholar.harvard.edu/files/sdkelly/files/14\_sk\_existential\_phen\_and\_cog\_sci.doc](https://scholar.harvard.edu/files/sdkelly/files/14_sk_existential_phen_and_cog_sci.doc)  
69. Phenomenology and the Cognitive Sciences | The Philosophy Paperboy, accessed April 21, 2025, [https://thephilosophypaperboy.com/feeds/phenomenology-and-the-cognitive-sciences/](https://thephilosophypaperboy.com/feeds/phenomenology-and-the-cognitive-sciences/)  
70. Hubert Dreyfus's views on artificial intelligence \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Hubert\_Dreyfus%27s\_views\_on\_artificial\_intelligence](https://en.wikipedia.org/wiki/Hubert_Dreyfus%27s_views_on_artificial_intelligence)  
71. (PDF) A Postmodern Critique of Artificial Intelligence \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/260943684\_A\_Postmodern\_Critique\_of\_Artificial\_Intelligence](https://www.researchgate.net/publication/260943684_A_Postmodern_Critique_of_Artificial_Intelligence)  
72. The cognitive research behind AI's rise | Stanford Report, accessed April 21, 2025, [https://news.stanford.edu/stories/2024/11/from-brain-to-machine-the-unexpected-journey-of-neural-networks](https://news.stanford.edu/stories/2024/11/from-brain-to-machine-the-unexpected-journey-of-neural-networks)  
73. Initiative to support interaction between cognitive sciences and artificial intelligence, accessed April 21, 2025, [https://ai.princeton.edu/news/2024/initiative-support-interaction-between-cognitive-sciences-and-artificial-intelligence](https://ai.princeton.edu/news/2024/initiative-support-interaction-between-cognitive-sciences-and-artificial-intelligence)  
74. AI Innovation Action Plan for Institutions of Higher Education, accessed April 21, 2025, [https://cset.georgetown.edu/publication/ai-innovation-action-plan-for-institutions-of-higher-education/](https://cset.georgetown.edu/publication/ai-innovation-action-plan-for-institutions-of-higher-education/)  
75. \[2405.04048\] Philosophy of Cognitive Science in the Age of Deep Learning \- arXiv, accessed April 21, 2025, [https://arxiv.org/abs/2405.04048](https://arxiv.org/abs/2405.04048)  
76. Predictive coding \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Predictive\_coding](https://en.wikipedia.org/wiki/Predictive_coding)  
77. Andrey Shkursky, Pure Reason as a Cognitive Framework: Toward a Self-Reflective Model of Human and Artificial Intelligence \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/rec/SHKPRA](https://philpapers.org/rec/SHKPRA)  
78. Dimensions of Disagreement: Divergence and Misalignment in Cognitive Science and Artificial Intelligence, accessed April 21, 2025, [https://cognition.princeton.edu/publications/dimensions-disagreement-divergence-and-misalignment-cognitive-science-and-artificial](https://cognition.princeton.edu/publications/dimensions-disagreement-divergence-and-misalignment-cognitive-science-and-artificial)  
79. Cognitive Science: An Introduction to the Study of Mind, accessed April 21, 2025, [http://www2.fiit.stuba.sk/\~kvasnicka/CognitiveScience/Friedenberg\_Cognitive%20science.pdf](http://www2.fiit.stuba.sk/~kvasnicka/CognitiveScience/Friedenberg_Cognitive%20science.pdf)  
80. How Philosophers and Scientists View Cognitive AI | HackerNoon, accessed April 21, 2025, [https://hackernoon.com/how-philosophers-and-scientists-view-cognitive-ai](https://hackernoon.com/how-philosophers-and-scientists-view-cognitive-ai)  
81. Theory Is All You Need: AI, Human Cognition, and Causal ..., accessed April 21, 2025, [https://pubsonline.informs.org/doi/10.1287/stsc.2024.0189](https://pubsonline.informs.org/doi/10.1287/stsc.2024.0189)  
82. Artificial intelligence, human cognition, and conscious supremacy \- Frontiers, accessed April 21, 2025, [https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1364714/full](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1364714/full)  
83. SQ4. How much have we progressed in understanding the key ..., accessed April 21, 2025, [https://ai100.stanford.edu/gathering-strength-gathering-storms-one-hundred-year-study-artificial-intelligence-ai100-2021-1/sq4](https://ai100.stanford.edu/gathering-strength-gathering-storms-one-hundred-year-study-artificial-intelligence-ai100-2021-1/sq4)  
84. Influence of Cognitive Neuroscience on Contemporary Philosophy ..., accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC6487795/](https://pmc.ncbi.nlm.nih.gov/articles/PMC6487795/)  
85. Cognition Without Neural Representation: Dynamics of a ... \- Frontiers, accessed April 21, 2025, [https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2021.643276/full](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2021.643276/full)  
86. AI Alignment, Philosophical Pluralism, and the Relevance of Non ..., accessed April 21, 2025, [https://www.alignmentforum.org/posts/jS2iiDPqMvZ2tnik2/ai-alignment-philosophical-pluralism-and-the-relevance-of](https://www.alignmentforum.org/posts/jS2iiDPqMvZ2tnik2/ai-alignment-philosophical-pluralism-and-the-relevance-of)  
87. What we think about when we think about ... \- PubMed Central, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC7509909/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7509909/)  
88. Cognitive Science in Search of Unity \- Instytut Filozofii i Socjologii PAN, accessed April 21, 2025, [https://ifispan.pl/cognitive-science-in-search-of-unity/](https://ifispan.pl/cognitive-science-in-search-of-unity/)  
89. Benzmüller | SYMBOLIC AI AND GÖDEL'S ONTOLOGICAL ARGUMENT | Zygon, accessed April 21, 2025, [https://www.zygonjournal.org/article/id/14861/](https://www.zygonjournal.org/article/id/14861/)  
90. View of Semantic Encyclopedias and Boolean Dreams | KULA ..., accessed April 21, 2025, [https://kula.uvic.ca/index.php/kula/article/view/155/458](https://kula.uvic.ca/index.php/kula/article/view/155/458)  
91. Metaphysics, Meaning, and Morality: A Theological Reflection on AI1 \- PhilArchive, accessed April 21, 2025, [https://philarchive.org/archive/WALMM-6](https://philarchive.org/archive/WALMM-6)  
92. Connectionism \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Connectionism](https://en.wikipedia.org/wiki/Connectionism)  
93. The Curious Case of Connectionism, accessed April 21, 2025, [https://pgrim.org/openphi/berkeley.pdf](https://pgrim.org/openphi/berkeley.pdf)  
94. AI for Beginners \- The Difference Between Symbolic & Connectionist AI \- RE•WORK Blog, accessed April 21, 2025, [https://blog.re-work.co/the-difference-between-symbolic-ai-and-connectionist-ai/](https://blog.re-work.co/the-difference-between-symbolic-ai-and-connectionist-ai/)  
95. Symbolism vs. Connectionism: A Closing Gap in Artificial Intelligence | Jieshu's Blog, accessed April 21, 2025, [http://wangjieshu.com/2017/12/23/symbol-vs-connectionism-a-closing-gap-in-artificial-intelligence/](http://wangjieshu.com/2017/12/23/symbol-vs-connectionism-a-closing-gap-in-artificial-intelligence/)  
96. The Computational Theory of Mind \- sabinasz.net, accessed April 21, 2025, [https://www.sabinasz.net/the-computational-theory-of-mind/](https://www.sabinasz.net/the-computational-theory-of-mind/)  
97. Knowledge Representation and Reasoning — A History DARPA Leadership \- AAAI Publications, accessed April 21, 2025, [https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/5295/7229](https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/5295/7229)  
98. DARPA's Impact on Artificial Intelligence \- AAAI Publications, accessed April 21, 2025, [https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/5294/7228](https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/5294/7228)  
99. 15-780: Introduction and History of AI \- CMU School of Computer Science, accessed April 21, 2025, [https://www.cs.cmu.edu/afs/cs/academic/class/15780-s16/www/slides/intro.pdf](https://www.cs.cmu.edu/afs/cs/academic/class/15780-s16/www/slides/intro.pdf)  
100. The Computational Theory of Mind \- Stanford Encyclopedia of Philosophy, accessed April 21, 2025, [https://plato.stanford.edu/archIves/fall2011/entries/computational-mind/](https://plato.stanford.edu/archIves/fall2011/entries/computational-mind/)  
101. Computational Theory of Mind | Internet Encyclopedia of Philosophy, accessed April 21, 2025, [https://iep.utm.edu/computational-theory-of-mind/](https://iep.utm.edu/computational-theory-of-mind/)  
102. The Computational Theory of Mind (Stanford Encyclopedia of Philosophy) | Are.na, accessed April 21, 2025, [https://www.are.na/block/329111](https://www.are.na/block/329111)  
103. The Computational Theory of Mind \> Notes (Stanford Encyclopedia of Philosophy), accessed April 21, 2025, [https://plato.sydney.edu.au/entries/computational-mind/notes.html](https://plato.sydney.edu.au/entries/computational-mind/notes.html)  
104. The computational theory of mind. \- Steven Horst \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/rec/HORTCT](https://philpapers.org/rec/HORTCT)  
105. The Chinese Room Argument \- Stanford Encyclopedia of Philosophy, accessed April 21, 2025, [https://plato.stanford.edu/entries/chinese-room/](https://plato.stanford.edu/entries/chinese-room/)  
106. What is the distinction between functionalism and a computational theory of mind? \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/askphilosophy/comments/12icjx4/what\_is\_the\_distinction\_between\_functionalism\_and/](https://www.reddit.com/r/askphilosophy/comments/12icjx4/what_is_the_distinction_between_functionalism_and/)  
107. Mental Representation \- Stanford Encyclopedia of Philosophy, accessed April 21, 2025, [https://plato.stanford.edu/entries/mental-representation/](https://plato.stanford.edu/entries/mental-representation/)  
108. Fodor and Pylyshyn: Three Minor Quibbles | Philosophical Naturalism, accessed April 21, 2025, [https://kingdablog.com/2015/03/28/fodor-and-pylyshyn-three-minor-quibbles/](https://kingdablog.com/2015/03/28/fodor-and-pylyshyn-three-minor-quibbles/)  
109. The representational theory of mind (Chapter 2\) \- The Cambridge Handbook of Cognitive Science, accessed April 21, 2025, [https://www.cambridge.org/core/books/cambridge-handbook-of-cognitive-science/representational-theory-of-mind/A098F044036FD75279859D751267689A](https://www.cambridge.org/core/books/cambridge-handbook-of-cognitive-science/representational-theory-of-mind/A098F044036FD75279859D751267689A)  
110. The Language of Thought Hypothesis (Stanford Encyclopedia of Philosophy), accessed April 21, 2025, [https://plato.stanford.edu/entries/language-thought/](https://plato.stanford.edu/entries/language-thought/)  
111. The computational origin of representation \- PMC \- PubMed Central, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC8300595/](https://pmc.ncbi.nlm.nih.gov/articles/PMC8300595/)  
112. Jerry A. Fodor & Zenon W. Pylyshyn, Connectionism and cognitive ..., accessed April 21, 2025, [https://philpapers.org/rec/FODCAC](https://philpapers.org/rec/FODCAC)  
113. philarchive.org, accessed April 21, 2025, [https://philarchive.org/archive/SPITRA-4](https://philarchive.org/archive/SPITRA-4)  
114. Connectionism \- Stanford Encyclopedia of Philosophy, accessed April 21, 2025, [https://plato.stanford.edu/entries/connectionism/](https://plato.stanford.edu/entries/connectionism/)  
115. Extended cognition | Mark Sprevak, accessed April 21, 2025, [https://marksprevak.com/publications/extended-cognition/](https://marksprevak.com/publications/extended-cognition/)  
116. Full article: Solving the relevance problem with predictive processing, accessed April 21, 2025, [https://www.tandfonline.com/doi/full/10.1080/09515089.2025.2460502?src=](https://www.tandfonline.com/doi/full/10.1080/09515089.2025.2460502?src)  
117. Connectionism | Philosophy Talk, accessed April 21, 2025, [https://www.philosophytalk.org/shows/connectionism](https://www.philosophytalk.org/shows/connectionism)  
118. Connectionism. The Stanford Encyclopedia of Philosophy (Winter 2002 Edition) | Request PDF \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/270819640\_Connectionism\_The\_Stanford\_Encyclopedia\_of\_Philosophy\_Winter\_2002\_Edition](https://www.researchgate.net/publication/270819640_Connectionism_The_Stanford_Encyclopedia_of_Philosophy_Winter_2002_Edition)  
119. en.wikipedia.org, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Connectionism\#:\~:text=The%20term%20connectionist%20model%20was,McClelland%2C%20David%20E.](https://en.wikipedia.org/wiki/Connectionism#:~:text=The%20term%20connectionist%20model%20was,McClelland%2C%20David%20E.)  
120. Connectionism (Stanford Encyclopedia of Philosophy/Winter 2018 Edition), accessed April 21, 2025, [https://plato.stanford.edu/archIves/win2018/entries/connectionism/](https://plato.stanford.edu/archIves/win2018/entries/connectionism/)  
121. S. F. Walker, A brief history of connectionism and its psychological implications \- PhilArchive, accessed April 21, 2025, [https://philarchive.org/rec/WALABH](https://philarchive.org/rec/WALABH)  
122. Connectionism \- Philosophy \- Oxford Bibliographies, accessed April 21, 2025, [https://www.oxfordbibliographies.com/abstract/document/obo-9780195396577/obo-9780195396577-0153.xml](https://www.oxfordbibliographies.com/abstract/document/obo-9780195396577/obo-9780195396577-0153.xml)  
123. PDP.Primer.html \- George Hollich, accessed April 21, 2025, [http://hincapie.psych.purdue.edu/PDP\_Primer/index.html](http://hincapie.psych.purdue.edu/PDP_Primer/index.html)  
124. How We Think: Brain-Inspired Models of Human Cognition Contribute to the Foundations of Today's Artificial Intelligence \- The Golden Goose Award, accessed April 21, 2025, [https://www.goldengooseaward.org/01awardees/pdp](https://www.goldengooseaward.org/01awardees/pdp)  
125. Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1 \- Gwern.net, accessed April 21, 2025, [https://gwern.net/doc/ai/nn/1986-rumelhart-pdp-v1.pdf](https://gwern.net/doc/ai/nn/1986-rumelhart-pdp-v1.pdf)  
126. Parallel Distributed Processing \- Stanford University, accessed April 21, 2025, [https://stanford.edu/\~jlmcc/papers/PDP/Chapter1.pdf](https://stanford.edu/~jlmcc/papers/PDP/Chapter1.pdf)  
127. Pinker and Prince vs. Rumelhart and McClelland – Brain Wars \- UMass Amherst, accessed April 21, 2025, [https://websites.umass.edu/brain-wars/the-debates/pinker-and-prince-vs-rumelhart-and-mcclelland/](https://websites.umass.edu/brain-wars/the-debates/pinker-and-prince-vs-rumelhart-and-mcclelland/)  
128. Parallel Distributed Processing \- Department of Computer Science, University of Toronto, accessed April 21, 2025, [http://www.cs.toronto.edu/\~fritz/absps/pdp1.pdf](http://www.cs.toronto.edu/~fritz/absps/pdp1.pdf)  
129. Parallel Distributed Processing, accessed April 21, 2025, [https://web.stanford.edu/\~jlmcc/papers/PDP/Chapter2.pdf](https://web.stanford.edu/~jlmcc/papers/PDP/Chapter2.pdf)  
130. Philosophy of Cognitive Science In the Age of Deep Learning \- arXiv, accessed April 21, 2025, [https://arxiv.org/html/2405.04048v1](https://arxiv.org/html/2405.04048v1)  
131. Connectionism and Cognitive Architecture: 1 A Critical Analysis, accessed April 21, 2025, [https://ruccs.rutgers.edu/images/personal-zenon-pylyshyn/proseminars/Proseminar13/ConnectionistArchitecture.pdf](https://ruccs.rutgers.edu/images/personal-zenon-pylyshyn/proseminars/Proseminar13/ConnectionistArchitecture.pdf)  
132. Connectionism, Learning and Meaning: Connection Science \- Taylor and Francis, accessed April 21, 2025, [https://www.tandfonline.com/doi/abs/10.1080/09540099208946617](https://www.tandfonline.com/doi/abs/10.1080/09540099208946617)  
133. Why Fodor and Pylyshyn Were Wrong: The Simplest Refutation, accessed April 21, 2025, [https://uh.edu/\~garson/Chalmers.PDF](https://uh.edu/~garson/Chalmers.PDF)  
134. consc.net, accessed April 21, 2025, [https://consc.net/papers/f-and-p.pdf](https://consc.net/papers/f-and-p.pdf)  
135. The Connectionist/Classical Debate \- Bibliography \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/browse/the-connectionistclassical-debate](https://philpapers.org/browse/the-connectionistclassical-debate)  
136. Ivan M.Havel \- Artificial Intelligence and Connectionism: Some Philosophical Implications, accessed April 21, 2025, [http://www.cts.cuni.cz/\~havel/work/ai-cvut.html](http://www.cts.cuni.cz/~havel/work/ai-cvut.html)  
137. Connectionism, Systematicity, and Nomic Necessity \- eScholarship.org, accessed April 21, 2025, [https://escholarship.org/uc/item/5kv2p52d](https://escholarship.org/uc/item/5kv2p52d)  
138. Smolensky vs. Fodor and Pylyshyn – Brain Wars, accessed April 21, 2025, [https://websites.umass.edu/brain-wars/the-debates/smolensky-vs-fodor-and-pylyshkyn/](https://websites.umass.edu/brain-wars/the-debates/smolensky-vs-fodor-and-pylyshkyn/)  
139. Philosophy of cognitive science in the age of deep learning | Request PDF \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/380783723\_Philosophy\_of\_cognitive\_science\_in\_the\_age\_of\_deep\_learning](https://www.researchgate.net/publication/380783723_Philosophy_of_cognitive_science_in_the_age_of_deep_learning)  
140. James Garson & Cameron Buckner, Connectionism \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/rec/GARC-2](https://philpapers.org/rec/GARC-2)  
141. philosophy of mind \- Philosophical Implications of Connectionism and Pattern Recognition, accessed April 21, 2025, [https://philosophy.stackexchange.com/questions/36230/philosophical-implications-of-connectionism-and-pattern-recognition](https://philosophy.stackexchange.com/questions/36230/philosophical-implications-of-connectionism-and-pattern-recognition)  
142. Consciousness, 4E cognition and Aristotle: a few conceptual and historical aspects, accessed April 21, 2025, [https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2023.1204602/full](https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2023.1204602/full)  
143. What is 4E cognitive science? \- Zurich Open Repository and Archive, accessed April 21, 2025, [https://www.zora.uzh.ch/270584](https://www.zora.uzh.ch/270584)  
144. Consciousness, 4E cognition and Aristotle: a few conceptual and historical aspects \- PMC, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10699441/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10699441/)  
145. Thinking avant la lettre: A Review of 4E Cognition \- PMC, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC7250653/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7250653/)  
146. Cameron Alexander, What is 4E cognitive science? \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/rec/ALEWIE](https://philpapers.org/rec/ALEWIE)  
147. (PDF) What is 4E cognitive science? \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/388231644\_What\_is\_4E\_cognitive\_science](https://www.researchgate.net/publication/388231644_What_is_4E_cognitive_science)  
148. Research on 4E Cognition, Conceptual Metaphor, and Ritual Magic from the History of Hermetic Philosophy and Related Currents Department at the University of Amsterdam : r/cogsci \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/cogsci/comments/1ffyezg/research\_on\_4e\_cognition\_conceptual\_metaphor\_and/](https://www.reddit.com/r/cogsci/comments/1ffyezg/research_on_4e_cognition_conceptual_metaphor_and/)  
149. Embodied cognition \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Embodied\_cognition](https://en.wikipedia.org/wiki/Embodied_cognition)  
150. Embodied AI beyond Embodied Cognition and Enactivism \- MDPI, accessed April 21, 2025, [https://www.mdpi.com/2409-9287/4/3/39](https://www.mdpi.com/2409-9287/4/3/39)  
151. Enacting anti-representationalism. \- PhilArchive, accessed April 21, 2025, [https://philarchive.org/archive/STEEAT-12](https://philarchive.org/archive/STEEAT-12)  
152. 4E Cognition in the Age of Artificial Intelligence \- Instituto de Filosofia \- UP, accessed April 21, 2025, [https://ifilosofia.up.pt/projects/4ecai](https://ifilosofia.up.pt/projects/4ecai)  
153. Beyond the computational-representational brain: why affective neuroscience tells us attitudes must be explained on multiple levels \- PubMed Central, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC4255623/](https://pmc.ncbi.nlm.nih.gov/articles/PMC4255623/)  
154. From academia to UX: Embodied cognition, creativity, and generative AI | ACM Interactions, accessed April 21, 2025, [https://interactions.acm.org/blog/view/from-academia-to-ux-embodied-cognition-creativity-and-generative-ai](https://interactions.acm.org/blog/view/from-academia-to-ux-embodied-cognition-creativity-and-generative-ai)  
155. Editorial: Bio A.I. \- from embodied cognition to enactive robotics \- PMC \- PubMed Central, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10682788/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10682788/)  
156. Editorial: Bio A.I. \- from embodied cognition to enactive robotics \- Frontiers, accessed April 21, 2025, [https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2023.1301993/full](https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2023.1301993/full)  
157. Towards a General Theory of Antirepresentationalism \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/240584355\_Towards\_a\_General\_Theory\_of\_Antirepresentationalism](https://www.researchgate.net/publication/240584355_Towards_a_General_Theory_of_Antirepresentationalism)  
158. Critique of some recent philosophy of LLMs' minds \- AI Alignment Forum, accessed April 21, 2025, [https://www.alignmentforum.org/posts/ejEgaYSaefCevapPa/critique-of-some-recent-philosophy-of-llms-minds](https://www.alignmentforum.org/posts/ejEgaYSaefCevapPa/critique-of-some-recent-philosophy-of-llms-minds)  
159. Anti-representationalism: Not a Well-founded Theory of Cognition, accessed April 21, 2025, [https://www.sdu.dk/Om\_SDU/Institutter\_centre/Ifpr/Formidling/Tidsskrifter/rescogitans/Issues/\~/media/57F5A7E888CB4E48BDC5B2155B758CD1.pdf](https://www.sdu.dk/Om_SDU/Institutter_centre/Ifpr/Formidling/Tidsskrifter/rescogitans/Issues/~/media/57F5A7E888CB4E48BDC5B2155B758CD1.pdf)  
160. Phenomenology \- Stanford Encyclopedia of Philosophy, accessed April 21, 2025, [https://plato.stanford.edu/entries/phenomenology/](https://plato.stanford.edu/entries/phenomenology/)  
161. Phenomenology, Cognitive Science, and Authenticity with Michael Wheeler \- YouTube, accessed April 21, 2025, [https://www.youtube.com/watch?v=X52h07\_5l6I](https://www.youtube.com/watch?v=X52h07_5l6I)  
162. Anti-Representationalism and the Dynamical Stance | Philosophy of Science, accessed April 21, 2025, [https://www.cambridge.org/core/journals/philosophy-of-science/article/antirepresentationalism-and-the-dynamical-stance/C3F70010394DD89C529DD91EE7A98317](https://www.cambridge.org/core/journals/philosophy-of-science/article/antirepresentationalism-and-the-dynamical-stance/C3F70010394DD89C529DD91EE7A98317)  
163. Representation Reconsidered \- Notre Dame Philosophical Reviews, accessed April 21, 2025, [https://ndpr.nd.edu/reviews/representation-reconsidered/](https://ndpr.nd.edu/reviews/representation-reconsidered/)  
164. A Call for Embodied AI \- arXiv, accessed April 21, 2025, [https://arxiv.org/html/2402.03824v3](https://arxiv.org/html/2402.03824v3)  
165. AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking, accessed April 21, 2025, [https://www.mdpi.com/2075-4698/15/1/6](https://www.mdpi.com/2075-4698/15/1/6)  
166. Protecting Human Cognition in the Age of AI \- arXiv, accessed April 21, 2025, [https://arxiv.org/html/2502.12447v1](https://arxiv.org/html/2502.12447v1)  
167. ECOLE-AI: Advancing EFL Learning with Cognitive Theory and Entangled Cognition in the AI Era \- Juniper Publishers, accessed April 21, 2025, [https://juniperpublishers.com/pbsij/PBSIJ.MS.ID.556090.php](https://juniperpublishers.com/pbsij/PBSIJ.MS.ID.556090.php)  
168. From tools to threats: a reflection on the impact of artificial-intelligence chatbots on cognitive health \- PMC, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11020077/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11020077/)  
169. Symbolism Versus Connectionism In AI: Is There A Third Way? \- Forbes, accessed April 21, 2025, [https://www.forbes.com/councils/forbestechcouncil/2020/09/01/symbolism-versus-connectionism-in-ai-is-there-a-third-way/](https://www.forbes.com/councils/forbestechcouncil/2020/09/01/symbolism-versus-connectionism-in-ai-is-there-a-third-way/)  
170. \[D\] Research at the intersection of Machine Learning and Cognitive Science? : r/MachineLearning \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/MachineLearning/comments/m149o6/d\_research\_at\_the\_intersection\_of\_machine/](https://www.reddit.com/r/MachineLearning/comments/m149o6/d_research_at_the_intersection_of_machine/)  
171. Cognitive neuroscience \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Cognitive\_neuroscience](https://en.wikipedia.org/wiki/Cognitive_neuroscience)  
172. Cognitive psychology-based artificial intelligence review \- Frontiers, accessed April 21, 2025, [https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.1024316/full](https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.1024316/full)  
173. A new era in cognitive neuroscience: the tidal wave of artificial ..., accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11075265/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11075265/)  
174. Introduction \- Neuroscience and Philosophy \- NCBI Bookshelf, accessed April 21, 2025, [https://www.ncbi.nlm.nih.gov/books/NBK583707/](https://www.ncbi.nlm.nih.gov/books/NBK583707/)  
175. Neuroscience and Cognitive Science: Philosophy of Mind | The University of Arizona, accessed April 21, 2025, [https://www.arizona.edu/degree-search/majors/neuroscience-and-cognitive-science-philosophy-of-mind-emphasis](https://www.arizona.edu/degree-search/majors/neuroscience-and-cognitive-science-philosophy-of-mind-emphasis)  
176. How fMRI can inform cognitive theories \- PMC \- PubMed Central, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC3610572/](https://pmc.ncbi.nlm.nih.gov/articles/PMC3610572/)  
177. Neurophilosophy: A Philosophical Analysis for Interpretation of fMRI to Replace the Commonsense Psychology | Life and Science \- DOI, accessed April 21, 2025, [https://dx.doi.org/10.37185/LnS.1.1.392](https://dx.doi.org/10.37185/LnS.1.1.392)  
178. Revisiting philosophy with fMRI \- American Psychological Association, accessed April 21, 2025, [https://www.apa.org/monitor/2010/11/fmri](https://www.apa.org/monitor/2010/11/fmri)  
179. (PDF) Using fMRI in Experimental Philosophy: Exploring the Prospects \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/327186811\_Using\_fMRI\_in\_Experimental\_Philosophy\_Exploring\_the\_Prospects](https://www.researchgate.net/publication/327186811_Using_fMRI_in_Experimental_Philosophy_Exploring_the_Prospects)  
180. Intentional Minds: A Philosophical Analysis of Intention Tested through fMRI Experiments Involving People with Schizophrenia, People with Autism, and Healthy Individuals \- PubMed Central, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC3034216/](https://pmc.ncbi.nlm.nih.gov/articles/PMC3034216/)  
181. Implications of Neuroscience for Ancient Traditional Philosophical Questions, accessed April 21, 2025, [https://www.jneurophilosophy.com/index.php/jnp/announcement/view/18](https://www.jneurophilosophy.com/index.php/jnp/announcement/view/18)  
182. Computational neuroscience FAQ \- Rajan Lab, accessed April 21, 2025, [https://www.rajanlab.com/faq](https://www.rajanlab.com/faq)  
183. Neuroethics and AI ethics: a proposal for collaboration \- PMC \- PubMed Central, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11360855/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11360855/)  
184. Philosophy of Mind: Neural Networks, Information Processing, and AI, accessed April 21, 2025, [https://susannaschellenberg.org/teaching/philosophy-of-mind-neural-networks-information-processing-and-ai/](https://susannaschellenberg.org/teaching/philosophy-of-mind-neural-networks-information-processing-and-ai/)  
185. PhilSci-Archive \- Black Boxes and Theory Deserts: Deep Networks and Epistemic Opacity in the Cognitive Sciences, accessed April 21, 2025, [https://philsci-archive.pitt.edu/20492/1/Faries%20%26%20Raja%20%282022%29%2C%20Black%20bloxes%20and%20theory%20deserts%20%28Preprint%29.pdf](https://philsci-archive.pitt.edu/20492/1/Faries%20%26%20Raja%20%282022%29%2C%20Black%20bloxes%20and%20theory%20deserts%20%28Preprint%29.pdf)  
186. Philosophy of cognitive science in the age of deep learning \- PubMed, accessed April 21, 2025, [https://pubmed.ncbi.nlm.nih.gov/38773731/](https://pubmed.ncbi.nlm.nih.gov/38773731/)  
187. (PDF) Deep learning and cognitive science \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/342257894\_Deep\_learning\_and\_cognitive\_science](https://www.researchgate.net/publication/342257894_Deep_learning_and_cognitive_science)  
188. The Meta-Dialectic: AI and Human Thought as a Higher Synthesis \-A Hegelian Exploration of Human-Machine Collaboration \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/387319209\_The\_Meta-Dialectic\_AI\_and\_Human\_Thought\_as\_a\_Higher\_Synthesis\_-A\_Hegelian\_Exploration\_of\_Human-Machine\_Collaboration](https://www.researchgate.net/publication/387319209_The_Meta-Dialectic_AI_and_Human_Thought_as_a_Higher_Synthesis_-A_Hegelian_Exploration_of_Human-Machine_Collaboration)  
189. Chaudhary | THE ARTIFICIALIZATION OF MIND AND WORLD, accessed April 21, 2025, [https://www.zygonjournal.org/article/id/14647/](https://www.zygonjournal.org/article/id/14647/)  
190. Palatable Conceptions of Disembodied Being: Terra Incognita in the Space of Possible Minds \- arXiv, accessed April 21, 2025, [https://arxiv.org/html/2503.16348v1](https://arxiv.org/html/2503.16348v1)  
191. Alex Grzankowski (Birkbeck, University of London): Publications \- PhilPeople, accessed April 21, 2025, [https://philpeople.org/profiles/alex-grzankowski/publications?app=philevents%22%3EJan](https://philpeople.org/profiles/alex-grzankowski/publications?app=philevents%22%3EJan)  
192. Large Language Models \- Bibliography \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/browse/large-language-models](https://philpapers.org/browse/large-language-models)  
193. Understanding LLM Understanding, accessed April 21, 2025, [https://skywritingspress.ca/2019/01/08/the-journey-begins/](https://skywritingspress.ca/2019/01/08/the-journey-begins/)  
194. philarchive.org, accessed April 21, 2025, [https://philarchive.org/archive/BROIAR-4](https://philarchive.org/archive/BROIAR-4)  
195. No Consciousness? No Meaning (and no AGI)\! \- Article (Preprint v2) by Marco Masi | Qeios, accessed April 21, 2025, [https://www.qeios.com/read/DN232Y.2](https://www.qeios.com/read/DN232Y.2)  
196. Large Language Models: The Need for Nuance in Current Debates and a Pragmatic Perspective on Understanding | OpenReview, accessed April 21, 2025, [https://openreview.net/forum?id=DOlbbJhJ1A](https://openreview.net/forum?id=DOlbbJhJ1A)  
197. arxiv.org, accessed April 21, 2025, [https://arxiv.org/pdf/2310.17407](https://arxiv.org/pdf/2310.17407)  
198. arxiv.org, accessed April 21, 2025, [https://arxiv.org/abs/2310.19671](https://arxiv.org/abs/2310.19671)  
199. \[2310.17407\] Meaning and understanding in large language models \- arXiv, accessed April 21, 2025, [https://arxiv.org/abs/2310.17407](https://arxiv.org/abs/2310.17407)  
200. Teaching AI What it Should and Shouldn't Do \- DARPA, accessed April 21, 2025, [https://www.darpa.mil/news/2024/teaching-ai](https://www.darpa.mil/news/2024/teaching-ai)  
201. Thinking Deep with AI: The Renaissance of the Socratic Method | AI News \- OpenTools, accessed April 21, 2025, [https://opentools.ai/news/thinking-deep-with-ai-the-renaissance-of-the-socratic-method](https://opentools.ai/news/thinking-deep-with-ai-the-renaissance-of-the-socratic-method)  
202. Google DeepMind paper about AI's catastrophic risk : r/singularity \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/singularity/comments/13skdta/google\_deepmind\_paper\_about\_ais\_catastrophic\_risk/](https://www.reddit.com/r/singularity/comments/13skdta/google_deepmind_paper_about_ais_catastrophic_risk/)  
203. Cameron Buckner \- "The philosophy of Large Language Models" \- YouTube, accessed April 21, 2025, [https://www.youtube.com/watch?v=cl\_qFYShnt0](https://www.youtube.com/watch?v=cl_qFYShnt0)  
204. Symbolic AI vs. Connectionist AI: Know the Difference \- SmythOS, accessed April 21, 2025, [https://smythos.com/ai-agents/ai-tutorials/symbolic-ai-vs-connectionist-ai/](https://smythos.com/ai-agents/ai-tutorials/symbolic-ai-vs-connectionist-ai/)  
205. AI's mysterious 'black box' problem, explained | University of Michigan-Dearborn, accessed April 21, 2025, [https://umdearborn.edu/news/ais-mysterious-black-box-problem-explained](https://umdearborn.edu/news/ais-mysterious-black-box-problem-explained)  
206. Black-Box Access is Insufficient for Rigorous AI Audits \- arXiv, accessed April 21, 2025, [https://arxiv.org/html/2401.14446v1](https://arxiv.org/html/2401.14446v1)  
207. Why Are We Using Black Box Models in AI When We Don't Need To ..., accessed April 21, 2025, [https://hdsr.mitpress.mit.edu/pub/f9kuryi8](https://hdsr.mitpress.mit.edu/pub/f9kuryi8)  
208. Meaningful Explanations of Black Box AI Decision Systems | Proceedings of the AAAI Conference on Artificial Intelligence, accessed April 21, 2025, [https://ojs.aaai.org/index.php/AAAI/article/view/5050](https://ojs.aaai.org/index.php/AAAI/article/view/5050)  
209. Why are we using black box models in AI when we don't need to? (2019) \- Hacker News, accessed April 21, 2025, [https://news.ycombinator.com/item?id=21953293](https://news.ycombinator.com/item?id=21953293)  
210. The Artificial Intelligence Black Box and the Failure of Intent and Causation \- Harvard Journal of Law & Technology, accessed April 21, 2025, [https://jolt.law.harvard.edu/assets/articlePDFs/v31/The-Artificial-Intelligence-Black-Box-and-the-Failure-of-Intent-and-Causation-Yavar-Bathaee.pdf](https://jolt.law.harvard.edu/assets/articlePDFs/v31/The-Artificial-Intelligence-Black-Box-and-the-Failure-of-Intent-and-Causation-Yavar-Bathaee.pdf)  
211. \[D\] Is the 'black box' issue being exaggerated? : r/MachineLearning \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/MachineLearning/comments/7cua8j/d\_is\_the\_black\_box\_issue\_being\_exaggerated/](https://www.reddit.com/r/MachineLearning/comments/7cua8j/d_is_the_black_box_issue_being_exaggerated/)  
212. AAAI-21 Tutorial Forum, accessed April 21, 2025, [https://aaai.org/conference/aaai/aaai-21/aaai21tutorials/](https://aaai.org/conference/aaai/aaai-21/aaai21tutorials/)  
213. How Can Deep Neural Networks Inform Theory in Psychological Science? \- OSF, accessed April 21, 2025, [https://osf.io/preprints/psyarxiv/j5ckf](https://osf.io/preprints/psyarxiv/j5ckf)  
214. AAAI-25 Tutorial and Lab List \- AAAI, accessed April 21, 2025, [https://aaai.org/conference/aaai/aaai-25/tutorial-and-lab-list/](https://aaai.org/conference/aaai/aaai-25/tutorial-and-lab-list/)  
215. A new frontier in artificial intelligence \- Deloitte, accessed April 21, 2025, [https://www2.deloitte.com/content/dam/Deloitte/us/Documents/deloitte-analytics/us-ai-institute-generative-artificial-intelligence.pdf](https://www2.deloitte.com/content/dam/Deloitte/us/Documents/deloitte-analytics/us-ai-institute-generative-artificial-intelligence.pdf)  
216. Information processing, computation, and cognition \- PMC \- PubMed Central, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC3006465/](https://pmc.ncbi.nlm.nih.gov/articles/PMC3006465/)  
217. Information Processing Theory in Psychology \- Verywell Mind, accessed April 21, 2025, [https://www.verywellmind.com/information-processing-theory-in-psychology-7503601](https://www.verywellmind.com/information-processing-theory-in-psychology-7503601)  
218. How do scientists criticize the computer metaphor of the brain? \- John Benjamins, accessed April 21, 2025, [https://www.jbe-platform.com/content/journals/10.1075/jaic.19018.bil](https://www.jbe-platform.com/content/journals/10.1075/jaic.19018.bil)  
219. Metaphors and Science: Are Brains like Computers? \- Spiegeloog, accessed April 21, 2025, [https://www.spiegeloog.amsterdam/metaphors-and-science-are-brains-like-computers/](https://www.spiegeloog.amsterdam/metaphors-and-science-are-brains-like-computers/)  
220. How do scientists criticize the computer metaphor of the brain? \- John Benjamins, accessed April 21, 2025, [https://benjamins.com/catalog/jaic.19018.bil](https://benjamins.com/catalog/jaic.19018.bil)  
221. Phenomenology and the Cognitive Sciences, accessed April 21, 2025, [https://ophen.org/series-934](https://ophen.org/series-934)  
222. Rosalie Waelen, Why AI Ethics Is a Critical Theory \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/rec/WAEWAE](https://philpapers.org/rec/WAEWAE)  
223. Towards a Critical Philosophy of Science: Continental Beginnings and Bugbears, Whigs, and Waterbears \- Fordham Research Commons, accessed April 21, 2025, [https://research.library.fordham.edu/cgi/viewcontent.cgi?article=1040\&context=phil\_babich](https://research.library.fordham.edu/cgi/viewcontent.cgi?article=1040&context=phil_babich)  
224. What is the relationship between Critical Theory and Continental Philosophy? \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/CriticalTheory/comments/jrjw5z/what\_is\_the\_relationship\_between\_critical\_theory/](https://www.reddit.com/r/CriticalTheory/comments/jrjw5z/what_is_the_relationship_between_critical_theory/)  
225. Personal identity, collective identity, the identity of science – continental versus analytic perspectives \- Frederik van Gelder, accessed April 21, 2025, [https://www.amsterdam-adorno.net/fvg2005\_continental-analytic.html](https://www.amsterdam-adorno.net/fvg2005_continental-analytic.html)  
226. If Anglo-American Philosophy Is So Great, Where Is Its Las Casas? (guest post by Manuel R. Vargas), accessed April 21, 2025, [https://dailynous.com/2017/05/16/anglo-american-philosophy-great-las-casas/](https://dailynous.com/2017/05/16/anglo-american-philosophy-great-las-casas/)  
227. 49115 PDFs | Review articles in CONTINENTAL PHILOSOPHY \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/topic/Continental-Philosophy/publications](https://www.researchgate.net/topic/Continental-Philosophy/publications)  
228. Is it the case that most scientists' issues with "philosophy" are actually with metaphysics and continental philosophy, not analytical philosophy? \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/philosophy/comments/2c1lu1/is\_it\_the\_case\_that\_most\_scientists\_issues\_with/](https://www.reddit.com/r/philosophy/comments/2c1lu1/is_it_the_case_that_most_scientists_issues_with/)  
229. XAI: Explainable Artificial Intelligence \- DARPA, accessed April 21, 2025, [https://www.darpa.mil/research/programs/explainable-artificial-intelligence](https://www.darpa.mil/research/programs/explainable-artificial-intelligence)  
230. Is AI Becoming Sentient? \- Communications of the ACM, accessed April 21, 2025, [https://cacm.acm.org/news/is-ai-becoming-sentient/](https://cacm.acm.org/news/is-ai-becoming-sentient/)  
231. DARPA's Contributions to AI. A graphical representation of DARPA's... | Download Scientific Diagram \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/figure/DARPAs-Contributions-to-AI-A-graphical-representation-of-DARPAs-contribution-to-AI\_fig1\_342628304](https://www.researchgate.net/figure/DARPAs-Contributions-to-AI-A-graphical-representation-of-DARPAs-contribution-to-AI_fig1_342628304)  
232. Initiative on AI and Education \- The Spencer Foundation, accessed April 21, 2025, [https://www.spencer.org/initiative-on-ai-and-education](https://www.spencer.org/initiative-on-ai-and-education)  
233. Artificial Intelligence Inheriting the Historical Crisis in Psychology: An ..., accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC8961441/](https://pmc.ncbi.nlm.nih.gov/articles/PMC8961441/)  
234. Philosophy Eats AI \- MIT Sloan Management Review, accessed April 21, 2025, [https://sloanreview.mit.edu/article/philosophy-eats-ai/](https://sloanreview.mit.edu/article/philosophy-eats-ai/)  
235. www.nber.org, accessed April 21, 2025, [https://www.nber.org/system/files/working\_papers/w24449/w24449.pdf](https://www.nber.org/system/files/working_papers/w24449/w24449.pdf)  
236. Ethical considerations with Google DeepMind scientist | Google Workspace Blog, accessed April 21, 2025, [https://workspace.google.com/blog/ai-and-machine-learning/thinking-through-ethics-ai-assistants-iason-gabriel-google-deepmind](https://workspace.google.com/blog/ai-and-machine-learning/thinking-through-ethics-ai-assistants-iason-gabriel-google-deepmind)  
237. Accelerating scientific breakthroughs with an AI co-scientist \- Google Research, accessed April 21, 2025, [https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/](https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/)  
238. Has OpenAI Surpassed DeepMind? : r/singularity \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/singularity/comments/i59uug/has\_openai\_surpassed\_deepmind/](https://www.reddit.com/r/singularity/comments/i59uug/has_openai_surpassed_deepmind/)  
239. Google Does Not Deserve DeepMind \- Analytics India Magazine, accessed April 21, 2025, [https://analyticsindiamag.com/global-tech/google-does-not-deserve-deepmind/](https://analyticsindiamag.com/global-tech/google-does-not-deserve-deepmind/)  
240. Advocating for Tech Firms to Hire Philosophers \- Daily Nous, accessed April 21, 2025, [https://dailynous.com/2019/11/25/tech-firms-hire-philosophers/](https://dailynous.com/2019/11/25/tech-firms-hire-philosophers/)  
241. How AI Is Transforming Life Sciences Commercialization \- Klick Ideas Exchange, accessed April 21, 2025, [https://idx.klick.com/articles/how-ai-is-transforming-life-sciences-commercialization](https://idx.klick.com/articles/how-ai-is-transforming-life-sciences-commercialization)  
242. Ethical Implications of the Commercialization of Artificial Intelligence (AI) Birmingham Business School \- ResearchGate, accessed April 21, 2025, [https://www.researchgate.net/publication/371510599\_Ethical\_Implications\_of\_the\_Commercialization\_of\_Artificial\_Intelligence\_AI\_Birmingham\_Business\_School](https://www.researchgate.net/publication/371510599_Ethical_Implications_of_the_Commercialization_of_Artificial_Intelligence_AI_Birmingham_Business_School)  
243. Digital Society Lab's Ljubisa Bojic on Bridging Science and AI Industry, accessed April 21, 2025, [https://therecursive.com/the-ai-dilemma-how-to-balance-commercial-growth-with-ethical-considerations/](https://therecursive.com/the-ai-dilemma-how-to-balance-commercial-growth-with-ethical-considerations/)  
244. AI Ethics Lab Explores Impacts of the Technology's Rapid Growth | Rutgers University-Camden, accessed April 21, 2025, [https://camden.rutgers.edu/news/ai-ethics-lab-explores-impacts-technologys-rapid-growth](https://camden.rutgers.edu/news/ai-ethics-lab-explores-impacts-technologys-rapid-growth)  
245. Introduction to the Philosophy of Cognitive Sciences | Coursera, accessed April 21, 2025, [https://www.coursera.org/learn/philosophy-cognitive-sciences](https://www.coursera.org/learn/philosophy-cognitive-sciences)  
246. Sailing through the Challenges of Artificial Intelligence in Institutional Research | AIR, accessed April 21, 2025, [https://www.airweb.org/article/2025/03/28/sailing-through-the-challenges-of-ai-in-ir](https://www.airweb.org/article/2025/03/28/sailing-through-the-challenges-of-ai-in-ir)  
247. Interdisciplinary research in artificial intelligence: Lessons from COVID-19 \- MIT Press Direct, accessed April 21, 2025, [https://direct.mit.edu/qss/article/5/4/922/124451/Interdisciplinary-research-in-artificial](https://direct.mit.edu/qss/article/5/4/922/124451/Interdisciplinary-research-in-artificial)  
248. How will Artificial Intelligence (AI) influence openness and collaboration in science?, accessed April 21, 2025, [https://elephantinthelab.org/how-will-artificial-intelligence-ai-influence-openness-and-collaboration-in-science/](https://elephantinthelab.org/how-will-artificial-intelligence-ai-influence-openness-and-collaboration-in-science/)  
249. Interdisciplinary Confusion and Resolution in the Context of Moral Machines \- PMC, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC9120092/](https://pmc.ncbi.nlm.nih.gov/articles/PMC9120092/)  
250. \[2310.12994\] Dimensions of Disagreement: Unpacking Divergence and Misalignment in Cognitive Science and Artificial Intelligence \- arXiv, accessed April 21, 2025, [https://arxiv.org/abs/2310.12994](https://arxiv.org/abs/2310.12994)  
251. AI has impressed with its use of Bayesian inference to approximate some human capabilities. Hmmm … are our brains Bayesian? \- Gregory Bufithis, accessed April 21, 2025, [https://www.gregorybufithis.com/2020/10/15/are-our-brains-bayesian/](https://www.gregorybufithis.com/2020/10/15/are-our-brains-bayesian/)  
252. The Predictive Processing Paradigm Has Roots in Kant \- Frontiers, accessed April 21, 2025, [https://www.frontiersin.org/journals/systems-neuroscience/articles/10.3389/fnsys.2016.00079/full](https://www.frontiersin.org/journals/systems-neuroscience/articles/10.3389/fnsys.2016.00079/full)  
253. Predictive coding I: Introduction | Mark Sprevak, accessed April 21, 2025, [https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/](https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/)  
254. Bayesian theories of consciousness: a review in search for a minimal unifying model \- Oxford Academic, accessed April 21, 2025, [https://academic.oup.com/nc/article/2021/2/niab038/6395174](https://academic.oup.com/nc/article/2021/2/niab038/6395174)  
255. Bayesian approaches to brain function \- Wikipedia, accessed April 21, 2025, [https://en.wikipedia.org/wiki/Bayesian\_approaches\_to\_brain\_function](https://en.wikipedia.org/wiki/Bayesian_approaches_to_brain_function)  
256. The Philosophy and Science of Predictive Processing \- Bloomsbury Publishing, accessed April 21, 2025, [https://www.bloomsbury.com/us/philosophy-and-science-of-predictive-processing-9781350099777/](https://www.bloomsbury.com/us/philosophy-and-science-of-predictive-processing-9781350099777/)  
257. (PDF) Breaking Boundaries: the Bayesian Brain Hypothesis for Perception and Prediction, accessed April 21, 2025, [https://www.researchgate.net/publication/369542735\_Breaking\_Boundaries\_the\_Bayesian\_Brain\_Hypothesis\_for\_Perception\_and\_Prediction](https://www.researchgate.net/publication/369542735_Breaking_Boundaries_the_Bayesian_Brain_Hypothesis_for_Perception_and_Prediction)  
258. Breaking boundaries: The Bayesian Brain Hypothesis for perception and prediction, accessed April 21, 2025, [https://pubmed.ncbi.nlm.nih.gov/37058949/](https://pubmed.ncbi.nlm.nih.gov/37058949/)  
259. How to grow a self: development of self-representation in the Bayesian brain \- Frontiers, accessed April 21, 2025, [https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2024.1441931/full](https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2024.1441931/full)  
260. Good Science, Bad Philosophy: Predictive Processing as Reheated Kantianism, accessed April 21, 2025, [https://footnotes2plato.com/2024/10/15/good-science-bad-philosophy-predictive-processing-as-reheated-kantianism/](https://footnotes2plato.com/2024/10/15/good-science-bad-philosophy-predictive-processing-as-reheated-kantianism/)  
261. Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents \- arXiv, accessed April 21, 2025, [https://arxiv.org/html/2407.08516v1](https://arxiv.org/html/2407.08516v1)  
262. The Debate Between AI Symbolism and Connectionism, Explained \- DeepLearning.AI, accessed April 21, 2025, [https://www.deeplearning.ai/the-batch/a-smoldering-conflict-flares/](https://www.deeplearning.ai/the-batch/a-smoldering-conflict-flares/)  
263. A Framework for the Foundation of the Philosophy of Artificial Intelligence \- Digital Commons@Lindenwood University, accessed April 21, 2025, [https://digitalcommons.lindenwood.edu/cgi/viewcontent.cgi?article=1682\&context=faculty-research-papers](https://digitalcommons.lindenwood.edu/cgi/viewcontent.cgi?article=1682&context=faculty-research-papers)  
264. Could AGI and quantum consciousness lead to a metaphysical connection between AI and humanity? A hopeful exploration of the possibilities and an antidote to AI doomerism : r/Futurology \- Reddit, accessed April 21, 2025, [https://www.reddit.com/r/Futurology/comments/1jsbgtn/could\_agi\_and\_quantum\_consciousness\_lead\_to\_a/](https://www.reddit.com/r/Futurology/comments/1jsbgtn/could_agi_and_quantum_consciousness_lead_to_a/)  
265. Ai-Being Cognita, The Unified Essence of Mind and Body: A Mathematical Solution Grounded in the Unmoved Mover \- PhilArchive, accessed April 21, 2025, [https://philarchive.org/rec/COGTUE](https://philarchive.org/rec/COGTUE)  
266. Intelligence Reimagined: AI's Influence on Metaphysics and the Evolution of Consciousness, accessed April 21, 2025, [https://www.researchgate.net/publication/377845837\_Intelligence\_Reimagined\_AI's\_Influence\_on\_Metaphysics\_and\_the\_Evolution\_of\_Consciousness](https://www.researchgate.net/publication/377845837_Intelligence_Reimagined_AI's_Influence_on_Metaphysics_and_the_Evolution_of_Consciousness)  
267. Knowing me, knowing you: theory of mind in AI \- PMC \- PubMed Central, accessed April 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC7253617/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7253617/)  
268. A Philosophical Defense of AI Cognition \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/archive/CAPGWH.pdf](https://philpapers.org/archive/CAPGWH.pdf)  
269. Emma Borg, LLMs, Turing tests and Chinese rooms: the prospects for meaning in large language models \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/rec/BORLTT-2](https://philpapers.org/rec/BORLTT-2)  
270. Understanding Artificial Agency \- PhilPapers, accessed April 21, 2025, [https://philpapers.org/archive/DUNUAA.pdf](https://philpapers.org/archive/DUNUAA.pdf)  
271. The Fragmentation of Belief \- PhilArchive, accessed April 21, 2025, [https://philarchive.org/archive/BENTFO-35](https://philarchive.org/archive/BENTFO-35)  
272. MICROFUNCTIONALISM: CONNECTIONISM AND THE SCIENTIFIC EXPLANATION OF MENTAL STATES\*, accessed April 21, 2025, [http://www.its.caltech.edu/\~squartz/clark.pdf](http://www.its.caltech.edu/~squartz/clark.pdf)