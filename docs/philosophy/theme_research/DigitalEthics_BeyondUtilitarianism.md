# **Digital Ethics Beyond Utility: Virtue, Care, Contractualism, and Pharmacology in Technosocial Worlds**

## **Introduction**

### **The Limits of Utilitarianism in Digital Ethics**

The rapid evolution and pervasive integration of digital technologies into nearly every facet of modern life have generated unprecedented ethical challenges. From the governance of global online platforms to the design of autonomous artificial intelligence (AI) systems and the pursuit of digital justice, existing ethical frameworks are frequently tested. Historically, and often by default, utilitarianism has served as a dominant framework for evaluating technology policy and design choices.1 This approach, broadly defined by its aim to maximize aggregate good or utility for the greatest number, often manifests in cost-benefit analyses, the optimization of quantifiable metrics (such as user engagement, system efficiency, or economic productivity), and a focus on overall consequences.1

However, the complexities of the digital age increasingly reveal the limitations of a purely utilitarian calculus. Several key issues arise. Firstly, the **problem of aggregation** inherent in utilitarianism often struggles to adequately account for the distribution of benefits and harms, potentially justifying outcomes where the significant burdens imposed on individuals or minority groups are outweighed by smaller benefits accrued across a larger population.8 This raises serious concerns in contexts like algorithmic bias or platform policies that might disadvantage specific communities. Secondly, utilitarianism faces **difficulties in quantifying diverse and often incommensurable values** central to digital ethics, such as privacy, autonomy, dignity, fairness, and trust. Reducing these complex human goods to a single metric of 'utility' can lead to their devaluation or neglect.9 Thirdly, the **challenge of predicting long-term consequences** in rapidly evolving, complex socio-technical systems undermines the consequentialist core of utilitarianism. As Shannon Vallor notes, we face an "acute technosocial opacity," making it exceedingly difficult to reliably foresee the full impact of technological innovations.24 Finally, the focus on maximizing overall good can potentially **justify actions involving exploitation or manipulation**, such as invasive data collection practices or addictive design features, if they are perceived to contribute to a larger net benefit.7

### **The Need for Diverse Ethical Frameworks**

These limitations underscore the necessity of moving beyond a singular reliance on utilitarianism and embracing a more diverse ethical toolkit to navigate the digital landscape.1 The multifaceted nature of digital technologies—acting simultaneously as tools, environments, media, and infrastructures—and their profound impact on human relationships, social structures, and individual character demand frameworks capable of addressing a wider range of moral considerations. Non-utilitarian approaches offer alternative lenses, shifting the focus from aggregate consequences to considerations such as moral character, the quality of relationships, duties and rights, the conditions of justifiable agreement, and the inherent ambiguity and transformative power of technology itself.24

### **Overview of Virtue Ethics, Care Ethics, Contractualism, and Pharmacology in the Digital Context**

This report explores four influential non-utilitarian ethical frameworks and their potential contributions to digital ethics.

1. **Shannon Vallor's Technomoral Virtue Ethics:** This approach emphasizes the cultivation of specific character traits (virtues) necessary for human flourishing in technologically mediated environments.30  
2. **María Puig de la Bellacasa's Care Ethics:** Focusing on relationality, maintenance, and interdependence, this framework extends the concept of care to encompass "more than human worlds," including technological systems.33  
3. **T.M. Scanlon's Contractualism:** This deontological theory assesses the rightness or wrongness of actions based on whether they adhere to principles that no one could reasonably reject, emphasizing mutual justification.9  
4. **Bernard Stiegler's Pharmacological Perspective:** This philosophical analysis views technology as a *pharmakon*—inherently both poison and cure—requiring a nuanced understanding of its dual effects on human existence, particularly on memory, attention, and desire.37

### **Report Aims and Structure**

The aim of this report is to conduct a comprehensive, expert-level analysis of these four non-utilitarian frameworks. It will critically assess their applicability to specific digital ethical challenges and synthesize their insights to evaluate how they might collectively provide more robust guidance than utilitarianism alone for pressing contemporary issues such as AI ethics, platform governance, and digital justice.

The report is structured as follows: Sections I through IV will delve into each framework individually, outlining its core concepts, analyzing its relevance and application to digital contexts, and assessing its strengths and limitations. Section V will synthesize these analyses, exploring points of convergence and divergence and applying the combined insights to the specific challenges of AI ethics, platform governance, and digital justice. Finally, the Conclusion will summarize the value of ethical pluralism in the digital age and offer recommendations for future research, policy, and design.

## **I. Cultivating Character Online: Shannon Vallor's Technomoral Virtues**

### **Foundations: Virtue Ethics for a Technological Age**

Shannon Vallor's *Technology and the Virtues* argues compellingly for the revival and adaptation of virtue ethics as a uniquely suitable framework for navigating the moral complexities of the 21st century.24 The contemporary technosocial landscape is characterized by rapid change, increasing complexity, instability, and unpredictability—conditions Vallor terms "acute technosocial opacity".24 This opacity makes it profoundly difficult for ethical theories reliant on rigid rules (like some forms of deontology) or the accurate prediction of consequences (like utilitarianism) to provide effective guidance.8 Virtue ethics, in contrast, developed in classical traditions (Aristotelian, Confucian, Buddhist) precisely to equip individuals with the moral and intellectual character needed to flourish even in such uncertain conditions.8

Vallor's central thesis is that securing a desirable future requires more than just technological advancement; it demands "better humans".30 Achieving this necessitates the deliberate cultivation of *technomoral virtues*: specific strengths of character adapted to the unique challenges and opportunities presented by emerging technologies and contemporary life.30 These virtues are not merely about individual goodness but are essential for collective human flourishing on a global scale.30 Recognizing the global nature of technological impact, Vallor draws upon diverse philosophical traditions—Aristotelian, Confucian, and Buddhist ethics—to construct a "global technomoral virtue ethic".8 While acknowledging the significant differences between these traditions 24, she seeks common ground in their structural understanding of virtue and shared practices of moral self-cultivation, aiming for a framework with broad enough resonance to foster the "robustly cooperative global deliberations" needed to address shared technological challenges.8

### **The Technomoral Virtues: Definitions and Digital Relevance**

Vallor identifies twelve key technomoral virtues as particularly crucial for navigating 21st-century life 24:

1. **Honesty:** An exemplary respect for truth and its appropriate expression in technosocial contexts.47 This becomes critical online amidst misinformation, disinformation, algorithmic filtering, anonymous interactions, and the curated, often performative, nature of social media identities.24 Discerning and communicating truth requires new skills and vigilance.49  
2. **Self-Control:** The ability to choose, and ideally desire, goods and experiences that genuinely contribute to flourishing, resisting harmful impulses or distractions.44 This is acutely challenged by technologies designed for addiction and constant engagement, such as infinite scrolling, notifications, and personalized content streams that exploit cognitive biases.24  
3. **Humility:** Recognizing the limits of our knowledge and abilities, particularly regarding complex technological systems and their impacts; renouncing blind faith in technological mastery.47 This counters techno-solutionism and the hubris often associated with innovation, urging caution in the face of unpredictable consequences and acknowledging the potential for unintended harm, especially relevant in AI development.51  
4. **Justice:** A reliable disposition to seek fair and equitable distribution of technology's benefits and risks, and concern for its impact on rights, dignity, and welfare.47 This directly addresses issues like algorithmic bias perpetuating societal inequalities, the digital divide in access and skills, exploitative data practices, and the fairness of platform labor conditions.24  
5. **Courage:** Intelligent fear and hope regarding the moral and material dangers and opportunities presented by technology.47 This involves facing the genuine risks of technology without succumbing to Luddism, and embracing potential benefits without naive optimism; for example, the courage to speak out against unethical tech practices or to disconnect despite social pressure.24  
6. **Empathy:** A cultivated openness to being morally moved to caring action by the emotions of others in our technosocial world.47 Mediated communication, online anonymity, echo chambers, and the potential dehumanization through interaction with AI can challenge the development and expression of empathy.51  
7. **Care:** A skillful, attentive, responsible, and emotionally responsive disposition to meet the needs of others within our shared technosocial environment.47 This extends beyond interpersonal interaction to the design and maintenance of caring systems, but also raises questions about the appropriateness of delegating care tasks (e.g., elder care) to robots, potentially eroding human capacity for care.24  
8. **Civility:** A sincere disposition to live well with fellow citizens in a globally networked society, engaging in wise deliberation, respectful communication, and collaborative action.47 This virtue is essential for combating online toxicity, polarization, and echo chambers, and for fostering constructive public discourse and democratic engagement in digital spaces.51  
9. **Flexibility:** A reliable and skillful disposition to adapt actions, beliefs, and feelings in response to novel, unpredictable, or unstable technosocial conditions.47 Given the rapid pace of technological change, flexibility is crucial for navigating unforeseen ethical dilemmas and adjusting moral frameworks.24  
10. **Perspective:** The ability to attend to, discern, and understand moral phenomena as meaningful parts of a moral whole.47 This involves seeing beyond immediate impacts or isolated events to grasp the broader systemic effects of technology and maintain moral coherence amidst the fragmentation and information overload of digital life.24  
11. **Magnanimity:** Moral leadership and nobility of spirit; aiming for great and honourable things in the technosocial realm.44 This involves setting high ethical standards in technological development and governance, and inspiring others towards collective flourishing.45  
12. **Technomoral Wisdom:** The master virtue, integrating and applying the other virtues appropriately in complex technosocial situations; practical wisdom adapted for the technological age.24 It represents the overall goal of cultivating technomoral expertise for living well with technology.24

### **Applications: Social Media, Surveillance, AI, and Human Enhancement**

Vallor applies this framework to several key technological domains, illustrating the specific virtues needed and the challenges posed in each 8:

* **New Social Media:** These platforms present challenges to honesty (performative identity, misinformation), self-control (addictive design), empathy (mediated interaction, polarization), and civility (online harassment, echo chambers).51 Cultivating virtues like perspective, honesty, and civility is crucial for navigating these spaces healthily and using them for genuine connection and constructive discourse rather than succumbing to their potentially fragmenting and polarizing effects. Vallor suggests learning from exemplars who successfully integrate social media into a flourishing life.24  
* **Surveillance and Self-Tracking:** Pervasive digital surveillance (by states and corporations) and the 'Quantified Self' movement challenge privacy, autonomy, and the nature of self-knowledge.8 Living virtuously in a 'panoptic' world requires cultivating honesty (resisting performativity driven by being watched), humility (recognizing the limits of self-knowledge through data), justice (ensuring fair use of surveillance data), and perspective (guiding self-tracking by the classical ideal of an examined life, rather than mere optimization).24  
* **Robotics and AI:** The increasing integration of robots (military, social, industrial) and AI systems raises questions about preserving human virtues like care and courage.8 For instance, delegating care for the elderly or children to robots might erode our own capacity for care.24 Using autonomous weapons challenges the virtue of courage and moral responsibility in warfare.32 Ensuring AI systems are developed and deployed justly requires cultivating virtues like justice (addressing bias), humility (recognizing AI limitations), and technomoral wisdom to align AI with human flourishing.51  
* **Human Enhancement Technologies:** Biomedical and genetic enhancements pose profound questions about human nature and flourishing.8 Vallor argues against both uncritical embrace and outright rejection, emphasizing the need for technomoral wisdom to discern what constitutes genuine enhancement aligned with a good life ("knowing what to wish for").24 Virtues like justice (preventing exacerbation of inequality), humility (respecting human limits), and perspective (understanding the long-term implications) are crucial for navigating these powerful technologies responsibly.56

### **Cultivation Strategies: Individual Practices and Systemic Design**

Cultivating technomoral virtues is an active, ongoing process drawing on practices adapted from classical traditions.8 Vallor outlines seven core elements of this practice 8:

1. **Moral Habituation:** Gradually developing virtuous habits through repeated practice, often guided by moral exemplars, moving from difficulty to ease and even pleasure in acting morally.58 *Digital Example:* Consistently practicing respectful disagreement in online forums until it becomes a natural response, rather than an effortful one.58  
2. **Relational Understanding:** Recognizing that ethical decisions occur within specific relationships and roles, requiring attentiveness to context rather than abstract impartiality.8 *Digital Example:* Adjusting communication style and content based on whether one is interacting with a close friend via private message versus a professional contact on a public platform.58  
3. **Reflective Self-Examination:** Regularly assessing one's own actions and motivations against ethical ideals, identifying weaknesses, and tracking progress ("Know thyself").8 *Digital Example:* Reviewing one's daily social media activity to identify instances of impulsive sharing or disrespectful comments, and planning corrective action.58  
4. **Intentional Self-Direction of Moral Development:** Consciously taking responsibility for one's character and sincerely aspiring to live virtuously.58 *Digital Example:* Deciding to prioritize digital privacy as a value and actively configuring settings and choosing platforms accordingly.58  
5. **Perceptual Attention to Moral Salience:** Developing the ability to notice and correctly interpret the morally relevant features of a situation.58 *Digital Example:* Recognizing the potential harm of spreading emotionally charged but unverified news online and pausing to investigate before sharing.58  
6. **Prudential Judgment (Phronesis):** The cultivated ability to deliberate well and choose appropriate means to achieve good ends in particular situations.58 *Digital Example:* Researching the effectiveness and transparency of different online charities before donating, rather than giving impulsively.58  
7. **Appropriate Extension of Moral Concern:** Skillfully extending care and consideration to the right beings, at the right time, to the right degree, and in the right manner, particularly challenging in a globally interconnected world.8 *Digital Example:* Considering the environmental impact of data centers or the labor conditions involved in manufacturing devices when making technology choices.58

These individual practices are supported by moral exemplars who embody the virtues 58, communal reinforcement 8, and enabling institutional and policy structures.41 Importantly, Vallor emphasizes that technology design itself is not neutral; it can either facilitate or hinder virtue cultivation.51 Platforms designed to maximize engagement through addictive loops actively undermine self-control, while systems designed for transparency and user control might support honesty and autonomy. This points towards an implicit critique within Vallor's framework: the dominant design paradigms of many digital technologies, driven by metrics like engagement or efficiency, are often fundamentally at odds with the goal of cultivating virtues for human flourishing.51 Implementing technomoral virtues, therefore, seems to require not only individual effort but also a significant shift in the underlying philosophy and economic incentives guiding technological design.

Furthermore, the methods Vallor proposes for virtue cultivation, such as reflective self-examination and perceptual attention 8, demand time, focus, and critical distance. However, many digital environments, especially social media and algorithmically curated feeds, are characterized by speed, ephemerality, and design choices that fragment attention.51 This creates a significant practical challenge: the very technosocial conditions that necessitate technomoral virtues may simultaneously make their cultivation more difficult. This suggests a need for conscious strategies, perhaps involving "slow tech" practices or deliberate environmental redesigns, to create spaces conducive to moral development amidst the digital torrent.

### **Critical Assessment: Strengths and Limitations**

Vallor's technomoral virtue ethics offers significant strengths: its nuance and context-sensitivity fit well with the complexities of technology; its focus on long-term character development addresses the formative power of technology; its adaptability is suited to rapid innovation; and its grounding in diverse traditions offers potential for global dialogue.24

However, the framework also faces critiques and challenges. One concerns **practicality and scalability**: how can deliberate, effortful virtue cultivation be achieved widely in fast-paced digital environments, especially when platforms may actively discourage it?24 Another concerns **action-guidance**: some critics question whether virtue ethics provides sufficiently clear prescriptions for specific design or policy dilemmas compared to rule-based or consequentialist approaches.46 The ambition for a **"global" ethic** also raises questions about reconciling deep differences between traditions without resorting to superficial commonalities or imposing dominant cultural values.24 The call for global cooperation 24 must contend with the realities of power imbalances in global technology development and governance, raising the risk of ethical frameworks inadvertently reflecting the perspectives of the powerful if not carefully managed through inclusive dialogue and contextual adaptation. Additionally, the **distinctiveness of "technomoral" virtues** is debated: are they fundamentally new, or adaptations of timeless virtues to new contexts?24 Finally, some critiques question whether certain virtues are *particularly* necessary or threatened by *modern* technology compared to previous technological shifts, suggesting technology might sometimes support virtues or simply change the terrain on which they are exercised.50 For example, while digital tools create new temptations challenging self-control, they might also offer new tools for self-monitoring; while online anonymity can hinder honesty, digital records can also make dishonesty easier to expose. This suggests a need for careful, empirically informed analysis of how specific technologies interact with specific virtues in practice.

## **II. Weaving Worlds of Care: María Puig de la Bellacasa's Ethics for Technoscience**

### **"Matters of Care": Beyond Human-Centric Ethics**

María Puig de la Bellacasa's *Matters of Care* offers a profound challenge to conventional ethical frameworks by decentering the human and extending the concept of care to encompass the intricate relationships within "more than human worlds".33 Drawing inspiration from feminist ethics of care, particularly Joan Tronto's foundational definition of care as "everything that we do to maintain, continue and repair 'our world' so that we can live in it as well as possible," Puig de la Bellacasa expands the 'our' and the 'we'.35 Her work argues against the anthropocentric view that care is solely a human activity, advocating instead for recognizing the agencies and interdependencies of non-human entities—animals, plants, soil ecologies, and significantly for this report, technological assemblages—within the living web of care.33

This perspective moves beyond traditional ethical theories often grounded in individual human rationality, abstract rights, social contracts, or universal obligations.34 Instead, it emphasizes relationality, context, and the concrete, often mundane, practices that sustain existence.34 Puig de la Bellacasa develops the notion of "matters of care," building upon Bruno Latour's "matters of concern".35 While Latour sought to reveal the constructed nature of scientific "matters of fact" by showing them as contested "matters of concern" involving networks of human and non-human actors 61, Puig de la Bellacasa infuses this with a more active, involved, and ethically charged dimension.35 "Matters of care" highlights the ethico-political obligation to attend to neglected things, the invisible labor involved in maintenance, and the potential for care to "make things matter" in a political sense.35

### **Speculative Ethics and More-Than-Human Worlds**

Puig de la Bellacasa frames her approach as a "speculative ethics".33 This is not a prescriptive ethical system providing definitive rules or answers, but rather an exploratory mode of thinking that resists normative control and embraces ambiguity.34 It focuses on asking pertinent, detailed questions about how to live well together within complex, interdependent worlds, rather than seeking universal principles.34

This speculative approach is applied to "more than human worlds," a concept acknowledging that our existence is inextricably entangled with non-human entities and technological systems within what Donna Haraway might term "naturecultures" or what Puig de la Bellacasa often refers to as "technoscientific assemblages".33 This perspective recognizes agency beyond the human, viewing technologies not merely as inert tools but as lively participants in socio-technical networks.33 Central to this is an appreciation for the "mundane," the "everyday," the repetitive, and often invisible practices of maintenance, upkeep, repair, and adaptation that are essential for sustaining these complex worlds, whether they involve caring for soil, households, or digital infrastructures.34

### **Implications for Digital Design: Maintenance, Repair, and Relationality**

Applying Puig de la Bellacasa's care ethics radically reframes how we understand and approach the design, development, and maintenance of digital systems.69 Digital technologies are reconceived not merely as products or tools to be used and discarded, but as complex "worlds," "ecologies," or "infrastructures of care" that require ongoing attention, maintenance, and repair to sustain their functionality and the relationships they mediate.69

This perspective brings into focus the crucial, yet often invisible and undervalued, labor involved in keeping digital systems running: software updates, patching vulnerabilities, hardware upkeep, data curation, content moderation, community management, user support, and the disposal or recycling of e-waste.69 Recognizing this labor as a form of care connects digital ethics to feminist critiques that highlight the marginalization of essential but often unpaid or underpaid maintenance and reproductive work.62

Consequently, design principles informed by care ethics would likely shift away from models prioritizing novelty, rapid obsolescence, and closed ecosystems towards emphasizing longevity, durability, repairability, interoperability, adaptability, and graceful degradation.69 This inherently links the ethics of care to environmental sustainability, promoting responsible use and extended lifespans for digital devices and infrastructures.69 This approach fundamentally challenges the economic logic of planned obsolescence and throwaway culture prevalent in the tech industry. It reframes activities like software maintenance, patching, and infrastructure upkeep—often viewed in conventional software development as costly "technical debt" to be minimized or deferred—as essential ethical practices. Neglecting maintenance or designing systems that are difficult or impossible to repair becomes not just an economic or operational issue, but a failure of care, an ethical lapse in the responsibility to sustain the socio-technical world we inhabit.35

Puig de la Bellacasa also explores "touch" as a potent metaphor for knowing and relating with care.34 Touch, unlike vision which can objectify from a distance, implies mutuality and vulnerability—to touch is to be touched.61 This prompts reflection on how digital interfaces and interactions could be designed to foster more reciprocal, attentive, and careful engagement, moving away from purely instrumental or extractive modes of interaction often seen in data collection or user manipulation.81

### **Care Ethics in Digital Communities and Systems**

The framework extends naturally to the nurturing and sustenance of online communities. Instead of focusing solely on metrics like user numbers or engagement time, a care-based approach would prioritize the design of platforms that foster healthy relationships, mutual support, trust, and collective well-being.69 This involves caring for the social fabric of the community, attending to conflicts, supporting newcomers, and maintaining shared norms and values.

The "more-than-human" dimension pushes us to consider our ethical obligations not only to human users but also to the non-human components of digital systems: the algorithms, databases, codebases, servers, networks, and physical infrastructures that make digital life possible.69 What does it mean to "care for" an algorithm or a network? It might involve ensuring its robustness, integrity, security, and efficiency, as exemplified by community network projects like Ninux.org where members actively maintain the physical antennas constituting their shared infrastructure.70 This perspective offers a novel ethical lens for AI governance, suggesting responsibilities extend to the "health" and sustainability of the AI system itself and its entanglement with broader ecological systems, such as the energy consumption of data centers or the sourcing of materials for hardware.69 This moves beyond purely human-centric concerns like bias affecting users, to encompass the well-being of the entire socio-technical-ecological assemblage.

Puig de la Bellacasa's concept of "alterbiopolitics" suggests a political dimension to care ethics in the digital realm, advocating for forms of governance that emphasize collective empowerment, interdependence, and flourishing for all beings (human and non-human) within the digital ecosystem, moving beyond frameworks centered solely on individual rights or market transactions.61 Furthermore, the framework calls attention to the temporal dimension of care.35 The slow, patient, unfolding rhythms often associated with caring practices (like tending soil or raising a child) stand in stark contrast to the accelerated pace of technological innovation, market cycles, and the demand for instantaneous responses in digital culture. Designing for care might involve incorporating mechanisms that respect diverse temporalities, allow for reflection, and resist the pressures of constant acceleration.

### **Challenges and Potentialities**

The strengths of Puig de la Bellacasa's care ethics lie in its ability to illuminate overlooked aspects of technology (maintenance, labor, relationality), its critique of anthropocentrism and purely instrumental views, its inherent connection of ethics to sustainability and politics, and its emphasis on situatedness and context.34

However, its "speculative" nature, while fostering openness, might be perceived as lacking concrete, actionable guidance for immediate design or policy decisions.35 Defining the "needs," "agency," or "flourishing" of non-human entities, especially complex technological systems, remains a significant conceptual challenge. There is also the risk, acknowledged within care ethics literature, that care can become paternalistic, controlling, or oppressive if not critically examined and implemented with attention to power dynamics.33 Finally, navigating situations where the needs of different elements within the more-than-human web conflict (e.g., user convenience vs. environmental impact of servers, community norms vs. algorithmic efficiency) requires further ethical deliberation beyond the framework itself.

The speculative nature of this ethics, however, also offers a potential counter to the drive for standardized, universal ethical "solutions" often sought in AI and platform governance.23 Instead of imposing one-size-fits-all rules, a care-based approach suggests prioritizing the development of situated, adaptive ethical norms through the ongoing, "thick, impure, involvement" 74 of the diverse members (human and potentially non-human) who constitute and maintain a specific digital world. This points towards more participatory, evolving, and context-sensitive governance models, resisting the premature closure often found in overly rigid ethical codes or regulations.

## **III. Justification and Consent in Code: T.M. Scanlon's Contractualism Online**

### **"What We Owe to Each Other": The Principle of Reasonable Rejection**

T.M. Scanlon's contractualism, most fully developed in his seminal work *What We Owe to Each Other*, offers a distinct approach to normative ethics grounded in the idea of mutual justification.10 It focuses specifically on the domain of morality concerning "what we owe to each other"—our duties and obligations in interpersonal interactions.10 The core principle of Scanlonian contractualism states: "An act is wrong if its performance under the circumstances would be disallowed by any set of principles for the general regulation of behaviour that no one could reasonably reject as a basis for informed, unforced, general agreement".9

This framework diverges significantly from utilitarianism, which assesses actions based on their aggregate consequences.11 Contractualism, instead, centers on the justifiability of the principles governing our actions to each individual affected.9 The determination of right and wrong hinges not on maximizing overall good, but on whether a principle could withstand potential rejection by those subject to it.

The concept of "reasonable rejection" is crucial.9 Rejection is deemed "reasonable" not merely based on self-interest, but by comparing the burdens imposed by a given principle on different individuals from their respective standpoints.89 We consider "generic reasons"—reasons that apply to anyone in a similar position—rather than highly specific personal preferences.91 A principle can be reasonably rejected if an alternative principle exists to which no one has an objection that is as strong or stronger.90 This often involves applying the "Greater Burden Principle": it is unreasonable to reject a principle imposing a burden if all alternatives would impose much greater burdens on others.12 This process is distinct from seeking actual agreement (as some individuals might agree to self-sacrificing principles) or hypothetical agreement behind a veil of ignorance (as in Rawls); Scanlon's framework operates with individuals who know their circumstances but are motivated by the desire to find principles acceptable to others.89 The fundamental motivation underpinning this ethical framework is the intrinsic value of living in relationships of mutual recognition and justification with fellow rational beings.10

### **Contractualism vs. Contract: Analyzing Terms of Service and Digital Consent**

Scanlon's contractualism provides a powerful lens for critically evaluating the ethical legitimacy of standard digital consent mechanisms, particularly Terms of Service (ToS) agreements and privacy policies.99 Legally, ToS are often classified as adhesion contracts or "boilerplate" agreements.100 Users typically face a "take it or leave it" scenario, lacking any meaningful power to negotiate terms, which are unilaterally defined and often subject to unilateral change by the platform provider.99 This creates a situation of "contractual authoritarianism".100

From a Scanlonian perspective, such mechanisms frequently fail to meet the standard of principles that cannot be reasonably rejected under conditions of informed, unforced agreement.85 Several factors contribute to this failure:

* **Complexity and Opacity:** ToS are notoriously lengthy, complex, and written in dense legal language, making it difficult for average users to fully understand the terms they are agreeing to.101 This undermines the "informed" condition of the agreement.  
* **Lack of Genuine Choice/Force:** Users often lack realistic alternatives to dominant platforms, making their "agreement" less than fully voluntary or "unforced".44 Rejecting the terms often means exclusion from essential social or economic participation.  
* **Unreasonable Burdens:** ToS frequently impose significant burdens on users, such as extensive data collection and usage permissions, limited liability for the platform, mandatory arbitration clauses, and opaque content moderation processes.99 It is plausible that individuals could reasonably reject principles permitting such terms if a fair process of justification, comparing burdens across alternative possible arrangements, were available.  
* **Unilateral Modification:** The common practice of platforms reserving the right to unilaterally change ToS further undermines the idea of a stable, agreed-upon set of principles.100

The contractualist framework, therefore, suggests that the "consent" obtained through typical ToS click-throughs is often ethically inadequate, lacking the genuine justifiability required for moral legitimacy. This challenges the ethical foundation of many prevalent platform practices related to data processing, content moderation, and user rights, even if these practices are legally permissible under current interpretations of contract law.102 The framework proposed by Elkin-Koren and Gal, viewing platforms as "contractual networks" where ToS establish complex, multi-stakeholder relationships rather than simple dyadic agreements, might offer a way to analyze these broader impacts within a contractualist-inspired lens, considering whether terms advance the shared goals and meet the reasonable expectations of all network members.99

### **Addressing Exploitation and Architecturally Constrained Choices**

Contractualism also offers tools to address ethical concerns surrounding manipulative design practices and data exploitation online. "Choice architecture" refers to the way options are presented, which can significantly influence decisions, often without conscious awareness.104 This includes techniques like nudging (subtly guiding choices) and dark patterns (deceptive interfaces designed to trick users).104

Principles that permit the use of manipulative choice architecture could likely be reasonably rejected under Scanlon's framework.108 Such practices arguably fail to treat users with the respect owed to them as rational agents capable of assessing reasons and making autonomous choices.85 By exploiting cognitive biases or deliberately obscuring information, manipulative designs undermine the conditions for informed, unforced agreement and prevent users from acting according to reasons they could endorse.106 This suggests an ethical imperative, derived from contractualism, for digital environments to be designed with transparency, minimizing manipulative nudges and empowering users to make genuinely informed decisions, even if this conflicts with platform goals like maximizing engagement or conversion rates.104

Similarly, contractualism provides a basis for condemning data exploitation, particularly the leveraging of user vulnerabilities (e.g., mental health status, addiction, age) inferred from data to maximize engagement or profit.114 Could principles permitting a platform to target depressed individuals with content known to deepen their depression, solely to increase engagement metrics, be justified to those individuals on grounds they could not reasonably reject? It seems highly unlikely.20 The severe burden imposed on the vulnerable individual would likely constitute grounds for reasonable rejection, especially when compared to alternative principles prioritizing user well-being or prohibiting such targeted exploitation. Contractualism's focus on justification to each individual highlights the ethical wrongness of practices that instrumentalize vulnerabilities, even if such practices might yield aggregate benefits (e.g., increased platform revenue).

### **Applications in Algorithmic Fairness and Data Ethics**

The "reasonable rejection" standard holds promise for informing debates in algorithmic fairness and data ethics, moving beyond purely utilitarian or technical considerations.91

* **Algorithmic Fairness:** Instead of solely relying on statistical parity metrics (which can sometimes conflict 115), contractualism asks whether the principles governing an algorithm's deployment could be reasonably rejected by those individuals or groups most burdened by its outcomes (e.g., due to bias or disparate impact).97 If a group facing systematic disadvantage due to an algorithm's decisions could point to alternative principles (e.g., using a less biased model, incorporating human review, adjusting decision thresholds, not using the algorithm for that purpose) that would impose lesser burdens on anyone else, then the current principle might be reasonably rejectable.12 This approach centers the perspectives of those potentially harmed and focuses on the justifiability of the system's governing rules.  
* **Data Ethics:** Contractualism provides a framework for evaluating data governance policies.20 Data collection, processing, sharing, and retention practices must be justifiable based on principles that affected individuals could not reasonably reject. This requires transparency about data practices and a careful assessment of the burdens imposed (e.g., privacy loss, potential for misuse, chilling effects) compared to the benefits and the burdens under alternative policies. It offers a moral grounding for data privacy and consent requirements that goes beyond mere legal compliance or calculations of aggregate utility.  
* **AI Decision-Making:** The emphasis on justification aligns with calls for transparency and explainability in AI systems.97 Opaque or inscrutable algorithmic decisions affecting individuals' lives (e.g., in hiring, credit, healthcare) may be difficult to justify to those affected, potentially rendering the principles permitting such opacity reasonably rejectable.

### **Applicability and Critiques in the Digital Sphere**

Scanlon's contractualism offers significant strengths for digital ethics: it provides a robust foundation for individual rights and fairness claims that resist being overridden by aggregate utility; it centers the ethical importance of justification, respect, and mutual recognition; and its focus on principles makes it potentially applicable to evaluating rules, policies, and system designs.9

However, applying contractualism in the digital sphere also presents challenges and invites critiques:

* **The Aggregation Problem:** While designed to avoid utilitarian aggregation, contractualism faces its own challenges in dealing with situations involving harms to different numbers of people. How should we weigh a severe burden on one person against lesser burdens on many (e.g., the World Cup transmitter case 11)? Debates persist on whether and how numbers should count within the framework.11 This becomes particularly complex when considering platform policies or algorithmic impacts affecting millions or billions of users.  
* **Indeterminacy of "Reasonable Rejection":** What constitutes a "reasonable" rejection can be ambiguous and highly contested, especially across diverse global user bases with differing values and sensitivities.86 Reaching consensus on which burdens are comparable or which rejections are truly reasonable can be difficult in practice.  
* **Scope Limitations:** Scanlon's theory primarily concerns duties between beings capable of understanding and responding to reasons and justifications (typically rational agents).85 This raises questions about its applicability to duties concerning non-human animals, the environment, or potentially future AI entities that may lack such capacities.28 While extensions like trustee accounts have been proposed 129, the core focus remains on inter-rational agent morality.  
* **Demandingness:** The requirement to consider principles justifiable to *everyone* affected might be overly demanding or computationally intractable in the context of complex, large-scale digital systems with vast numbers of users and unpredictable emergent effects.125  
* **Idealization vs. Reality:** The framework relies on an idealized notion of informed, unforced agreement and mutual motivation to find justifiable principles.85 This ideal contrasts sharply with the realities of the digital world, characterized by significant power asymmetries, information manipulation, coercive conditions (lack of alternatives), and profit motives that often overshadow ethical considerations.99 Bridging this gap remains a critical challenge.

## **IV. The Digital Pharmakon: Bernard Stiegler's Philosophy of Technology**

### **Technology as Poison and Cure: The Pharmakon Explained**

Bernard Stiegler's philosophy offers a unique and critical lens for understanding technology, centered on his adoption and radical extension of the ancient Greek concept of the *pharmakon*.37 Drawing initially from Jacques Derrida's analysis of writing in Plato's *Phaedrus* 37, Stiegler applies the term—which signifies simultaneously poison, cure, remedy, drug, and scapegoat—to *technics* (the broader category encompassing tools, techniques, and technologies) in general.

The core insight is that technology is inherently ambivalent, never neutral.37 Every technical object or system possesses the potential to be both beneficial and detrimental, curative and toxic, enabling and disabling.38 Its specific effects are not predetermined but emerge from its interaction with human individuals and societies within particular historical and socio-economic contexts. Ethical evaluation, therefore, requires a "pharmacological" approach: a careful analysis and critical assessment of both the poisonous and curative potentials of any given technology.37

This pharmacological view is deeply intertwined with Stiegler's foundational argument concerning "originary technicity".38 He posits that the human and the technical are co-constitutive and co-emergent; there is no "human nature" preceding technics.37 Technics, understood as organized inorganic matter (tools, artifacts, writing systems, digital networks), function as forms of "exteriorized memory" or "tertiary retention".38 These external memory supports are not merely aids to internal (primary and secondary) retention but are fundamentally constitutive of human consciousness, experience, knowledge, culture, and temporality itself.37 The human evolves *through* its technics; technology is our defining quality, akin to the fire Prometheus gave humanity.38

### **Digital Technologies through a Pharmacological Lens (AI, Social Media, Automation)**

Stiegler's pharmacological perspective provides a powerful framework for analyzing the dual potentials of contemporary digital technologies:

* **Social Media:** These platforms act as potent pharmaka. The *cure* lies in their potential for connection, community building, rapid information dissemination, and facilitating social movements.38 The *poison*, however, manifests as addiction, the erosion of attention spans ("hyper attention" replacing deep attention), the spread of misinformation and polarization, the commodification of social relationships, the pressure towards performativity, and the potential for increased anxiety and mental health issues.38  
* **AI and Algorithms:** AI offers cures through efficiency gains, pattern recognition capabilities, automation of complex tasks, and potential solutions to scientific and social problems.137 The poison includes the risks of embedded bias leading to discrimination, the opacity of decision-making processes ("black boxes"), the potential for widespread deskilling and loss of human judgment, new forms of social control and surveillance, and potentially even existential risks associated with superintelligence.139  
* **Automation:** Automation promises the cure of liberation from tedious or dangerous labor and increased productivity.156 Its poisonous potential lies in mass unemployment, the exacerbation of economic inequality, the deskilling of the workforce (proletarianization), and the disruption of the established relationship between work, income, and social participation.156  
* **Digital Memory (Tertiary Retention):** The vast digital archives and networked information systems offer the cure of unprecedented access to knowledge and cultural heritage, facilitating learning and collective memory.38 The poison lies in the potential atrophy of internal memory capacities, dependence on fragile external systems, the possibility of manipulation or erasure of digital records, and the control exerted by those who manage these memory infrastructures.38 The way these digital memory systems function—collecting data, training algorithms, shaping feeds—doesn't just record the past but actively constitutes present experience and orients future possibilities, making control over them a fundamental ethical and political issue.140

### **Beyond Cost-Benefit: Nuanced Ethical Evaluation**

The pharmacological perspective inherently critiques simplistic utilitarian or cost-benefit analyses of technology.40 Such approaches often focus narrowly on quantifiable outcomes and short-term gains, failing to grasp the deeper, qualitative transformations that technologies induce in human existence, consciousness, and social organization.37 Stiegler insists on analyzing the *specific dynamics* through which a technology operates as *both* poison and cure simultaneously within its context.37 The focus shifts from a simple calculation of net good/bad to understanding the complex, often paradoxical, ways technology reshapes fundamental aspects of being human, such as individuation, knowledge, desire, and care, over the long term.38

### **Impacts on Attention, Desire, Proletarianization, and Individuation**

Stiegler's later work increasingly focused on the ways consumer capitalism, particularly through digital media and marketing technologies (mnemotechnics and psychotechnics), systematically captures and channels human attention and desire (libidinal energy) towards consumption.37 This relentless demand on attention leads to its fragmentation and destruction, fostering "hyper attention" at the expense of deep, sustained focus necessary for critical thought, learning, and care.38 This process, he argues, results in a "crisis of spirit" and widespread "symbolic misery".40

This connects to his concept of "generalized proletarianization".38 Extending Marx, Stiegler argues that contemporary technocapitalism leads to the loss not only of *savoir-faire* (practical skills, know-how) through automation, but also of *savoir-vivre* (existential knowledge, how to live well) and *savoir conceptualiser* (theoretical knowledge, critical thinking).135 As individuals delegate cognitive and existential functions to automated systems and become passive consumers of standardized culture, their capacity for autonomous thought and action diminishes. This affects not just industrial workers but potentially everyone integrated into the consumerist system, leading to what he terms "organized immaturity".144

This process fundamentally impacts "individuation," a concept Stiegler borrows and adapts from Gilbert Simondon, referring to the ongoing process through which individuals and collectives constitute themselves and develop unique identities.37 Technology, as a pharmakon, can either foster "long circuits" of individuation—promoting learning, critical reflection, and the development of unique knowledge and desire—or impose "short circuits" that lead to standardization, homogenization, and the loss of singularity ("disindividuation") through control and manipulation.38 The ethical challenge, therefore, extends beyond immediate harms to encompass the long-term effects of technology on our capacity for meaningful existence and self-creation. This suggests that the ethical problems posed by AI and automation are not limited to job displacement but include a deeper erosion of human knowledge and critical capacity, demanding responses focused on education, care, and fostering meaningful individuation, rather than solely economic adjustments.144

### **Towards a Therapeutic Use of Technology**

Crucially, Stiegler's pharmacology is not merely diagnostic but also prescriptive.37 Recognizing the inherent ambivalence of the pharmakon means acknowledging that the cure lies within the poison itself ("where the danger lies, also grows the saving power" 146). The task is to actively cultivate the therapeutic potential of technologies while mitigating their toxic effects.39

This requires practices of care, critical attention, education, and fostering alternative forms of desire and social organization.37 Stiegler emphasizes the role of art and aesthetics in disrupting dominant narratives, fostering critical reflection, and imagining alternative futures.37 He also advocated for new socio-economic models, such as a "contributory economy," where technology is leveraged to support collective knowledge creation, skill development (reversing proletarianization), and local community well-being, rather than being solely driven by consumerism and short-term profit maximization.137

The pharmacological perspective thus reframes ethical engagement with technology. It moves away from seeking definitive judgments of "good" or "bad" technology, or aiming for a static state of "ethical technology." Instead, it posits ethics as an ongoing, dynamic process of pharmacological practice: continually diagnosing the specific poisons and cures embedded within our technics, and actively working, through care, critique, education, and political action, to cultivate their therapeutic potential and mitigate their toxicity in the pursuit of a life worth living.38

## **V. Synthesis: Integrating Non-Utilitarian Frameworks for Digital Challenges**

### **Convergence and Divergence: Weaving the Frameworks Together**

The exploration of virtue ethics (Vallor), care ethics (Puig de la Bellacasa), contractualism (Scanlon), and pharmacology (Stiegler) reveals a shared dissatisfaction with the limitations of purely utilitarian or instrumental approaches to digital ethics. Each framework, in its own way, seeks to address dimensions of moral life often neglected by calculations of aggregate consequences: the importance of individual character and flourishing (Vallor), the significance of relationships, maintenance, and interdependence (Puig de la Bellacasa), the centrality of mutual respect and justification (Scanlon), and the profound, ambivalent ways technology shapes human existence itself (Stiegler).

Despite their different starting points and conceptual vocabularies, potential synergies emerge. Vallor's emphasis on virtues like Care, Empathy, and Justice 24 resonates deeply with Puig de la Bellacasa's focus on relationality, attentiveness to needs, and the ongoing work of maintenance.33 Cultivating these virtues could be seen as essential for enacting the practices of care that Puig de la Bellacasa advocates in digital design and community building. Similarly, Scanlon's requirement for principles to be justifiable based on reasons others cannot reasonably reject 36 aligns with the need for Perspective and Wisdom in Vallor's framework 24 and the attentive consideration demanded by care ethics.34 A process of justification, to be truly meaningful, might need to embody virtues like honesty and civility, and be conducted with care for the relationships involved.

Stiegler's pharmacological lens provides a crucial contextual layer for the other frameworks. It helps explain the socio-technical *conditions* under which the cultivation of virtues might be supported or undermined (e.g., attention economies hindering self-control 135), how practices of care might be devalued or instrumentalized by dominant economic logics 79, and how the very possibility of meaningful justification can be compromised by manipulative technologies or the erosion of critical thinking ("proletarianization" 135).

However, tensions also exist. The emphasis on specific virtues or care practices might seem vague or difficult to operationalize compared to the more procedural focus of contractualism.35 Stiegler's often critical, even apocalyptic, tone regarding the trajectory of technocapitalism might clash with the more constructive, hopeful ambitions underlying Vallor's virtue cultivation or Puig de la Bellacasa's nurturing of caring relations. Integrating these frameworks requires navigating these differences, recognizing that each offers a valuable but partial perspective on the complex ethical landscape of the digital age.

### **Rethinking AI Ethics: Addressing Bias, Accountability, and Agency**

Applying these non-utilitarian frameworks enriches the discourse on AI ethics beyond optimizing outcomes or ensuring procedural fairness alone.1

* **Bias:** Addressing algorithmic bias requires more than technical debiasing or measuring disparate impact. Virtue ethics calls for cultivating justice and fairness as character traits in AI designers and deployers.2 Care ethics demands attentiveness to the specific ways bias harms marginalized groups and calls for care in data collection and curation processes.68 Contractualism asks if the principles permitting potentially biased systems can be justified to those disproportionately burdened, forcing a comparison with less burdensome alternatives.97 Pharmacology reveals bias not just as a technical flaw but as a potential 'poison' reflecting and amplifying existing societal inequalities embedded within data and technical systems.139  
* **Accountability:** Moving beyond purely technical traceability or legal liability, virtue ethics emphasizes the moral responsibility stemming from the character of the actors involved.2 Care ethics highlights relational accountability within the network of humans and systems involved in AI development and deployment.69 Contractualism grounds accountability in the requirement to justify AI decisions and their governing principles to those affected.97 Pharmacology points to the systemic nature of effects, cautioning against simplistic attributions of responsibility and highlighting the limits of individual control within complex technological assemblages.139  
* **Agency:** Protecting human autonomy against AI encroachment involves cultivating virtues like self-control and wisdom to navigate AI influences (Vallor) 47, designing AI systems with care to empower rather than diminish users (Puig de la Bellacasa) 62, ensuring AI systems operate under principles that respect rational agency and are reasonably endorsable (Scanlon) 97, and critically resisting the "proletarianizing" effects of AI that deskill users and undermine their capacity for autonomous thought and action (Stiegler).135

### **Reforming Platform Governance: Content Moderation, User Rights, and Power**

These frameworks offer critical perspectives on the governance of online platforms, challenging models based solely on maximizing engagement, minimizing harm defined narrowly, or enforcing opaque rules.22

* **Content Moderation:** This complex task can be viewed not just as rule enforcement or harm reduction, but as a practice requiring virtues like civility, perspective, and justice (Vallor) 51; as an act of care aimed at maintaining the health and integrity of the community (Puig de la Bellacasa) 69; as needing policies and procedures justifiable to users based on principles they could not reasonably reject (Scanlon) 94; and as operating within a pharmacological context where platforms function as attention economies that shape public discourse, potentially toxically (Stiegler).38 Integrating these perspectives highlights inherent tensions, for instance, between promoting civility and allowing robust (even offensive) expression that might be deemed non-rejectable, or between nurturing a caring community and avoiding the manipulative engagement techniques Stiegler critiques. Ethical governance must therefore involve navigating these complex trade-offs.  
* **User Rights:** Rights related to privacy, expression, and due process can be grounded not only in abstract principles or utility but also in the requirements of virtue (justice demands respecting dignity 47), care (attending to users' relational needs and vulnerabilities 69), contractualism (terms and conditions must be justifiable and non-rejectable 99), and pharmacology (protecting users from exploitation and control inherent in the platform's technical architecture 140).1  
* **Power Dynamics:** The significant power imbalance between large platforms and individual users is illuminated by these frameworks. Virtue ethics might critique the lack of humility or magnanimity shown by powerful platforms.47 Care ethics emphasizes the dependencies created by platforms and the responsibilities that arise from them.69 Contractualism highlights the failure of genuine, unforced agreement in the face of platform dominance.100 Pharmacology exposes the mechanisms through which platforms exert control by shaping attention and desire via their technical infrastructure.38

### **Envisioning Digital Justice: Access, Equity, and Data Sovereignty**

These non-utilitarian approaches provide richer ways to conceptualize and pursue digital justice, moving beyond simple metrics of access or distribution.6

* **Access and Equity:** Digital divides and algorithmic discrimination are framed not just as inefficiencies or losses of potential utility, but as failures of justice (Vallor) 47, failures of care to attend to the needs of the marginalized (Puig de la Bellacasa) 62, consequences of operating under principles or background conditions that are reasonably rejectable by the disadvantaged (Scanlon) 19, and as systemic outcomes of a technocapitalist system that inherently produces inequality and proletarianization (Stiegler).3731  
* **Data Sovereignty/Ownership:** Debates about data control can be enriched by considering the virtues of justice and honesty in data practices (Vallor) 47, the need for caring, relational approaches to data governance that respect interdependencies (Puig de la Bellacasa) 69, the requirement that data collection and use principles be justifiable to data subjects (Scanlon) 20, and the understanding of data as a form of tertiary retention, control over which shapes consciousness and power (Stiegler).14216

Achieving digital justice, when viewed through this combined lens, appears to require a multi-level strategy. It necessitates cultivating virtuous dispositions in individuals and institutions (Vallor), implementing attentive and sustainable maintenance practices within socio-technical systems (Puig de la Bellacasa), establishing fair procedures and principles grounded in mutual justification (Scanlon), and undertaking a systemic critique and potential transformation of the underlying technological and economic structures that generate injustice (Stiegler). Focusing solely on one level, such as perfecting algorithmic fairness rules without addressing the broader context or the character of those involved, is likely insufficient.

### **Comparative Analysis: Strengths of a Multi-Framework Approach vs. Utilitarianism**

The synthesis of virtue ethics, care ethics, contractualism, and pharmacology offers a significantly more robust and nuanced approach to digital ethics than utilitarianism alone.1 These non-utilitarian frameworks collectively bring into focus critical dimensions often obscured by a purely consequentialist calculus: the importance of moral character and intention; the value of relationships, interdependence, and care; the demands of justice, fairness, and respect for individual dignity grounded in mutual justification; the significance of power dynamics; and the deep, transformative, and inherently ambivalent nature of technology itself. They allow for a richer understanding of harms and benefits, including symbolic, relational, and existential impacts that resist easy quantification.

While utilitarianism often pushes towards optimization of predefined metrics, these diverse frameworks converge, despite their differences, on a broader vision. Ethical technology, from this integrated perspective, is less about maximizing a particular outcome and more about fostering environments, practices, and socio-technical systems that support human (and potentially more-than-human) flourishing, enable relationships of care and mutual respect, operate according to justifiable principles, and encourage critical awareness of technology's pervasive and ambivalent power.

The primary challenge lies in integrating these diverse perspectives into coherent and actionable guidance. As noted, tensions can arise between the demands of different frameworks (e.g., civility vs. rejectability, community care vs. critique of engagement). Ethical decision-making in complex digital contexts will often involve navigating these tensions and making difficult trade-offs, rather than applying a single algorithm. The value of this multi-framework approach lies not in providing easy answers, but in equipping designers, policymakers, and users with a richer conceptual toolkit for deliberation, critique, and the pursuit of more just and humane technosocial futures.

**Table 1: Comparative Analysis of Non-Utilitarian Frameworks in Digital Ethics**

| Feature | Virtue Ethics (Vallor) | Care Ethics (Puig de la Bellacasa) | Contractualism (Scanlon) | Pharmacology (Stiegler) |
| :---- | :---- | :---- | :---- | :---- |
| **Core Principle** | Cultivation of technomoral character for flourishing | Maintaining/repairing relational webs (human & non-human) | Justifiability based on principles no one could reasonably reject | Understanding & navigating technology as poison & cure (pharmakon) |
| **Primary Focus** | Agent's character, habits, wisdom | Relationships, interdependence, maintenance, context, neglected things | Principles, justification, mutual recognition, individual burdens | Technology's constitutive role, ambivalence, systemic effects |
| **AI Bias** | Cultivate justice/fairness in designers; virtuous AI design | Attend to specific harms on marginalized; care for data/systems | Are biased systems/principles reasonably rejectable by burdened? | Bias as poison reflecting/amplifying societal inequalities |
| **AI Accountability** | Moral responsibility of virtuous agents | Relational accountability within the socio-technical network | Justification required for AI decisions & principles | Systemic effects limit simple attribution; critique of control |
| **AI & Agency** | Cultivate self-control, wisdom vs. AI influence | Design for empowerment & co-existence with AI | AI principles must respect rational agency & be endorsable | Resist AI's "proletarianizing" effects on knowledge & autonomy |
| **Platform Mod.** | Foster civility, perspective; moderate virtuously | Maintain community health; care for users & moderators | Are moderation policies reasonably rejectable? | Critique attention economy; moderation as pharmacological act |
| **Platform User Rights** | Grounded in justice, dignity | Grounded in relational needs & vulnerabilities | Grounded in non-rejectable terms & justification | Grounded in resisting exploitation & control |
| **Digital Justice (Access/Equity)** | Failure of justice virtue | Neglect of needs; failure to care for marginalized | Unfair background conditions; rejectable principles | Systemic production of inequality; proletarianization |
| **Digital Justice (Data Sov.)** | Justice/honesty in data practices | Relational data governance; care for data ecologies | Justifiable data principles; non-rejectable use | Data as tertiary retention; control shapes consciousness |
| **Key Strengths** | Nuance, context, character focus, adaptability | Highlights maintenance, relationality, non-human, sustainability | Strong basis for rights/fairness, emphasizes justification | Deep critique of tech's role, reveals ambivalence, systemic view |
| **Key Weaknesses/ Challenges** | Action-guidance vagueness? Scalability? Global unity? | Speculative nature lacks concrete rules? Defining non-human needs? | Aggregation issues? Defining "reasonable"? Scope limits? Demanding? | Can seem overly critical/pessimistic? Less direct action guidance? |

## **VI. Conclusion**

### **Recap: The Value of Ethical Pluralism in the Digital Age**

The analysis undertaken in this report underscores the significant limitations of relying solely on utilitarian frameworks to address the complex ethical challenges posed by digital technologies. While considerations of consequences and overall welfare remain relevant, the inherent difficulties in aggregation, quantification of diverse values, prediction under conditions of opacity, and the potential to justify exploitation necessitate a broader ethical perspective. The exploration of Shannon Vallor's technomoral virtue ethics, María Puig de la Bellacasa's care ethics for technoscience, T.M. Scanlon's contractualism, and Bernard Stiegler's pharmacological philosophy reveals the distinct and valuable contributions that non-utilitarian approaches can make.

### **Key Insights from Virtue, Care, Contractualism, and Pharmacology**

These diverse frameworks collectively shift the focus of digital ethics towards crucial dimensions often marginalized by utility calculations.

* **Virtue ethics** emphasizes the indispensable role of *character* in navigating technological complexity and uncertainty, calling for the cultivation of specific technomoral virtues like justice, humility, and wisdom for individual and collective flourishing.24  
* **Care ethics** highlights the importance of *relationships, interdependence, and the ongoing work of maintenance* in sustaining our increasingly entangled human, non-human, and technological worlds, urging attention to neglected practices and entities.33  
* **Contractualism** provides a robust standard for *fairness and rights* grounded in mutual respect and justification, demanding that the principles governing our digital interactions and systems be defensible to each person affected on grounds they could not reasonably reject.9  
* **Pharmacology** offers a critical lens on the *inherent ambivalence and constitutive power* of technology itself, revealing how digital tools act as pharmaka—simultaneously poison and cure—that profoundly shape memory, attention, desire, and the very fabric of human existence.37

Together, these perspectives foster a more context-sensitive, relationally aware, character-focused, justification-oriented, and critically conscious approach to digital ethics. They move the conversation beyond optimizing metrics towards considering the qualitative impacts of technology on human life, social structures, and potentially, the broader ecological web.

### **Recommendations for Future Research, Policy, and Design**

The insights gleaned from these non-utilitarian frameworks suggest several avenues for future work:

* **Future Research:** Further philosophical work is needed to explore methods for integrating these diverse frameworks more systematically, addressing their internal tensions and developing hybrid approaches. Applying these frameworks to emerging technologies beyond the current scope (e.g., neurotechnology, synthetic biology, advanced robotics, quantum computing) will be crucial. Empirical research investigating how these ethical considerations manifest in practice among designers, users, and policymakers is also needed.  
* **Policy Considerations:** Policymakers should consider regulations informed by these broader ethical concerns. Examples include:  
  * *Promoting Sustainability and Care:* Policies encouraging repairability, interoperability, and longevity in digital devices, potentially through 'right to repair' legislation or eco-design standards.69 Support for open infrastructures and community-managed networks.70  
  * *Ensuring Justifiable Consent:* Moving beyond ineffective ToS towards standards for genuinely informed and unforced consent for data practices, possibly incorporating contractualist principles of reasonable rejectability.99  
  * *Fostering Digital Citizenship:* Investing in educational initiatives aimed at cultivating technomoral virtues, critical thinking skills, and awareness of technology's pharmacological effects.155  
  * *Addressing Systemic Harms:* Developing policies that address the negative externalities of the attention economy, algorithmic bias beyond simple non-discrimination, and the "proletarianizing" effects of automation.140  
* **Design Principles:** Designers and engineers can draw inspiration from these frameworks to create more ethically robust technologies:  
  * *Design for Virtue:* Intentionally designing interfaces and systems that encourage virtues like self-control, reflection, honesty, and civility, rather than undermining them.51  
  * *Design for Care:* Prioritizing maintenance, repairability, longevity, and user support; designing platforms that foster healthy relationships and community well-being.69  
  * *Design for Justification:* Emphasizing transparency, explainability, and user control, ensuring that system operations and policies are understandable and defensible to users.97  
  * *Design for Critical Awareness:* Creating tools and interfaces that help users understand the pharmacological effects of technology, manage their attention, and resist manipulation.144

### **Final Thoughts: Towards Wiser and More Just Technosocial Futures**

Navigating the ethical terrain of the digital age requires more than optimizing for efficiency or aggregate benefit. It demands wisdom, care, justice, and a critical understanding of the tools that increasingly shape our lives. By engaging with diverse ethical frameworks—including virtue ethics, care ethics, contractualism, and the pharmacological perspective—we can cultivate a richer, more nuanced, and ultimately more responsible approach to technology. The goal is not simply to avoid harm, but to actively shape our technosocial future in ways that promote genuine human (and more-than-human) flourishing, foster relationships of mutual respect and care, and ensure that our powerful tools serve life-affirming ends.30 This requires ongoing, inclusive, and ethically pluralistic deliberation involving designers, policymakers, users, and citizens alike.

#### **Works cited**

1. Ethical Responsibility in the Design of Artificial Intelligence (AI) Systems \- JMU Scholarly Commons, accessed April 20, 2025, [https://commons.lib.jmu.edu/cgi/viewcontent.cgi?article=1114\&context=ijr](https://commons.lib.jmu.edu/cgi/viewcontent.cgi?article=1114&context=ijr)  
2. Navigating AI Ethics: Integrating Philosophical Foundations for a Just Technological Future, accessed April 20, 2025, [https://www.thothica.com/sample-research/navigating-ai-ethics-integrating-philosophical-foundations-for-a-just-technological-future](https://www.thothica.com/sample-research/navigating-ai-ethics-integrating-philosophical-foundations-for-a-just-technological-future)  
3. Ethical decision-making in IT governance: A review of models and frameworks \- International Journal of Science and Research Archive, accessed April 20, 2025, [https://ijsra.net/sites/default/files/IJSRA-2024-0373.pdf](https://ijsra.net/sites/default/files/IJSRA-2024-0373.pdf)  
4. Ethical Theory and Technology \- PhilArchive, accessed April 20, 2025, [https://philarchive.org/archive/TSOETA](https://philarchive.org/archive/TSOETA)  
5. Utilitarianism, deontology, and virtue ethics in AI context | AI Ethics Class Notes \- Fiveable, accessed April 20, 2025, [https://library.fiveable.me/artificial-intelligence-and-ethics/unit-2/utilitarianism-deontology-virtue-ethics-ai-context/study-guide/uk9lJyQbhFMjCYkC](https://library.fiveable.me/artificial-intelligence-and-ethics/unit-2/utilitarianism-deontology-virtue-ethics-ai-context/study-guide/uk9lJyQbhFMjCYkC)  
6. Towards A Unified Utilitarian Ethics Framework for Healthcare Artificial Intelligence, accessed April 20, 2025, [https://montrealethics.ai/towards-a-unified-utilitarian-ethics-framework-for-healthcare-artificial-intelligence/](https://montrealethics.ai/towards-a-unified-utilitarian-ethics-framework-for-healthcare-artificial-intelligence/)  
7. Learning Analytics and Ethics: A Framework beyond Utilitarianism \- EDUCAUSE Review, accessed April 20, 2025, [https://er.educause.edu/articles/2014/8/learning-analytics-and-ethics-a-framework-beyond-utilitarianism](https://er.educause.edu/articles/2014/8/learning-analytics-and-ethics-a-framework-beyond-utilitarianism)  
8. Cultivating Technomoral Interrelations: A Review of Shannon Vallor's Technology and the Virtues Damien Williams, Virginia Tec, accessed April 20, 2025, [https://social-epistemology.com/wp-content/uploads/2018/02/2018-02-22-williams-technology-virtue.pdf](https://social-epistemology.com/wp-content/uploads/2018/02/2018-02-22-williams-technology-virtue.pdf)  
9. S. Matthew Liao, What we owe to each other by T. M. Scanlon \- PhilPapers, accessed April 20, 2025, [https://philpapers.org/rec/LIAWWO](https://philpapers.org/rec/LIAWWO)  
10. Rightness as Justifiability: Thomas Scanlon's moral contractualism | Politika, accessed April 20, 2025, [https://www.politika.io/en/notice/rightness-as-justifiability-thomas-scanlons-moral-contractualism](https://www.politika.io/en/notice/rightness-as-justifiability-thomas-scanlons-moral-contractualism)  
11. What We Owe to Many \- PhilArchive, accessed April 20, 2025, [https://philarchive.org/archive/SUIWWO](https://philarchive.org/archive/SUIWWO)  
12. Contractualism and Social Risk, accessed April 20, 2025, [https://oar.princeton.edu/bitstream/88435/pr1qn5z988/1/ContractualismSocialRisk.pdf](https://oar.princeton.edu/bitstream/88435/pr1qn5z988/1/ContractualismSocialRisk.pdf)  
13. 2, accessed April 20, 2025, [https://faculty.philosophy.umd.edu/pcarruthers/AI-2.htm](https://faculty.philosophy.umd.edu/pcarruthers/AI-2.htm)  
14. sen williams (eds) 1982 utilitarianism and beyond, accessed April 20, 2025, [https://www.utilitarianism.com/beyond.pdf](https://www.utilitarianism.com/beyond.pdf)  
15. Three Different Currents of Thought to Conceive Justice: Legal, and Medical Ethics Reflections \- MDPI, accessed April 20, 2025, [https://www.mdpi.com/2409-9287/9/3/61](https://www.mdpi.com/2409-9287/9/3/61)  
16. Foundational Ethics: 5 Core Principles for Ethical Decision-Making in 2024 \- Infonetica, accessed April 20, 2025, [https://www.infonetica.net/articles/foundational-ethics](https://www.infonetica.net/articles/foundational-ethics)  
17. Ethical theories and frameworks | Digital Ethics and Privacy in Business Class Notes, accessed April 20, 2025, [https://library.fiveable.me/digital-ethics-and-privacy-in-business/unit-1/ethical-theories-frameworks/study-guide/OUcb7oaxvypgwpnc](https://library.fiveable.me/digital-ethics-and-privacy-in-business/unit-1/ethical-theories-frameworks/study-guide/OUcb7oaxvypgwpnc)  
18. 10\. A Framework for Making Ethical Decisions \- Maricopa Open Digital Press, accessed April 20, 2025, [https://open.maricopa.edu/societyandbusiness/chapter/a-framework-for-making-ethical-decisions/](https://open.maricopa.edu/societyandbusiness/chapter/a-framework-for-making-ethical-decisions/)  
19. What We Owe Each Other \- Boston Review, accessed April 20, 2025, [https://www.bostonreview.net/articles/martin-oneill-tm-scanlon-inequality/](https://www.bostonreview.net/articles/martin-oneill-tm-scanlon-inequality/)  
20. (PDF) A Public Health Reset Through Contractualism \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/356209156\_A\_Public\_Health\_Reset\_Through\_Contractualism](https://www.researchgate.net/publication/356209156_A_Public_Health_Reset_Through_Contractualism)  
21. If contractualism, then AMF \- Rethink Priorities, accessed April 20, 2025, [https://rethinkpriorities.org/research-area/if-contractualism-then-amf/](https://rethinkpriorities.org/research-area/if-contractualism-then-amf/)  
22. Medicine, healthcare, and the market, accessed April 20, 2025, [https://www.espmh.org/wp-content/uploads/Abstract-booklet-2024-Frankfurt-Offenbach.pdf](https://www.espmh.org/wp-content/uploads/Abstract-booklet-2024-Frankfurt-Offenbach.pdf)  
23. Ethical Framework for Artificial Intelligence and Digital Technologies Mona Ashoka\*, Rohit Madana, Anton Johaa and Uthayasankar \- Bradford Scholars, accessed April 20, 2025, [https://bradscholars.brad.ac.uk/bitstreams/d0fb531b-057f-4141-90ad-bf4a185cb685/download](https://bradscholars.brad.ac.uk/bitstreams/d0fb531b-057f-4141-90ad-bf4a185cb685/download)  
24. Technology and the Virtues: A Philosophical Guide to a Future ..., accessed April 20, 2025, [https://ndpr.nd.edu/reviews/technology-and-the-virtues-a-philosophical-guide-to-a-future-worth-wanting/](https://ndpr.nd.edu/reviews/technology-and-the-virtues-a-philosophical-guide-to-a-future-worth-wanting/)  
25. Living well in the technosocial world – a review of Shannon Vallor's Technology and the Virtues | LibrarianShipwreck, accessed April 20, 2025, [https://librarianshipwreck.wordpress.com/2017/08/24/living-well-in-the-technosocial-world-a-review-of-shannon-vallors-technology-and-the-virtues/](https://librarianshipwreck.wordpress.com/2017/08/24/living-well-in-the-technosocial-world-a-review-of-shannon-vallors-technology-and-the-virtues/)  
26. Cultivating Technomoral Interrelations, Damien Williams \- Social Epistemology Review and Reply Collective, accessed April 20, 2025, [https://social-epistemology.com/2018/02/22/cultivating-technomoral-interrelations-damien-williams/](https://social-epistemology.com/2018/02/22/cultivating-technomoral-interrelations-damien-williams/)  
27. Justice and fairness | Business Ethics in the Digital Age Class Notes \- Fiveable, accessed April 20, 2025, [https://library.fiveable.me/business-ethics-in-the-digital-age/unit-1/justice-fairness/study-guide/wXmoFjwAtWG2E3sq](https://library.fiveable.me/business-ethics-in-the-digital-age/unit-1/justice-fairness/study-guide/wXmoFjwAtWG2E3sq)  
28. Contractualism \- Stanford Encyclopedia of Philosophy, accessed April 20, 2025, [https://plato.stanford.edu/entries/contractualism/](https://plato.stanford.edu/entries/contractualism/)  
29. Non-empirical methods for ethics research on digital technologies in medicine, health care and public health: a systematic journal review, accessed April 20, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11519279/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11519279/)  
30. Technology and the Virtues \- Hardcover \- Shannon Vallor \- Oxford University Press, accessed April 20, 2025, [https://global.oup.com/academic/product/technology-and-the-virtues-9780190498511](https://global.oup.com/academic/product/technology-and-the-virtues-9780190498511)  
31. Technology and the Virtues: A Philosophical Guide to a Future Worth Wanting, accessed April 20, 2025, [https://socialconcerns.nd.edu/virtues/newsletter-post/technology-and-the-virtues-a-philosophical-guide-to-a-future-worth-wanting/](https://socialconcerns.nd.edu/virtues/newsletter-post/technology-and-the-virtues-a-philosophical-guide-to-a-future-worth-wanting/)  
32. Technology and the Virtues: A Philosophical Guide to a Future Worth Wanting, accessed April 20, 2025, [https://academic.oup.com/book/25951](https://academic.oup.com/book/25951)  
33. Matters of Care: Speculative Ethics in More than Human Worlds \- Project MUSE, accessed April 20, 2025, [https://muse.jhu.edu/book/50528](https://muse.jhu.edu/book/50528)  
34. María Puig de la Bellacasa, *Matters of Care: Speculative Ethics in More Than Human Worlds* | Somatechnics \- Edinburgh University Press, accessed April 20, 2025, [https://www.euppublishing.com/doi/10.3366/soma.2020.0332](https://www.euppublishing.com/doi/10.3366/soma.2020.0332)  
35. Matters of care: speculative ethics in more than human worlds \- Taylor & Francis Online, accessed April 20, 2025, [https://www.tandfonline.com/doi/full/10.1080/14636778.2019.1586527](https://www.tandfonline.com/doi/full/10.1080/14636778.2019.1586527)  
36. What We Owe to Each Other \- Harvard University Press, accessed April 20, 2025, [https://www.hup.harvard.edu/books/9780674004238](https://www.hup.harvard.edu/books/9780674004238)  
37. The Politics of Spirit in Stiegler's Techno-Pharmacology \- Pure, accessed April 20, 2025, [http://pure-oai.bham.ac.uk/ws/files/29951844/ThePolsofSpiritinStiegler\_27sTechno\_Pharmacology\_3.pdf](http://pure-oai.bham.ac.uk/ws/files/29951844/ThePolsofSpiritinStiegler_27sTechno_Pharmacology_3.pdf)  
38. Bernard Stiegler (1952-2020) | Issue 140 \- Philosophy Now, accessed April 20, 2025, [https://philosophynow.org/issues/140/Bernard\_Stiegler\_1952-2020](https://philosophynow.org/issues/140/Bernard_Stiegler_1952-2020)  
39. Bernard Stiegler's Pharmacology \- The Montreal Review, accessed April 20, 2025, [https://www.themontrealreview.com/Articles/Bernard\_Stiegler\_Elements\_of\_Pharmacology.php](https://www.themontrealreview.com/Articles/Bernard_Stiegler_Elements_of_Pharmacology.php)  
40. What Makes Life Worth Living: On Pharmacology: 9780745662718: Stiegler, Bernard, Ross, Daniel \- Amazon.com, accessed April 20, 2025, [https://www.amazon.com/What-Makes-Life-Worth-Living/dp/0745662714](https://www.amazon.com/What-Makes-Life-Worth-Living/dp/0745662714)  
41. Amazon.com: Technology and the Virtues: A Philosophical Guide to a Future Worth Wanting, accessed April 20, 2025, [https://www.amazon.com/Technology-Virtues-Philosophical-Future-Wanting/dp/019049851X](https://www.amazon.com/Technology-Virtues-Philosophical-Future-Wanting/dp/019049851X)  
42. Shannon Vallor, "Technology and the Virtues" (Oxford UP, 2016\) \- New Books Network, accessed April 20, 2025, [https://newbooksnetwork.com/shannon-vallor-technology-and-the-virtues-oxford-up-2016](https://newbooksnetwork.com/shannon-vallor-technology-and-the-virtues-oxford-up-2016)  
43. Amazon.com: Technology and the Virtues: A Philosophical Guide to a Future Worth Wanting, accessed April 20, 2025, [https://www.amazon.com/Technology-Virtues-Philosophical-Future-Wanting/dp/019090528X](https://www.amazon.com/Technology-Virtues-Philosophical-Future-Wanting/dp/019090528X)  
44. Technology and the Virtues: Change Yourself, Change the Future \- mssv, accessed April 20, 2025, [https://mssv.net/2018/06/18/technology-and-the-virtues-change-yourself-change-the-future/](https://mssv.net/2018/06/18/technology-and-the-virtues-change-yourself-change-the-future/)  
45. Artificial Intelligence and Human Creativity: A Delicate Balance \- UNH Scholars Repository, accessed April 20, 2025, [https://scholars.unh.edu/cgi/viewcontent.cgi?article=1100\&context=comm-entary](https://scholars.unh.edu/cgi/viewcontent.cgi?article=1100&context=comm-entary)  
46. Technology and the Virtues book review \- Erhardt Graeff, accessed April 20, 2025, [https://erhardtgraeff.com/2024/12/20/technology-and-the-virtues-book-review/](https://erhardtgraeff.com/2024/12/20/technology-and-the-virtues-book-review/)  
47. Exemplars of technomoral virtues – To inspire researchers, engineers, developers and designers, accessed April 20, 2025, [https://dearengineerblog.wordpress.com/](https://dearengineerblog.wordpress.com/)  
48. The Role of Virtues in the Philosophy of Technology \- Word on Fire, accessed April 20, 2025, [https://www.wordonfire.org/articles/the-role-of-virtues-in-the-philosophy-of-technology/](https://www.wordonfire.org/articles/the-role-of-virtues-in-the-philosophy-of-technology/)  
49. Vallor's technomoral and related virtues | Download Scientific Diagram \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/figure/Vallors-technomoral-and-related-virtues\_fig1\_348852786](https://www.researchgate.net/figure/Vallors-technomoral-and-related-virtues_fig1_348852786)  
50. (PDF) Yesterday's Virtue Ethicists Meet Tomorrow's High Tech: A ..., accessed April 20, 2025, [https://www.researchgate.net/publication/318149689\_Yesterday's\_Virtue\_Ethicists\_Meet\_Tomorrow's\_High\_Tech\_A\_Critical\_Response\_to\_Technology\_and\_the\_Virtues\_by\_Shannon\_Vallor](https://www.researchgate.net/publication/318149689_Yesterday's_Virtue_Ethicists_Meet_Tomorrow's_High_Tech_A_Critical_Response_to_Technology_and_the_Virtues_by_Shannon_Vallor)  
51. Virtue Ethics and a Technomoral Framework for Online Activism \- International Journal of Communication, accessed April 20, 2025, [https://ijoc.org/index.php/ijoc/article/download/14318/3384](https://ijoc.org/index.php/ijoc/article/download/14318/3384)  
52. justice \- Exemplars of technomoral virtues \- WordPress.com, accessed April 20, 2025, [https://dearengineerblog.wordpress.com/tag/justice/](https://dearengineerblog.wordpress.com/tag/justice/)  
53. Shannon Vallor's "technomoral virtues" \- The Society of the Free and... \- groups \- Crabgrass \- we.Riseup.net, accessed April 20, 2025, [https://we.riseup.net/sotfe/shannon-vallor-s-technomoral-virtues](https://we.riseup.net/sotfe/shannon-vallor-s-technomoral-virtues)  
54. Prof Shannon Vallor's lecture on "Technomoral Virtues and the Future of Human Flourishing" \- YouTube, accessed April 20, 2025, [https://www.youtube.com/watch?v=5zqDx2q7oTY](https://www.youtube.com/watch?v=5zqDx2q7oTY)  
55. I am philosopher Shannon Vallor \- AMA about philosophy of science, philosophy of technology and the ethics of emerging technologies\! \- Reddit, accessed April 20, 2025, [https://www.reddit.com/r/philosophy/comments/60v3vi/i\_am\_philosopher\_shannon\_vallor\_ama\_about/](https://www.reddit.com/r/philosophy/comments/60v3vi/i_am_philosopher_shannon_vallor_ama_about/)  
56. Shannon Vallor,  
57. Tech on Earth Podcast, Episode 4: “Virtue Ethics and Technomoral Futures” \- YouTube, accessed April 20, 2025, [https://www.youtube.com/watch?v=9Wds1zB0cyc](https://www.youtube.com/watch?v=9Wds1zB0cyc)  
58. Shannon Vallor's “technomoral virtues” — LessWrong, accessed April 20, 2025, [https://www.lesswrong.com/posts/KKayJ2CXEgW2CaCXr/shannon-vallor-s-technomoral-virtues](https://www.lesswrong.com/posts/KKayJ2CXEgW2CaCXr/shannon-vallor-s-technomoral-virtues)  
59. 5.4 Virtue Ethics and Ethics of Care – Introduction to Philosophy \- Pima Open Digital Press, accessed April 20, 2025, [https://pimaopen.pressbooks.pub/introphilosophy/chapter/5-4-normative-theories-virtue-ethics/](https://pimaopen.pressbooks.pub/introphilosophy/chapter/5-4-normative-theories-virtue-ethics/)  
60. Matters of Care: Speculative Ethics in More than Human Worlds (Volume 41\) (Posthumanities) \- Amazon.com, accessed April 20, 2025, [https://www.amazon.com/Matters-Care-Posthumanities-Mar%C3%ADa-Bellacasa/dp/1517900654](https://www.amazon.com/Matters-Care-Posthumanities-Mar%C3%ADa-Bellacasa/dp/1517900654)  
61. Matters Of Care by Maria Puig De La Bellacasa \- Society & Space, accessed April 20, 2025, [https://www.societyandspace.org/articles/matters-of-care-by-maria-puig-de-la-bellacasa](https://www.societyandspace.org/articles/matters-of-care-by-maria-puig-de-la-bellacasa)  
62. Reframing Care \- Reading María Puig de la Bellacasa 'Matters of Care Speculative Ethics in More Than Human Worlds' \- Ethics of care, accessed April 20, 2025, [https://ethicsofcare.org/reframing-care-reading-maria-puig-de-la-bellacasa-matters-of-care-speculative-ethics-in-more-than-human-worlds/](https://ethicsofcare.org/reframing-care-reading-maria-puig-de-la-bellacasa-matters-of-care-speculative-ethics-in-more-than-human-worlds/)  
63. Matters of Care: Speculative Ethics in More Than Human Worlds | FSP, accessed April 20, 2025, [https://feministspatialpractices.com/directory/matters-of-care-speculative-ethics-in-more-than-human-worlds](https://feministspatialpractices.com/directory/matters-of-care-speculative-ethics-in-more-than-human-worlds)  
64. Matters of Care: Speculative Ethics in More than Human Worlds (Volume 41\) (Posthumanities) \- Amazon.com, accessed April 20, 2025, [https://www.amazon.com/Matters-Care-Speculative-Ethics-Posthumanities/dp/1517900646](https://www.amazon.com/Matters-Care-Speculative-Ethics-Posthumanities/dp/1517900646)  
65. María Puig de la Bellacasa \- UC Santa Cruz \- History of Consciousness, accessed April 20, 2025, [https://histcon.ucsc.edu/people/index.php?uid=mpuigdel](https://histcon.ucsc.edu/people/index.php?uid=mpuigdel)  
66. Matters of Care \- Maria Puig de La Bellacasa.pdf, accessed April 20, 2025, [https://syllabus.pirate.care/library/Maria%20Puig%20de%20La%20Bellacasa/Matters%20of%20Care%20(171)/Matters%20of%20Care%20-%20Maria%20Puig%20de%20La%20Bellacasa.pdf](https://syllabus.pirate.care/library/Maria%20Puig%20de%20La%20Bellacasa/Matters%20of%20Care%20\(171\)/Matters%20of%20Care%20-%20Maria%20Puig%20de%20La%20Bellacasa.pdf)  
67. Matters of Care: Speculative Ethics in More Than Human Worlds \- María Puig de la Bellacasa \- Google Books, accessed April 20, 2025, [https://books.google.com/books/about/Matters\_of\_Care.html?id=OsJBvgAACAAJ](https://books.google.com/books/about/Matters_of_Care.html?id=OsJBvgAACAAJ)  
68. Matters of care: Speculative ethics in more than human worlds \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/321704484\_Matters\_of\_care\_Speculative\_ethics\_in\_more\_than\_human\_worlds](https://www.researchgate.net/publication/321704484_Matters_of_care_Speculative_ethics_in_more_than_human_worlds)  
69. www.ssoar.info Infrastructures of care: Ethics in everyday digital media use, accessed April 20, 2025, [https://www.ssoar.info/ssoar/bitstream/handle/document/101482/ssoar-tatup-2025-1-peil-Infrastructures\_of\_care\_Ethics\_in.pdf?sequence=1\&isAllowed=y](https://www.ssoar.info/ssoar/bitstream/handle/document/101482/ssoar-tatup-2025-1-peil-Infrastructures_of_care_Ethics_in.pdf?sequence=1&isAllowed=y)  
70. M. Puig de la Bellacasa Matters of Care. Speculative Ethics in More Than Human Worlds, Min, accessed April 20, 2025, [https://tecnoscienza.unibo.it/article/download/17450/16299/68023](https://tecnoscienza.unibo.it/article/download/17450/16299/68023)  
71. Matters of Care in Technoscience: Assembling Neglected Things | Request PDF, accessed April 20, 2025, [https://www.researchgate.net/publication/51108901\_Matters\_of\_Care\_in\_Technoscience\_Assembling\_Neglected\_Things](https://www.researchgate.net/publication/51108901_Matters_of_Care_in_Technoscience_Assembling_Neglected_Things)  
72. Matters of care in technoscience: Assembling neglected things, accessed April 20, 2025, [https://pages.memoryoftheworld.org/library/Maria%20Puig%20de%20La%20Bellacasa/Matters%20of%20Care%20in%20Technoscience\_%20Assembling%20Neglected%20Things%20%2813%29/Matters%20of%20Care%20in%20Technoscience\_%20Assembli%20-%20Maria%20Puig%20de%20La%20Bellacasa.pdf](https://pages.memoryoftheworld.org/library/Maria%20Puig%20de%20La%20Bellacasa/Matters%20of%20Care%20in%20Technoscience_%20Assembling%20Neglected%20Things%20%2813%29/Matters%20of%20Care%20in%20Technoscience_%20Assembli%20-%20Maria%20Puig%20de%20La%20Bellacasa.pdf)  
73. Matters of care in technoscience: assembling neglected things \- PubMed, accessed April 20, 2025, [https://pubmed.ncbi.nlm.nih.gov/21553641/](https://pubmed.ncbi.nlm.nih.gov/21553641/)  
74. (PDF) book review \- María Puig de la Bellacasa (2017) Matters of Care: Speculative Ethics in More Than Human Worlds. Minneapolis and London: University of Minnesota Press. 265 pages. ISBN: 978-1-5179-0064-9 \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/325269953\_book\_review\_-\_Maria\_Puig\_de\_la\_Bellacasa\_2017\_Matters\_of\_Care\_Speculative\_Ethics\_in\_More\_Than\_Human\_Worlds\_Minneapolis\_and\_London\_University\_of\_Minnesota\_Press\_265\_pages\_ISBN\_978-1-5179-0064-9](https://www.researchgate.net/publication/325269953_book_review_-_Maria_Puig_de_la_Bellacasa_2017_Matters_of_Care_Speculative_Ethics_in_More_Than_Human_Worlds_Minneapolis_and_London_University_of_Minnesota_Press_265_pages_ISBN_978-1-5179-0064-9)  
75. Review to M. Puig de la Bellacasa Matters of Care. Speculative Ethics in More Than Human Worlds, Minneapolis, University of Minnesota Press, 2017, pp. 280 \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/347463987\_Review\_to\_M\_Puig\_de\_la\_Bellacasa\_Matters\_of\_Care\_Speculative\_Ethics\_in\_More\_Than\_Human\_Worlds\_Minneapolis\_University\_of\_Minnesota\_Press\_2017\_pp\_280](https://www.researchgate.net/publication/347463987_Review_to_M_Puig_de_la_Bellacasa_Matters_of_Care_Speculative_Ethics_in_More_Than_Human_Worlds_Minneapolis_University_of_Minnesota_Press_2017_pp_280)  
76. Matters of Care: Speculative Ethics in More than Human Worlds (Posthumanities Book 41), accessed April 20, 2025, [https://www.amazon.com/Matters-Care-Speculative-Ethics-Posthumanities-ebook/dp/B06XFSSMDX](https://www.amazon.com/Matters-Care-Speculative-Ethics-Posthumanities-ebook/dp/B06XFSSMDX)  
77. (PDF) María Puig de la Bellacasa (2017) Matters of Care: Speculative Ethics in More Than Human Worlds. Minneapolis and London: University of Minnesota Press. 265 pages. ISBN: 978-1-5179-0065-6 \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/325218986\_Maria\_Puig\_de\_la\_Bellacasa\_2017\_Matters\_of\_Care\_Speculative\_Ethics\_in\_More\_Than\_Human\_Worlds\_Minneapolis\_and\_London\_University\_of\_Minnesota\_Press\_265\_pages\_ISBN\_978-1-5179-0065-6](https://www.researchgate.net/publication/325218986_Maria_Puig_de_la_Bellacasa_2017_Matters_of_Care_Speculative_Ethics_in_More_Than_Human_Worlds_Minneapolis_and_London_University_of_Minnesota_Press_265_pages_ISBN_978-1-5179-0065-6)  
78. book review \- Bristol University Press Digital, accessed April 20, 2025, [https://bristoluniversitypressdigital.com/view/journals/ijcc/2/3/article-p445.pdf](https://bristoluniversitypressdigital.com/view/journals/ijcc/2/3/article-p445.pdf)  
79. Soil Times The Pace of Ecological Care \- Akademie Schloss Solitude, accessed April 20, 2025, [https://www.akademie-solitude.de/de/solitude-journal/soil-times-the-pace-of-ecological-care/](https://www.akademie-solitude.de/de/solitude-journal/soil-times-the-pace-of-ecological-care/)  
80. View of Infrastructures of care: Ethics in everyday digital media use | TATuP, accessed April 20, 2025, [https://www.tatup.de/index.php/tatup/article/view/7169/12052](https://www.tatup.de/index.php/tatup/article/view/7169/12052)  
81. Touching Technologies, Touching Visions. The Reclaiming of Sensorial Experience and the Politics of Speculative Thinking | Request PDF \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/240504364\_Touching\_Technologies\_Touching\_Visions\_The\_Reclaiming\_of\_Sensorial\_Experience\_and\_the\_Politics\_of\_Speculative\_Thinking](https://www.researchgate.net/publication/240504364_Touching_Technologies_Touching_Visions_The_Reclaiming_of_Sensorial_Experience_and_the_Politics_of_Speculative_Thinking)  
82. Full article: Touching imaginaries: otherwise worlds and speculative techno-touch in Wanuri Kahiu's Pumzi, accessed April 20, 2025, [https://www.tandfonline.com/doi/full/10.1080/17458927.2023.2210035](https://www.tandfonline.com/doi/full/10.1080/17458927.2023.2210035)  
83. Navigating Latest Trends in AI Ethics | United Nations University, accessed April 20, 2025, [https://unu.edu/macau/blog-post/navigating-latest-trends-ai-ethics](https://unu.edu/macau/blog-post/navigating-latest-trends-ai-ethics)  
84. Concepts of Ethics and Their Application to AI \- PMC \- PubMed Central, accessed April 20, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC7968613/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7968613/)  
85. Contractualism and Our Duties to Nonhuman Animals Matthew Talbert West Virginia University Published in Environmental Ethics 28, accessed April 20, 2025, [https://community.wvu.edu/\~matalbert/Matthew\_Talbert/Research\_&\_Publications\_files/Talbert,%20Contractualism%20and%20Duties%20to%20Nonhuman%20Animals.pdf](https://community.wvu.edu/~matalbert/Matthew_Talbert/Research_&_Publications_files/Talbert,%20Contractualism%20and%20Duties%20to%20Nonhuman%20Animals.pdf)  
86. Scanlon's Contractualism and Its Critics \- CUNY Academic Works, accessed April 20, 2025, [https://academicworks.cuny.edu/cgi/viewcontent.cgi?article=3507\&context=gc\_etds](https://academicworks.cuny.edu/cgi/viewcontent.cgi?article=3507&context=gc_etds)  
87. What We Owe Each Other Scanlon \- ffcp.garena.com, accessed April 20, 2025, [https://ffcp.garena.com/library-catalog/secured-downloads/download/What\_We\_Owe\_Each\_Other\_Scanlon.pdf](https://ffcp.garena.com/library-catalog/secured-downloads/download/What_We_Owe_Each_Other_Scanlon.pdf)  
88. What We Owe to Each Other / Edition 1 by T. M. Scanlon | 9780674004238 \- Barnes & Noble, accessed April 20, 2025, [https://www.barnesandnoble.com/w/what-we-owe-to-each-other-t-m-scanlon/1100715735](https://www.barnesandnoble.com/w/what-we-owe-to-each-other-t-m-scanlon/1100715735)  
89. Contractualism (Stanford Encyclopedia of Philosophy/Spring 2010 Edition), accessed April 20, 2025, [https://plato.stanford.edu/archIves/spr2010/entries/contractualism/](https://plato.stanford.edu/archIves/spr2010/entries/contractualism/)  
90. Contractualism \- PhilPapers, accessed April 20, 2025, [https://philpapers.org/archive/SUIC-2.pdf](https://philpapers.org/archive/SUIC-2.pdf)  
91. Contractualism and Poverty Relief \- PhilPapers, accessed April 20, 2025, [https://philpapers.org/archive/GILCAP-2](https://philpapers.org/archive/GILCAP-2)  
92. Contractualism (Stanford Encyclopedia of Philosophy/Winter 2018 Edition), accessed April 20, 2025, [https://plato.stanford.edu/archIves/win2018/entries/contractualism/](https://plato.stanford.edu/archIves/win2018/entries/contractualism/)  
93. Ex Ante and Ex Post Contractualism – a Synthesis \- PhilArchive, accessed April 20, 2025, [https://philarchive.org/archive/SUIEAAv1](https://philarchive.org/archive/SUIEAAv1)  
94. CONTRACTUALISM'S (NOT SO) SLIPPERY SLOPE | Legal Theory | Cambridge Core, accessed April 20, 2025, [https://www.cambridge.org/core/journals/legal-theory/article/contractualisms-not-so-slippery-slope/0F4F3286A9D4C6DC9794B265BB4A3209](https://www.cambridge.org/core/journals/legal-theory/article/contractualisms-not-so-slippery-slope/0F4F3286A9D4C6DC9794B265BB4A3209)  
95. A Public Health Reset Through Contractualism | Voices in Bioethics, accessed April 20, 2025, [https://journals.library.columbia.edu/index.php/bioethics/article/view/8600](https://journals.library.columbia.edu/index.php/bioethics/article/view/8600)  
96. A Legitimate Freedom Approach to Sustainability: Sen, Scanlon and the Inadequacy of the Human Development Index | Request PDF \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/262970926\_A\_Legitimate\_Freedom\_Approach\_to\_Sustainability\_Sen\_Scanlon\_and\_the\_Inadequacy\_of\_the\_Human\_Development\_Index](https://www.researchgate.net/publication/262970926_A_Legitimate_Freedom_Approach_to_Sustainability_Sen_Scanlon_and_the_Inadequacy_of_the_Human_Development_Index)  
97. What Can Agents Reasonably Endorse? (Chapter 3\) \- Algorithms and Autonomy, accessed April 20, 2025, [https://www.cambridge.org/core/books/algorithms-and-autonomy/what-can-agents-reasonably-endorse/30DE9944817931FCEB8DC2DBDBFD86CE](https://www.cambridge.org/core/books/algorithms-and-autonomy/what-can-agents-reasonably-endorse/30DE9944817931FCEB8DC2DBDBFD86CE)  
98. 'PERSISTENT LOSING' & ELECTORAL DEMOCRACY IN THREE WORLD CITIES \- LSE Theses Online, accessed April 20, 2025, [http://etheses.lse.ac.uk/1738/1/U185669.pdf](http://etheses.lse.ac.uk/1738/1/U185669.pdf)  
99. Social Media as Contractual Networks: A Bottom Up Check on Content Moderation | Iowa Law Review, accessed April 20, 2025, [https://ilr.law.uiowa.edu/print/volume-107-issue-3/social-media-as-contractual-networks-a-bottom-up-check-on-content-moderation](https://ilr.law.uiowa.edu/print/volume-107-issue-3/social-media-as-contractual-networks-a-bottom-up-check-on-content-moderation)  
100. Terms of Service – Glossary of Platform Law and Policy Terms, accessed April 20, 2025, [https://platformglossary.info/terms-of-service/](https://platformglossary.info/terms-of-service/)  
101. Terms of service and human rights: an analysis of online platform contracts \- Freedom of Expression \- The Council of Europe, accessed April 20, 2025, [https://www.coe.int/en/web/freedom-expression/home/-/asset\_publisher/RAupmF2S6voG/content/terms-of-service-and-human-rights-an-analysis-of-online-platform-contracts](https://www.coe.int/en/web/freedom-expression/home/-/asset_publisher/RAupmF2S6voG/content/terms-of-service-and-human-rights-an-analysis-of-online-platform-contracts)  
102. How Internet Contracts Impact Research: Content Analysis of Terms of Service on Consumer Product Websites \- PMC, accessed April 20, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC7744264/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7744264/)  
103. A Contractual Approach To Social Media Governance \- Yale Law & Policy Review, accessed April 20, 2025, [https://yalelawandpolicy.org/contractual-approach-social-media-governance](https://yalelawandpolicy.org/contractual-approach-social-media-governance)  
104. Choice Architecture \- The Decision Lab, accessed April 20, 2025, [https://thedecisionlab.com/reference-guide/psychology/choice-architecture](https://thedecisionlab.com/reference-guide/psychology/choice-architecture)  
105. Choice architecture: what is it, why use it — and is it ethical? \- Nulab, accessed April 20, 2025, [https://nulab.com/learn/design-and-ux/what-is-choice-architecture-and-is-it-ethical/](https://nulab.com/learn/design-and-ux/what-is-choice-architecture-and-is-it-ethical/)  
106. Nudge in perspective: A systematic literature review on the ethical issues with nudging, accessed April 20, 2025, [https://www.researchgate.net/publication/367596407\_Nudge\_in\_perspective\_A\_systematic\_literature\_review\_on\_the\_ethical\_issues\_with\_nudging](https://www.researchgate.net/publication/367596407_Nudge_in_perspective_A_systematic_literature_review_on_the_ethical_issues_with_nudging)  
107. Let the Chips Fall\! Public Nudging Arrangements, Coercion, and the Role of Independent Shopkeepers \- PMC \- PubMed Central, accessed April 20, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10177725/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10177725/)  
108. The Moral Permissibility of Digital Nudging in the Workplace: Reconciling Justification and Legitimation | Business Ethics Quarterly \- Cambridge University Press, accessed April 20, 2025, [https://www.cambridge.org/core/journals/business-ethics-quarterly/article/moral-permissibility-of-digital-nudging-in-the-workplace-reconciling-justification-and-legitimation/C41672CEDF3BD0818872B14EC95AA4A5](https://www.cambridge.org/core/journals/business-ethics-quarterly/article/moral-permissibility-of-digital-nudging-in-the-workplace-reconciling-justification-and-legitimation/C41672CEDF3BD0818872B14EC95AA4A5)  
109. The Moral Permissibility of Digital Nudging in the Workplace: Reconciling Justification and Legitimation \- Cambridge University Press, accessed April 20, 2025, [https://www.cambridge.org/core/services/aop-cambridge-core/content/view/C41672CEDF3BD0818872B14EC95AA4A5/S1052150X23000040a.pdf/moral\_permissibility\_of\_digital\_nudging\_in\_the\_workplace\_reconciling\_justification\_and\_legitimation.pdf](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/C41672CEDF3BD0818872B14EC95AA4A5/S1052150X23000040a.pdf/moral_permissibility_of_digital_nudging_in_the_workplace_reconciling_justification_and_legitimation.pdf)  
110. Nudging and Participation: a Contractualist Approach to Behavioural Policy \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/334229969\_Nudging\_and\_Participation\_a\_Contractualist\_Approach\_to\_Behavioural\_Policy](https://www.researchgate.net/publication/334229969_Nudging_and_Participation_a_Contractualist_Approach_to_Behavioural_Policy)  
111. The Cognitive Mechanisms of Contractualist Moral Decision-Making, accessed April 20, 2025, [https://faculty.washington.edu/maxkw/publication/levine-2018-cognitive/levine-2018-cognitive.pdf](https://faculty.washington.edu/maxkw/publication/levine-2018-cognitive/levine-2018-cognitive.pdf)  
112. Research \- Cushman Lab, accessed April 20, 2025, [https://cushmanlab.fas.harvard.edu/research/](https://cushmanlab.fas.harvard.edu/research/)  
113. Johann Jakob Häußermann, Nudging and Participation: a Contractualist Approach to Behavioural Policy \- PhilPapers, accessed April 20, 2025, [https://philpapers.org/rec/HUENAP](https://philpapers.org/rec/HUENAP)  
114. Against Algorithmic Exploitation of Human Vulnerabilities \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/367088704\_Against\_Algorithmic\_Exploitation\_of\_Human\_Vulnerabilities](https://www.researchgate.net/publication/367088704_Against_Algorithmic_Exploitation_of_Human_Vulnerabilities)  
115. The Reach of Fairness \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/389259810\_The\_Reach\_of\_Fairness](https://www.researchgate.net/publication/389259810_The_Reach_of_Fairness)  
116. Citations of: Fairness \- PhilArchive, accessed April 20, 2025, [https://philarchive.org/citations/BROF-3?eId=BROF-3\&url=\&sqc=off\&categorizerOn=off\&onlineOnly=\&proOnly=off\&hideAbstracts=off\&filterByAreas=off\&publishedOnly=off\&newWindow=off\&total=117\&langFilter=off\&direction=citations\&page\_size=50\&freeOnly=\&showCategories=off\&offset=0](https://philarchive.org/citations/BROF-3?eId=BROF-3&url&sqc=off&categorizerOn=off&onlineOnly&proOnly=off&hideAbstracts=off&filterByAreas=off&publishedOnly=off&newWindow=off&total=117&langFilter=off&direction=citations&page_size=50&freeOnly&showCategories=off&offset=0)  
117. AI-related data ethics oversight in UK policing \- Oxford Academic, accessed April 20, 2025, [https://academic.oup.com/policing/article/doi/10.1093/police/paae016/7604796](https://academic.oup.com/policing/article/doi/10.1093/police/paae016/7604796)  
118. (PDF) AI-related data ethics oversight in UK policing \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/378127144\_AI-related\_data\_ethics\_oversight\_in\_UK\_policing](https://www.researchgate.net/publication/378127144_AI-related_data_ethics_oversight_in_UK_policing)  
119. Citations of: Contractualism and utilitarianism \- PhilArchive, accessed April 20, 2025, [https://philarchive.org/citations/SCACAU](https://philarchive.org/citations/SCACAU)  
120. AI-related data ethics oversight in UK policing \- OUCI, accessed April 20, 2025, [https://ouci.dntb.gov.ua/en/works/98er8Oa7/](https://ouci.dntb.gov.ua/en/works/98er8Oa7/)  
121. Modelling Moral Decision-Making in a Contractualist Artificial Agent \- OSF, accessed April 20, 2025, [https://osf.io/658rs/download](https://osf.io/658rs/download)  
122. Algorithms and Autonomy: The Ethics of Automated Decision Systems \- PhilPapers, accessed April 20, 2025, [https://philpapers.org/archive/RUBAAA-5.pdf](https://philpapers.org/archive/RUBAAA-5.pdf)  
123. What Should AI Owe To Us? Accountable and Aligned AI Systems via Contractualist AI Alignment \- LessWrong, accessed April 20, 2025, [https://www.lesswrong.com/posts/Cty2rSMut483QgBQ2/what-should-ai-owe-to-us-accountable-and-aligned-ai-systems](https://www.lesswrong.com/posts/Cty2rSMut483QgBQ2/what-should-ai-owe-to-us-accountable-and-aligned-ai-systems)  
124. Scanlonian Contractualism and Animals, accessed April 20, 2025, [https://hammer.purdue.edu/articles/thesis/\_b\_Scanlonian\_Contractualism\_and\_Animals\_b\_/25655460](https://hammer.purdue.edu/articles/thesis/_b_Scanlonian_Contractualism_and_Animals_b_/25655460)  
125. The Demandingness of Scanlon's Contractualism\* | Ethics: Vol 113, No 2, accessed April 20, 2025, [https://www.journals.uchicago.edu/doi/abs/10.1086/342853](https://www.journals.uchicago.edu/doi/abs/10.1086/342853)  
126. The Aggregation Problem for Scanlonian Contractualism \- CentAUR, accessed April 20, 2025, [https://centaur.reading.ac.uk/97047/1/Van%20Gils\_Thesis%20Redacted.pdf](https://centaur.reading.ac.uk/97047/1/Van%20Gils_Thesis%20Redacted.pdf)  
127. Review: What We Owe to Each Other \- Lotz in Translation, accessed April 20, 2025, [https://lotzintranslation.com/2023/05/24/review-what-we-owe-to-each-other/](https://lotzintranslation.com/2023/05/24/review-what-we-owe-to-each-other/)  
128. "Scanlon's Contractualism and Its Critics" by Kenneth R. Weisshaar, accessed April 20, 2025, [https://academicworks.cuny.edu/gc\_etds/2468/](https://academicworks.cuny.edu/gc_etds/2468/)  
129. A Critique of Scanlon on the Scope of Morality \- Digital Commons @ Cal Poly, accessed April 20, 2025, [https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=2217\&context=bts](https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=2217&context=bts)  
130. "A Critique of Scanlon on the Scope of Morality" by Benjamin A. Elmore, accessed April 20, 2025, [https://digitalcommons.calpoly.edu/bts/vol24/iss1/11/](https://digitalcommons.calpoly.edu/bts/vol24/iss1/11/)  
131. Pharmakon \- Wikipedia, accessed April 20, 2025, [https://en.wikipedia.org/wiki/Pharmakon](https://en.wikipedia.org/wiki/Pharmakon)  
132. In Response to Bernard Stiegler: A Pharmacological Avant-Garde \- Arrow@TU Dublin, accessed April 20, 2025, [https://arrow.tudublin.ie/cgi/viewcontent.cgi?article=1023\&context=inp](https://arrow.tudublin.ie/cgi/viewcontent.cgi?article=1023&context=inp)  
133. The Politics of Spirit in Stiegler's Techno-Pharmacology \- CiteSeerX, accessed April 20, 2025, [https://citeseerx.ist.psu.edu/document?repid=rep1\&type=pdf\&doi=12887c0e1a2b71891c80981137459ec1c4fe0905](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=12887c0e1a2b71891c80981137459ec1c4fe0905)  
134. Stiegler and Technics \- Notre Dame Philosophical Reviews, accessed April 20, 2025, [https://ndpr.nd.edu/reviews/stiegler-and-technics/](https://ndpr.nd.edu/reviews/stiegler-and-technics/)  
135. Reading Bernard Stiegler \- Sam Kinsley, accessed April 20, 2025, [https://www.samkinsley.com/2011/11/01/reading-bernard-stiegler/](https://www.samkinsley.com/2011/11/01/reading-bernard-stiegler/)  
136. Bernard Stiegler: In Memoriam – 3:AM Magazine, accessed April 20, 2025, [https://www.3ammagazine.com/3am/bernard-stiegler-in-memoriam/](https://www.3ammagazine.com/3am/bernard-stiegler-in-memoriam/)  
137. Bernard Stiegler and the fate of aesthetic performance in the time of digital media, accessed April 20, 2025, [https://etheses.bham.ac.uk/id/eprint/11095](https://etheses.bham.ac.uk/id/eprint/11095)  
138. stiegler on technology \- William Temple Foundation, accessed April 20, 2025, [https://williamtemplefoundation.org.uk/wp-content/uploads/Reader-Stiegler-on-Technology.pdf](https://williamtemplefoundation.org.uk/wp-content/uploads/Reader-Stiegler-on-Technology.pdf)  
139. Full article: Stiegler's Rigour: Metaphors for a Critical Continental Philosophy of Technology, accessed April 20, 2025, [https://www.tandfonline.com/doi/full/10.1080/20539320.2022.2059980](https://www.tandfonline.com/doi/full/10.1080/20539320.2022.2059980)  
140. Bernard Stiegler on the Dangers of the Digital | Political Theology Network, accessed April 20, 2025, [https://politicaltheology.com/bernard-stiegler-on-the-dangers-of-the-digital/](https://politicaltheology.com/bernard-stiegler-on-the-dangers-of-the-digital/)  
141. The technology of forgetting \- Yuk Hui, accessed April 20, 2025, [https://digitalmilieu.net/19/the-technology-of-forgetting/](https://digitalmilieu.net/19/the-technology-of-forgetting/)  
142. Phantasy, Technology, Critique: On Bernard Stiegler's Pharmacology of the Imagination, accessed April 20, 2025, [https://www.researchgate.net/publication/388225201\_Phantasy\_Technology\_Critique\_On\_Bernard\_Stiegler's\_Pharmacology\_of\_the\_Imagination](https://www.researchgate.net/publication/388225201_Phantasy_Technology_Critique_On_Bernard_Stiegler's_Pharmacology_of_the_Imagination)  
143. Our Tools Shape Our Selves \- DigitalRosh, accessed April 20, 2025, [https://digitalrosh.com/knowledge/digital-culture/inspiration/our-tools-shape-our-selves/](https://digitalrosh.com/knowledge/digital-culture/inspiration/our-tools-shape-our-selves/)  
144. A Pharmacological Perspective on Technology-Induced Organised Immaturity: The Care-giving Role of the Arts | Business Ethics Quarterly \- Cambridge University Press, accessed April 20, 2025, [https://www.cambridge.org/core/journals/business-ethics-quarterly/article/pharmacological-perspective-on-technologyinduced-organised-immaturity-the-caregiving-role-of-the-arts/06DC29FD2CD8F6990156ADCC82EEF255](https://www.cambridge.org/core/journals/business-ethics-quarterly/article/pharmacological-perspective-on-technologyinduced-organised-immaturity-the-caregiving-role-of-the-arts/06DC29FD2CD8F6990156ADCC82EEF255)  
145. A Pharmacological Perspective on Technology-Induced Organised Immaturity: The Care-giving Role of the Arts \- Cambridge University Press & Assessment, accessed April 20, 2025, [https://www.cambridge.org/core/services/aop-cambridge-core/content/view/06DC29FD2CD8F6990156ADCC82EEF255/S1052150X22000392a.pdf/a-pharmacological-perspective-on-technology-induced-organised-immaturity-the-care-giving-role-of-the-arts.pdf](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/06DC29FD2CD8F6990156ADCC82EEF255/S1052150X22000392a.pdf/a-pharmacological-perspective-on-technology-induced-organised-immaturity-the-care-giving-role-of-the-arts.pdf)  
146. A pharmacology of digital tools \- Thought Shrapnel, accessed April 20, 2025, [https://thoughtshrapnel.com/2024/04/10/a-pharmacology-of.html](https://thoughtshrapnel.com/2024/04/10/a-pharmacology-of.html)  
147. BERNARD STIEGLER AND THE FATE OF AESTHETIC PERFORMANCE IN THE TIME OF DIGITAL MEDIA by TAI LING \- University of Birmingham, accessed April 20, 2025, [https://etheses.bham.ac.uk/id/eprint/11095/13/Ling2020PhD.pdf](https://etheses.bham.ac.uk/id/eprint/11095/13/Ling2020PhD.pdf)  
148. What Makes Life Worth Living: On Pharmacology by Bernard Stiegler | Goodreads, accessed April 20, 2025, [https://www.goodreads.com/book/show/17804580](https://www.goodreads.com/book/show/17804580)  
149. What Makes Life Worth Living: On Pharmacology \- Wiley, accessed April 20, 2025, [https://www.wiley.com/en-us/What+Makes+Life+Worth+Living%3A+On+Pharmacology-p-9780745662701](https://www.wiley.com/en-us/What+Makes+Life+Worth+Living%3A+On+Pharmacology-p-9780745662701)  
150. What Makes Life Worth Living: On Pharmacology | Wiley \- Sybex, accessed April 20, 2025, [https://dev.store.wiley.com/en-hk/What+Makes+Life+Worth+Living%3A+On+Pharmacology-p-9780745662701](https://dev.store.wiley.com/en-hk/What+Makes+Life+Worth+Living%3A+On+Pharmacology-p-9780745662701)  
151. What Makes Life Worth Living: On Pharmacology \- Stiegler, Bernard: 9780745662718 \- AbeBooks, accessed April 20, 2025, [https://www.abebooks.com/9780745662718/What-Life-Worth-Living-Pharmacology-0745662714/plp](https://www.abebooks.com/9780745662718/What-Life-Worth-Living-Pharmacology-0745662714/plp)  
152. What Makes Life Worth Living: On Pharmacology \- Polity, accessed April 20, 2025, [https://www.politybooks.com/bookdetail/?isbn=9780745662701](https://www.politybooks.com/bookdetail/?isbn=9780745662701)  
153. Society is the patient \- Gwynneth Porter, accessed April 20, 2025, [https://gwynnethporter.net/society-is-the-patient/](https://gwynnethporter.net/society-is-the-patient/)  
154. What Makes Life Worth Living: On Pharmacology by Bernard Stiegler (2013-06-10), accessed April 20, 2025, [https://www.amazon.com/What-Makes-Life-Worth-Living/dp/B01FKS710I](https://www.amazon.com/What-Makes-Life-Worth-Living/dp/B01FKS710I)  
155. Bernard Stiegler and the necessity of education is the hammer broken and so what?, accessed April 20, 2025, [https://www.tandfonline.com/doi/full/10.1080/00131857.2022.2096007](https://www.tandfonline.com/doi/full/10.1080/00131857.2022.2096007)  
156. Bernard Stiegler and Urban Space \- Mediapolis – a journal of cities and culture, accessed April 20, 2025, [https://www.mediapolisjournal.com/2024/04/bernard-stiegler/](https://www.mediapolisjournal.com/2024/04/bernard-stiegler/)  
157. The Regulation of the Subject by the Technology of Time \- Rhizomes: Cultural Studies in Emerging Knowledge, accessed April 20, 2025, [http://www.rhizomes.net/issue34/kennel.html](http://www.rhizomes.net/issue34/kennel.html)  
158. New Media Technologies as Pharmacon\*\* Bir Farmakon Olarak Yeni Medya Teknolojileri Abstract Öz, accessed April 20, 2025, [https://dergi.bilgi.edu.tr/index.php/reflektif/article/download/167/102/866](https://dergi.bilgi.edu.tr/index.php/reflektif/article/download/167/102/866)  
159. Life is what you fill your attention with – the war for attention and the role of digital technology in the work of Bernard Stiegler \- OpenEdition Journals, accessed April 20, 2025, [https://journals.openedition.org/phenomenology/442](https://journals.openedition.org/phenomenology/442)  
160. Full article: 'Stiegler and Butler on AI and the evolution of intelligence', accessed April 20, 2025, [https://www.tandfonline.com/doi/full/10.1080/00131857.2024.2446386?src=exp-la](https://www.tandfonline.com/doi/full/10.1080/00131857.2024.2446386?src=exp-la)  
161. (PDF) 'Stiegler and Butler on AI and the evolution of intelligence' \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/387681712\_'Stiegler\_and\_Butler\_on\_AI\_and\_the\_evolution\_of\_intelligence'](https://www.researchgate.net/publication/387681712_'Stiegler_and_Butler_on_AI_and_the_evolution_of_intelligence')  
162. In the 21st century, technology has impacted popular culture to such a degree that 'the end' seems innevitable. Philosophers Bernard Stiegler and Yuk Hui show there is a way out | Matt Bluemink : r/philosophy \- Reddit, accessed April 20, 2025, [https://www.reddit.com/r/philosophy/comments/1at25xr/in\_the\_21st\_century\_technology\_has\_impacted/](https://www.reddit.com/r/philosophy/comments/1at25xr/in_the_21st_century_technology_has_impacted/)  
163. Phenomenological Approaches to Ethics and Information Technology, accessed April 20, 2025, [https://plato.stanford.edu/entries/ethics-it-phenomenology/](https://plato.stanford.edu/entries/ethics-it-phenomenology/)  
164. Dubito Ergo Sum: Exploring AI Ethics \- PhilArchive, accessed April 20, 2025, [https://philarchive.org/archive/DRFDES](https://philarchive.org/archive/DRFDES)  
165. Decoding AI Ethics: The Moral Landscape of Artificial Intelligence \- IABAC, accessed April 20, 2025, [https://iabac.org/blog/decoding-ai-ethics-the-moral-landscape-of-artificial-intelligence](https://iabac.org/blog/decoding-ai-ethics-the-moral-landscape-of-artificial-intelligence)  
166. The Moral Consideration of Artificial Entities: A Literature Review \- PMC, accessed April 20, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC8352798/](https://pmc.ncbi.nlm.nih.gov/articles/PMC8352798/)  
167. Governance for health in the 21st century, accessed April 20, 2025, [https://apps.who.int/iris/bitstream/handle/10665/326429/9789289002745-eng.pdf](https://apps.who.int/iris/bitstream/handle/10665/326429/9789289002745-eng.pdf)  
168. Deliberative Democracy, Public Reason, and the Allocation of Clinical Care Resources \- PhilArchive, accessed April 20, 2025, [https://philarchive.org/archive/BADDDP](https://philarchive.org/archive/BADDDP)  
169. CONTENTS ARTICLES: \- College of Law, accessed April 20, 2025, [https://law.fsu.edu/sites/g/files/upcbnu1581/files/JTLP/jtlp-v15n2.pdf](https://law.fsu.edu/sites/g/files/upcbnu1581/files/JTLP/jtlp-v15n2.pdf)  
170. Politics by Automatic Means? A Critique of Artificial Intelligence Ethics at Work \- PMC, accessed April 20, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC9334705/](https://pmc.ncbi.nlm.nih.gov/articles/PMC9334705/)  
171. Copyright By Siwing Tsoi 2015 \- University of Texas at Austin, accessed April 20, 2025, [https://repositories.lib.utexas.edu/bitstreams/d91407df-63d2-470f-8546-dc8601b10c79/download](https://repositories.lib.utexas.edu/bitstreams/d91407df-63d2-470f-8546-dc8601b10c79/download)  
172. Ethical concerns in contemporary virtual reality and frameworks for pursuing responsible use \- Frontiers, accessed April 20, 2025, [https://www.frontiersin.org/journals/virtual-reality/articles/10.3389/frvir.2025.1451273/full](https://www.frontiersin.org/journals/virtual-reality/articles/10.3389/frvir.2025.1451273/full)  
173. All the AI models seem to be utilitarian-leaning \- Why aren't they Kantian? : r/askphilosophy, accessed April 20, 2025, [https://www.reddit.com/r/askphilosophy/comments/1i6i9c3/all\_the\_ai\_models\_seem\_to\_be\_utilitarianleaning/](https://www.reddit.com/r/askphilosophy/comments/1i6i9c3/all_the_ai_models_seem_to_be_utilitarianleaning/)  
174. Technology and the Situationist Challenge to Virtue Ethics \- PMC \- PubMed Central, accessed April 20, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10973075/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10973075/)  
175. Varieties of Virtue Ethics \- Bibliography \- PhilPapers, accessed April 20, 2025, [https://philpapers.org/browse/varieties-of-virtue-ethics](https://philpapers.org/browse/varieties-of-virtue-ethics)  
176. Has there been any effort to consolidate Virtue Ethics, Contractualism, Utilitarianism, etc. into a comprehensive ethical framework? : r/askphilosophy \- Reddit, accessed April 20, 2025, [https://www.reddit.com/r/askphilosophy/comments/42yyvt/has\_there\_been\_any\_effort\_to\_consolidate\_virtue/](https://www.reddit.com/r/askphilosophy/comments/42yyvt/has_there_been_any_effort_to_consolidate_virtue/)  
177. An Introduction to Data Ethics Shannon Vallor, Ph.D. TABLE OF CONTENTS Introduction 2-7 What ethically significant harms and be, accessed April 20, 2025, [https://www.scu.edu/media/ethics-center/technology-ethics/IntroToDataEthics.pdf](https://www.scu.edu/media/ethics-center/technology-ethics/IntroToDataEthics.pdf)  
178. 9.1: App. A: Normative Ethics | AI Safety, Ethics, and Society Textbook, accessed April 20, 2025, [https://www.aisafetybook.com/textbook/appendix-ethics](https://www.aisafetybook.com/textbook/appendix-ethics)  
179. (PDF) Using Goals of Care Conversations to Build Ethics Competency \- ResearchGate, accessed April 20, 2025, [https://www.researchgate.net/publication/354812421\_Using\_Goals\_of\_Care\_Conversations\_to\_Build\_Ethics\_Competency](https://www.researchgate.net/publication/354812421_Using_Goals_of_Care_Conversations_to_Build_Ethics_Competency)  
180. Toward a virtue-based normative ethics for the health professions \- PubMed, accessed April 20, 2025, [https://pubmed.ncbi.nlm.nih.gov/10144959/](https://pubmed.ncbi.nlm.nih.gov/10144959/)